{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY\n",
    "top_k_categorical_accuracy\n",
    "https://stackoverflow.com/questions/47887533/keras-convolution-along-samples\n",
    "https://keras.io/layers/wrappers/#timedistributed\n",
    "### !Try target position time (current or next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "input_width = 160\n",
    "input_height = 100\n",
    "sequence_size = 15\n",
    "class_number = 12\n",
    "channels = 3\n",
    "data_path = \"D:\\\\Python\\\\Keras\\\\Wormax\\\\data_prepared\\\\\"\n",
    "model_name = 'models//worm_sequence15_4.h5'\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import models, optimizers, layers\n",
    "import keras.backend as K\n",
    "from keras.applications import Xception\n",
    "from keras.layers import TimeDistributed, Conv2D, Dropout, LSTM, Dense, MaxPooling2D, Flatten, GRU\n",
    "\n",
    "def actual_acc(y_true, y_pred):\n",
    "    return K.equal(K.argmax(y_pred), K.argmax(y_true))\n",
    "\n",
    "def convolution_feature_extractor(input_height, input_width):\n",
    "    model = models.Sequential()        \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(input_height, input_width, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.summary()    \n",
    "    return model\n",
    "\n",
    "def define_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(TimeDistributed(\n",
    "            convolution_feature_extractor(input_height, input_width),\n",
    "            input_shape=(None, input_height, input_width, 3)\n",
    "            ))\n",
    "\n",
    "    model.add(GRU(128, return_sequences=True))#, dropout=0.5))\n",
    "    model.add(GRU(128))\n",
    "    model.add(Dense(class_number, activation='softmax'))    \n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[actual_acc])\n",
    "\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 158, 32)       896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 16, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 240,832\n",
      "Trainable params: 240,832\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, None, 4096)        240832    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 128)         1622400   \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 128)               98688     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                1548      \n",
      "=================================================================\n",
      "Total params: 1,963,468\n",
      "Trainable params: 1,963,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little prepocessing\n",
    "from math import atan2, pi\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return atan2(y, x)\n",
    "\n",
    "def get_direction(x, y, n_classes = 12):\n",
    "    return round(get_angle(x, y)/2/pi*n_classes)%n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Training and validation\n",
    "data_ratio = 0.7\n",
    "            \n",
    "# Generator done for not to overflow MEM\n",
    "# holds one data file for every instance(train and validation)\n",
    "def generator(data_dir, sequence_size, num_classes, role, batch_size=128, shuffle=True):\n",
    "    \n",
    "    listdir = []\n",
    "    listdir = filter(lambda x: os.path.isfile, os.listdir(data_dir))\n",
    "    listdir = np.array(list(listdir))\n",
    "    if shuffle:\n",
    "        random.shuffle(listdir)\n",
    "    \n",
    "    #print('Found {} files for {}'.format(len(listdir), role))\n",
    "    \n",
    "    file_i = 0\n",
    "    while 1:\n",
    "        arr = np.load(data_dir + listdir[file_i])\n",
    "        file_i = (file_i+1) if file_i+1<len(listdir) else 0\n",
    "        \n",
    "        # Expanding blocks and banning inappropriate\n",
    "        data = []\n",
    "        banned_indexes = np.array([])\n",
    "        for i in arr:\n",
    "            ban = np.arange(len(data)+len(i)-sequence_size, len(data)+len(i)+1)\n",
    "            banned_indexes = np.concatenate((banned_indexes, ban), axis=0)\n",
    "            for j in i:\n",
    "                data.append(j)\n",
    "        data = np.array(data)        \n",
    "        \n",
    "        if role == 'train':\n",
    "            data = data[:int(round(len(data)*data_ratio))]\n",
    "        elif role == 'validation':\n",
    "            data = data[int(round(len(data)*data_ratio)):]\n",
    "        else:\n",
    "            raise TypeError('bad role parameter')\n",
    "        \n",
    "        indexes = np.arange(len(data)-sequence_size-1)\n",
    "        indexes = np.delete(indexes, banned_indexes)\n",
    "        if shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "        \n",
    "        for i in range(0, len(indexes), batch_size):\n",
    "            samples = np.zeros((batch_size, sequence_size, input_height, input_width, channels))\n",
    "            targets = np.zeros((batch_size, num_classes))\n",
    "            for j, index in enumerate(indexes[i:i + batch_size]):\n",
    "                # some issue with shapes(dummy reshape)\n",
    "                sample = np.zeros((sequence_size, input_height, input_width, channels))\n",
    "                for k, dt in enumerate(data[index:index + sequence_size, 0]):\n",
    "                    sample[k] = dt[0]\n",
    "                samples[j] = sample\n",
    "                targets[j] = to_categorical(get_direction(*data[index + sequence_size - 1][1][:2]), num_classes=num_classes)\n",
    "            \n",
    "            # will not work without this\n",
    "            samples = samples / 255\n",
    "            \n",
    "            yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 15, 100, 160, 3)\n",
      "(10, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DeprecationWarning: using a non-integer array as obj in delete will result in an error in the future\n",
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: DeprecationWarning: in the future out of bounds indices will raise an error instead of being ignored by `numpy.delete`.\n"
     ]
    }
   ],
   "source": [
    "train_generator = generator(data_path, sequence_size, class_number, 'train', batch_size=10)\n",
    "validation_generator = generator(data_path, sequence_size, class_number, 'validation', batch_size=10)\n",
    "\n",
    "print(next(train_generator)[0].shape)\n",
    "print(next(train_generator)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    %matplotlib notebook\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.animation import FuncAnimation\n",
    "    from grabscreen import grab_screen\n",
    "    from image_preproc import preproc_img, prepare_image\n",
    "\n",
    "    gridsize = (1, 1)\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    ax1 = plt.subplot2grid(gridsize, (0, 0))\n",
    "\n",
    "    samples, targets = next(train_generator)\n",
    "    im1 = ax1.imshow(samples[0][0])\n",
    "\n",
    "    n = 8\n",
    "    fig.suptitle(str(np.argmax(targets[n])), fontsize=20)\n",
    "    def update(i):\n",
    "        i %= sequence_size\n",
    "        im1.set_data(samples[n][i])\n",
    "\n",
    "    ani = FuncAnimation(plt.gcf(), update, interval=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####9####\n",
    "###8###10##\n",
    "##7#####11#\n",
    "#6#######0#\n",
    "##5#####1##\n",
    "###4###2###\n",
    "#####3####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count class instances count for balancing\n",
    "if False:\n",
    "    i = 0\n",
    "    classes = np.zeros((class_number))\n",
    "    for samples, targets in generator(data_path, sequence_size, class_number, 'train', batch_size=128):\n",
    "        for j in targets:\n",
    "            classes += j\n",
    "        i += 1\n",
    "        if i == 1500:\n",
    "            break\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### tensorboard --logdir=D:\\Python\\Keras\\Wormax\\log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0: 1.14,\n",
    "                 1: 1.12,\n",
    "                 2: 1.21,\n",
    "                 3: 1.36,\n",
    "                 4: 1.35,\n",
    "                 5: 1.16,\n",
    "                 6: 1.0,\n",
    "                 7: 1.02,\n",
    "                 8: 1.04,\n",
    "                 9: 1.1,\n",
    "                 10: 1.15,\n",
    "                 11: 1.24}\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log_dir\\\\' + model_name\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name + '.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.5,                              \n",
    "        patience=50, \n",
    "        min_lr=0.00001\n",
    "    )\n",
    "]\n",
    "\n",
    "steps_per_epoch = 100\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=500,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=int(round(steps_per_epoch/data_ratio*(1-data_ratio))),\n",
    "                            shuffle=True,\n",
    "                            class_weight=class_weight,\n",
    "                            callbacks=callbacks\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
