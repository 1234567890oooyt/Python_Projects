{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY\n",
    "top_k_categorical_accuracy\n",
    "https://stackoverflow.com/questions/47887533/keras-convolution-along-samples\n",
    "https://keras.io/layers/wrappers/#timedistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "input_width = 160\n",
    "input_height = 100\n",
    "channels = 3\n",
    "class_number = 12\n",
    "data_path = \"D:\\\\Python\\\\Wormax_learn2\\\\preprocessed_data_local_notshuffled\\\\\"\n",
    "model_name = 'models/worm_single_larger_adam_1'\n",
    "look_forward = 2\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers, models, optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "def actual_acc(y_true, y_pred):\n",
    "    return K.equal(K.argmax(y_pred), K.argmax(y_true))\n",
    "\n",
    "def define_model():\n",
    "    model = models.Sequential()\n",
    "        \n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                            input_shape=(input_height, input_width, channels)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(class_number, activation='softmax'))    \n",
    "           \n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[actual_acc])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 158, 32)       896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 16, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 2,344,652\n",
      "Trainable params: 2,344,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little prepocessing\n",
    "from math import atan2, pi\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return atan2(y, x)\n",
    "\n",
    "def get_direction(x, y, n_classes = 12):\n",
    "    return round(get_angle(x, y)/2/pi*n_classes)%n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Training and validation\n",
    "data_ratio = 0.7\n",
    "\n",
    "def generator(data_dir, num_classes, role, shuffle=True, batch_size=128):\n",
    "    \n",
    "    listdir = []\n",
    "    listdir = filter(lambda x: os.path.isfile, os.listdir(data_dir))\n",
    "    listdir = np.array(list(listdir))\n",
    "    random.shuffle(listdir)\n",
    "    \n",
    "    #print('Found {} files for {}'.format(len(listdir), role))\n",
    "    \n",
    "    file_i = 0\n",
    "    while 1:\n",
    "        data = np.load(data_dir + listdir[file_i])\n",
    "        file_i = (file_i+1) if file_i+1<len(listdir) else 0\n",
    "        \n",
    "        if role == 'train':\n",
    "            data = data[:int(round(len(data)*data_ratio))]\n",
    "        elif role == 'validation':\n",
    "            data = data[int(round(len(data)*data_ratio)):]\n",
    "        else:\n",
    "            raise 'bad role parameter'\n",
    "        \n",
    "        # Generating y\n",
    "        data_targets = np.zeros((len(data)-look_forward, 12))\n",
    "        for i in range(len(data_targets)):\n",
    "            data_targets[i] = np.array(to_categorical(get_direction(*data[i+look_forward][1][:2]), num_classes=num_classes))\n",
    "        data = data[:-1]\n",
    "        \n",
    "        # Only X\n",
    "        data_features = data[:,0]\n",
    "        \n",
    "        indexes = np.arange(len(data_features)-1)\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "        \n",
    "        for i in range(0, len(data)-look_forward-batch_size, batch_size):\n",
    "            samples = data_features.take(indexes[i:i+batch_size],axis=0)\n",
    "            targets = data_targets.take(indexes[i:i+batch_size],axis=0)\n",
    "            \n",
    "            # Weird reshape cuz bug # actually not bug, initial data array is not tensor(idk how to fix)\n",
    "            samples2 = np.zeros((batch_size, input_height, input_width, channels))\n",
    "            for j, sample in enumerate(samples):\n",
    "                samples2[j] = sample\n",
    "            \n",
    "            # will not work without this\n",
    "            samples2 = samples2 / 255\n",
    "            yield samples2, np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count class instances count for balancing\n",
    "if False:\n",
    "    i = 0\n",
    "    classes = np.zeros((class_number))\n",
    "    for samples, targets in generator(data_path, class_number, 'train', batch_size=1024):\n",
    "        for j in targets:\n",
    "            classes += j\n",
    "        i += 1\n",
    "        if i == 1000:\n",
    "            break\n",
    "    classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 160, 3)\n",
      "(16, 12)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_generator = generator(data_path, class_number, 'train', batch_size=16)\n",
    "validation_generator = generator(data_path, class_number, 'validation', batch_size=32)\n",
    "\n",
    "print(next(train_generator)[0].shape)\n",
    "print(next(train_generator)[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### tensorboard --logdir=D:\\Python\\Keras\\Wormax\\log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 3.5749 - actual_acc: 0.2450 - val_loss: 2.5968 - val_actual_acc: 0.0727\n",
      "Epoch 2/500\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 2.7879 - actual_acc: 0.4363 - val_loss: 2.5831 - val_actual_acc: 0.1214\n",
      "Epoch 3/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.2739 - actual_acc: 0.5356 - val_loss: 2.3894 - val_actual_acc: 0.2115\n",
      "Epoch 4/500\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 2.1345 - actual_acc: 0.5825 - val_loss: 3.1490 - val_actual_acc: 0.2398\n",
      "Epoch 5/500\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 3.1859 - actual_acc: 0.3575 - val_loss: 2.1989 - val_actual_acc: 0.2173\n",
      "Epoch 6/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 3.2978 - actual_acc: 0.3631 - val_loss: 2.2515 - val_actual_acc: 0.2420\n",
      "Epoch 7/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.7408 - actual_acc: 0.4625 - val_loss: 2.3520 - val_actual_acc: 0.2013\n",
      "Epoch 8/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 2.4146 - actual_acc: 0.5450 - val_loss: 2.6860 - val_actual_acc: 0.2042\n",
      "Epoch 9/500\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 2.7644 - actual_acc: 0.4450 - val_loss: 2.3746 - val_actual_acc: 0.1672\n",
      "Epoch 10/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.6544 - actual_acc: 0.2475 - val_loss: 2.2382 - val_actual_acc: 0.2202\n",
      "Epoch 11/500\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 3.4596 - actual_acc: 0.3100 - val_loss: 2.2405 - val_actual_acc: 0.2238\n",
      "Epoch 12/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.1901 - actual_acc: 0.3681 - val_loss: 2.4483 - val_actual_acc: 0.1991\n",
      "Epoch 13/500\n",
      "100/100 [==============================] - 37s 370ms/step - loss: 3.0376 - actual_acc: 0.3869 - val_loss: 2.3622 - val_actual_acc: 0.2166\n",
      "Epoch 14/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.0678 - actual_acc: 0.3356 - val_loss: 2.3058 - val_actual_acc: 0.2275\n",
      "Epoch 15/500\n",
      "100/100 [==============================] - 11s 115ms/step - loss: 2.2174 - actual_acc: 0.5406 - val_loss: 2.5319 - val_actual_acc: 0.2355\n",
      "Epoch 16/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.9026 - actual_acc: 0.6194 - val_loss: 2.4324 - val_actual_acc: 0.2144\n",
      "Epoch 17/500\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 1.5904 - actual_acc: 0.6737 - val_loss: 2.7509 - val_actual_acc: 0.2558\n",
      "Epoch 18/500\n",
      "100/100 [==============================] - 20s 196ms/step - loss: 2.7716 - actual_acc: 0.4381 - val_loss: 2.3341 - val_actual_acc: 0.1715\n",
      "Epoch 19/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.1922 - actual_acc: 0.3412 - val_loss: 2.4342 - val_actual_acc: 0.2653\n",
      "Epoch 20/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 2.8750 - actual_acc: 0.4169 - val_loss: 2.2170 - val_actual_acc: 0.2529\n",
      "Epoch 21/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.6832 - actual_acc: 0.4669 - val_loss: 2.3297 - val_actual_acc: 0.2108\n",
      "Epoch 22/500\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 2.6046 - actual_acc: 0.4787 - val_loss: 2.2403 - val_actual_acc: 0.2108\n",
      "Epoch 23/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.3122 - actual_acc: 0.3062 - val_loss: 2.1189 - val_actual_acc: 0.2275\n",
      "Epoch 24/500\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 2.9603 - actual_acc: 0.3787 - val_loss: 1.8621 - val_actual_acc: 0.3750\n",
      "Epoch 25/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.7731 - actual_acc: 0.4513 - val_loss: 1.7454 - val_actual_acc: 0.3823\n",
      "Epoch 26/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 2.5628 - actual_acc: 0.4825 - val_loss: 2.0145 - val_actual_acc: 0.3169\n",
      "Epoch 27/500\n",
      "100/100 [==============================] - 22s 224ms/step - loss: 3.0169 - actual_acc: 0.4144 - val_loss: 1.8769 - val_actual_acc: 0.3888\n",
      "Epoch 28/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6323 - actual_acc: 0.4694 - val_loss: 2.0686 - val_actual_acc: 0.2943\n",
      "Epoch 29/500\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 2.2630 - actual_acc: 0.5563 - val_loss: 2.2311 - val_actual_acc: 0.2791\n",
      "Epoch 30/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.0455 - actual_acc: 0.5969 - val_loss: 2.3721 - val_actual_acc: 0.2660\n",
      "Epoch 31/500\n",
      "100/100 [==============================] - 16s 159ms/step - loss: 2.6264 - actual_acc: 0.4825 - val_loss: 2.1518 - val_actual_acc: 0.2711\n",
      "Epoch 32/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.1051 - actual_acc: 0.3900 - val_loss: 2.2453 - val_actual_acc: 0.2478\n",
      "Epoch 33/500\n",
      "100/100 [==============================] - 12s 123ms/step - loss: 2.6242 - actual_acc: 0.4844 - val_loss: 2.3847 - val_actual_acc: 0.2478\n",
      "Epoch 34/500\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 2.7883 - actual_acc: 0.3981 - val_loss: 2.1664 - val_actual_acc: 0.2733\n",
      "Epoch 35/500\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 2.9648 - actual_acc: 0.3656 - val_loss: 2.1403 - val_actual_acc: 0.2318\n",
      "Epoch 36/500\n",
      "100/100 [==============================] - 11s 109ms/step - loss: 2.5691 - actual_acc: 0.4731 - val_loss: 2.2263 - val_actual_acc: 0.2180\n",
      "Epoch 37/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.4513 - actual_acc: 0.4931 - val_loss: 2.1211 - val_actual_acc: 0.3227\n",
      "Epoch 38/500\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.1103 - actual_acc: 0.5662 - val_loss: 2.2250 - val_actual_acc: 0.3009\n",
      "Epoch 39/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.9293 - actual_acc: 0.4219 - val_loss: 2.0043 - val_actual_acc: 0.2718\n",
      "Epoch 40/500\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 2.5879 - actual_acc: 0.4944 - val_loss: 2.1682 - val_actual_acc: 0.2682\n",
      "Epoch 41/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.3793 - actual_acc: 0.5369 - val_loss: 2.4789 - val_actual_acc: 0.2558\n",
      "Epoch 42/500\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 2.2672 - actual_acc: 0.5662 - val_loss: 2.3514 - val_actual_acc: 0.2580\n",
      "Epoch 43/500\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 2.8684 - actual_acc: 0.4237 - val_loss: 2.0780 - val_actual_acc: 0.2812\n",
      "Epoch 44/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 3.0031 - actual_acc: 0.3906 - val_loss: 2.1523 - val_actual_acc: 0.2558\n",
      "Epoch 45/500\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 2.8011 - actual_acc: 0.4169 - val_loss: 2.1054 - val_actual_acc: 0.3067\n",
      "Epoch 46/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6805 - actual_acc: 0.4600 - val_loss: 2.0862 - val_actual_acc: 0.3067\n",
      "Epoch 47/500\n",
      "100/100 [==============================] - 21s 205ms/step - loss: 2.8679 - actual_acc: 0.4094 - val_loss: 2.0189 - val_actual_acc: 0.2754\n",
      "Epoch 48/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.0165 - actual_acc: 0.3756 - val_loss: 1.8207 - val_actual_acc: 0.3772\n",
      "Epoch 49/500\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 2.6826 - actual_acc: 0.4269 - val_loss: 1.8770 - val_actual_acc: 0.3481\n",
      "Epoch 50/500\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.4246 - actual_acc: 0.4944 - val_loss: 1.9415 - val_actual_acc: 0.2762\n",
      "Epoch 51/500\n",
      "100/100 [==============================] - 42s 421ms/step - loss: 2.2444 - actual_acc: 0.5000 - val_loss: 2.1632 - val_actual_acc: 0.2667\n",
      "Epoch 52/500\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.2855 - actual_acc: 0.5438 - val_loss: 2.2345 - val_actual_acc: 0.2049\n",
      "Epoch 53/500\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 1.9929 - actual_acc: 0.5981 - val_loss: 2.2334 - val_actual_acc: 0.2834\n",
      "Epoch 54/500\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.7794 - actual_acc: 0.6450 - val_loss: 2.3009 - val_actual_acc: 0.2653\n",
      "Epoch 55/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 1.5213 - actual_acc: 0.7044 - val_loss: 2.3905 - val_actual_acc: 0.2638\n",
      "Epoch 56/500\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 2.7945 - actual_acc: 0.4244 - val_loss: 1.9769 - val_actual_acc: 0.3307\n",
      "Epoch 57/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.4026 - actual_acc: 0.3212 - val_loss: 2.2032 - val_actual_acc: 0.2522\n",
      "Epoch 58/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 3.1457 - actual_acc: 0.3619 - val_loss: 2.0850 - val_actual_acc: 0.3132\n",
      "Epoch 59/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 3.0989 - actual_acc: 0.3937 - val_loss: 1.8394 - val_actual_acc: 0.3525\n",
      "Epoch 60/500\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 3.0432 - actual_acc: 0.3856 - val_loss: 1.9680 - val_actual_acc: 0.3328\n",
      "Epoch 61/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.7724 - actual_acc: 0.4106 - val_loss: 2.1104 - val_actual_acc: 0.2994\n",
      "Epoch 62/500\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 2.3569 - actual_acc: 0.5244 - val_loss: 2.0575 - val_actual_acc: 0.2885\n",
      "Epoch 63/500\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 2.0052 - actual_acc: 0.5806 - val_loss: 2.0328 - val_actual_acc: 0.3045\n",
      "Epoch 64/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 1.8461 - actual_acc: 0.6200 - val_loss: 2.0424 - val_actual_acc: 0.3009\n",
      "Epoch 65/500\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.8034 - actual_acc: 0.4281 - val_loss: 1.9386 - val_actual_acc: 0.3147\n",
      "Epoch 66/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6410 - actual_acc: 0.4600 - val_loss: 1.9725 - val_actual_acc: 0.3161\n",
      "Epoch 67/500\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 2.4080 - actual_acc: 0.5181 - val_loss: 2.2746 - val_actual_acc: 0.2180\n",
      "Epoch 68/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1556 - actual_acc: 0.5619 - val_loss: 2.3608 - val_actual_acc: 0.2485\n",
      "Epoch 69/500\n",
      "100/100 [==============================] - 22s 220ms/step - loss: 2.7338 - actual_acc: 0.4438 - val_loss: 2.0654 - val_actual_acc: 0.2703\n",
      "Epoch 70/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.1864 - actual_acc: 0.3475 - val_loss: 1.9079 - val_actual_acc: 0.3459\n",
      "Epoch 71/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 3.0643 - actual_acc: 0.3825 - val_loss: 1.9319 - val_actual_acc: 0.3140\n",
      "Epoch 72/500\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 2.9064 - actual_acc: 0.4119 - val_loss: 1.9741 - val_actual_acc: 0.2769\n",
      "Epoch 73/500\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.8704 - actual_acc: 0.4062 - val_loss: 1.8666 - val_actual_acc: 0.3844\n",
      "Epoch 74/500\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 3.0401 - actual_acc: 0.4188 - val_loss: 1.7415 - val_actual_acc: 0.4331\n",
      "Epoch 75/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5454 - actual_acc: 0.5100 - val_loss: 1.7190 - val_actual_acc: 0.4077\n",
      "Epoch 76/500\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 2.2544 - actual_acc: 0.5588 - val_loss: 1.9136 - val_actual_acc: 0.3765\n",
      "Epoch 77/500\n",
      "100/100 [==============================] - 4s 42ms/step - loss: 2.1973 - actual_acc: 0.5900 - val_loss: 2.0233 - val_actual_acc: 0.2929\n",
      "Epoch 78/500\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 2.9359 - actual_acc: 0.4263 - val_loss: 1.8300 - val_actual_acc: 0.3634\n",
      "Epoch 79/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.9064 - actual_acc: 0.3994 - val_loss: 1.6416 - val_actual_acc: 0.4077\n",
      "Epoch 80/500\n",
      "100/100 [==============================] - 14s 139ms/step - loss: 2.7448 - actual_acc: 0.4325 - val_loss: 2.1884 - val_actual_acc: 0.2551\n",
      "Epoch 81/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 2.4785 - actual_acc: 0.5088 - val_loss: 2.4081 - val_actual_acc: 0.2485\n",
      "Epoch 82/500\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 2.5866 - actual_acc: 0.4775 - val_loss: 2.0668 - val_actual_acc: 0.3336\n",
      "Epoch 83/500\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 2.7533 - actual_acc: 0.4544 - val_loss: 1.9128 - val_actual_acc: 0.3278\n",
      "Epoch 84/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 2.4601 - actual_acc: 0.5212 - val_loss: 1.9541 - val_actual_acc: 0.3321\n",
      "Epoch 85/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.1969 - actual_acc: 0.5713 - val_loss: 2.0009 - val_actual_acc: 0.3496\n",
      "Epoch 86/500\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.8805 - actual_acc: 0.6475 - val_loss: 2.1595 - val_actual_acc: 0.3183\n",
      "Epoch 87/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.9293 - actual_acc: 0.3906 - val_loss: 1.9596 - val_actual_acc: 0.2987\n",
      "Epoch 88/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 2.3611 - actual_acc: 0.4994 - val_loss: 2.0477 - val_actual_acc: 0.3205\n",
      "Epoch 89/500\n",
      "100/100 [==============================] - 4s 39ms/step - loss: 2.1576 - actual_acc: 0.5487 - val_loss: 1.9085 - val_actual_acc: 0.3656\n",
      "Epoch 90/500\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 1.9742 - actual_acc: 0.5950 - val_loss: 1.9802 - val_actual_acc: 0.3619\n",
      "Epoch 91/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 2.6796 - actual_acc: 0.4600 - val_loss: 1.7837 - val_actual_acc: 0.4048\n",
      "Epoch 92/500\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 2.6075 - actual_acc: 0.4525 - val_loss: 2.0489 - val_actual_acc: 0.2798\n",
      "Epoch 93/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 2.4222 - actual_acc: 0.5144 - val_loss: 2.1447 - val_actual_acc: 0.2812\n",
      "Epoch 94/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1747 - actual_acc: 0.5644 - val_loss: 1.8773 - val_actual_acc: 0.3416\n",
      "Epoch 95/500\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 2.3663 - actual_acc: 0.5269 - val_loss: 1.9444 - val_actual_acc: 0.3038\n",
      "Epoch 96/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.0438 - actual_acc: 0.3900 - val_loss: 1.9844 - val_actual_acc: 0.3009\n",
      "Epoch 97/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 2.7706 - actual_acc: 0.4356 - val_loss: 2.0553 - val_actual_acc: 0.2922\n",
      "Epoch 98/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5906 - actual_acc: 0.4650 - val_loss: 2.2721 - val_actual_acc: 0.2733\n",
      "Epoch 99/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 2.4441 - actual_acc: 0.5112 - val_loss: 2.3089 - val_actual_acc: 0.2914\n",
      "Epoch 100/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 3.0567 - actual_acc: 0.3963 - val_loss: 2.1064 - val_actual_acc: 0.2980\n",
      "Epoch 101/500\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 2.7249 - actual_acc: 0.4562 - val_loss: 2.2148 - val_actual_acc: 0.2791\n",
      "Epoch 102/500\n",
      "100/100 [==============================] - 15s 151ms/step - loss: 2.3772 - actual_acc: 0.5306 - val_loss: 2.3451 - val_actual_acc: 0.2871\n",
      "Epoch 103/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.2286 - actual_acc: 0.5581 - val_loss: 2.1423 - val_actual_acc: 0.3401\n",
      "Epoch 104/500\n",
      "100/100 [==============================] - 20s 200ms/step - loss: 2.6084 - actual_acc: 0.4688 - val_loss: 2.0101 - val_actual_acc: 0.3249\n",
      "Epoch 105/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.8582 - actual_acc: 0.4044 - val_loss: 2.1890 - val_actual_acc: 0.3721\n",
      "Epoch 106/500\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 2.6764 - actual_acc: 0.4637 - val_loss: 2.0278 - val_actual_acc: 0.3365\n",
      "Epoch 107/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.4731 - actual_acc: 0.5019 - val_loss: 2.1653 - val_actual_acc: 0.2573\n",
      "Epoch 108/500\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.3631 - actual_acc: 0.5438 - val_loss: 2.0421 - val_actual_acc: 0.2551\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6712 - actual_acc: 0.4856 - val_loss: 1.9761 - val_actual_acc: 0.2798\n",
      "Epoch 110/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 2.2097 - actual_acc: 0.5588 - val_loss: 1.6214 - val_actual_acc: 0.4564\n",
      "Epoch 111/500\n",
      "100/100 [==============================] - 12s 122ms/step - loss: 2.1760 - actual_acc: 0.5787 - val_loss: 1.6161 - val_actual_acc: 0.4426\n",
      "Epoch 112/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 1.6948 - actual_acc: 0.6631 - val_loss: 1.9332 - val_actual_acc: 0.3699\n",
      "Epoch 113/500\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.9060 - actual_acc: 0.4131 - val_loss: 1.9717 - val_actual_acc: 0.3430\n",
      "Epoch 114/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 3.0471 - actual_acc: 0.3769 - val_loss: 1.9465 - val_actual_acc: 0.2994\n",
      "Epoch 115/500\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.8372 - actual_acc: 0.4269 - val_loss: 1.9597 - val_actual_acc: 0.3096\n",
      "Epoch 116/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.6541 - actual_acc: 0.4394 - val_loss: 1.9666 - val_actual_acc: 0.3401\n",
      "Epoch 117/500\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 2.8269 - actual_acc: 0.4231 - val_loss: 1.9624 - val_actual_acc: 0.3350\n",
      "Epoch 118/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.9339 - actual_acc: 0.3969 - val_loss: 1.9456 - val_actual_acc: 0.3365\n",
      "Epoch 119/500\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 2.8737 - actual_acc: 0.4344 - val_loss: 2.0235 - val_actual_acc: 0.3256\n",
      "Epoch 120/500\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 2.6591 - actual_acc: 0.4625 - val_loss: 2.0884 - val_actual_acc: 0.3110\n",
      "Epoch 121/500\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 2.4326 - actual_acc: 0.4950 - val_loss: 2.1573 - val_actual_acc: 0.3038\n",
      "Epoch 122/500\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 3.0207 - actual_acc: 0.3956 - val_loss: 1.9736 - val_actual_acc: 0.3140\n",
      "Epoch 123/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.4816 - actual_acc: 0.4844 - val_loss: 2.0010 - val_actual_acc: 0.3089\n",
      "Epoch 124/500\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 2.1929 - actual_acc: 0.5494 - val_loss: 1.9438 - val_actual_acc: 0.3408\n",
      "Epoch 125/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1445 - actual_acc: 0.5581 - val_loss: 1.8949 - val_actual_acc: 0.3670\n",
      "Epoch 126/500\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.7783 - actual_acc: 0.4544 - val_loss: 1.9762 - val_actual_acc: 0.3118\n",
      "Epoch 127/500\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 2.7386 - actual_acc: 0.4500 - val_loss: 2.1168 - val_actual_acc: 0.3001\n",
      "Epoch 128/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5175 - actual_acc: 0.4888 - val_loss: 1.9540 - val_actual_acc: 0.3227\n",
      "Epoch 129/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 2.2513 - actual_acc: 0.5531 - val_loss: 2.0405 - val_actual_acc: 0.3212\n",
      "Epoch 130/500\n",
      "100/100 [==============================] - 13s 127ms/step - loss: 2.4348 - actual_acc: 0.5187 - val_loss: 1.9709 - val_actual_acc: 0.3147\n",
      "Epoch 131/500\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 2.8739 - actual_acc: 0.3900 - val_loss: 1.9773 - val_actual_acc: 0.3278\n",
      "Epoch 132/500\n",
      "100/100 [==============================] - 8s 75ms/step - loss: 2.7211 - actual_acc: 0.4275 - val_loss: 1.9390 - val_actual_acc: 0.3503\n",
      "Epoch 133/500\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 2.4168 - actual_acc: 0.5106 - val_loss: 1.8720 - val_actual_acc: 0.3728\n",
      "Epoch 134/500\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 2.2549 - actual_acc: 0.5344 - val_loss: 1.8529 - val_actual_acc: 0.3743\n",
      "Epoch 135/500\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 2.6537 - actual_acc: 0.4738 - val_loss: 1.9357 - val_actual_acc: 0.2820\n",
      "Epoch 136/500\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.1824 - actual_acc: 0.5575 - val_loss: 1.8532 - val_actual_acc: 0.3677\n",
      "Epoch 137/500\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 1.9569 - actual_acc: 0.5981 - val_loss: 2.0294 - val_actual_acc: 0.3438\n",
      "Epoch 138/500\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 1.8592 - actual_acc: 0.6213 - val_loss: 2.0810 - val_actual_acc: 0.3052\n",
      "Epoch 139/500\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.2136 - actual_acc: 0.5487 - val_loss: 1.9316 - val_actual_acc: 0.3670\n",
      "Epoch 140/500\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 2.2056 - actual_acc: 0.5544 - val_loss: 1.8778 - val_actual_acc: 0.3576\n",
      "Epoch 141/500\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 1.9140 - actual_acc: 0.6188 - val_loss: 1.9742 - val_actual_acc: 0.3176\n",
      "Epoch 142/500\n",
      "100/100 [==============================] - 19s 194ms/step - loss: 1.8023 - actual_acc: 0.6238 - val_loss: 2.1344 - val_actual_acc: 0.2856\n",
      "Epoch 143/500\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.0157 - actual_acc: 0.6100 - val_loss: 2.1944 - val_actual_acc: 0.2594\n",
      "Epoch 144/500\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.9302 - actual_acc: 0.4044 - val_loss: 1.5024 - val_actual_acc: 0.4600\n",
      "Epoch 145/500\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 2.6430 - actual_acc: 0.4794 - val_loss: 1.4478 - val_actual_acc: 0.4978\n",
      "Epoch 146/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5002 - actual_acc: 0.5031 - val_loss: 2.1787 - val_actual_acc: 0.2660\n",
      "Epoch 147/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 2.1915 - actual_acc: 0.5744 - val_loss: 2.1471 - val_actual_acc: 0.2573\n",
      "Epoch 148/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 2.8939 - actual_acc: 0.4206 - val_loss: 1.7467 - val_actual_acc: 0.3648\n",
      "Epoch 149/500\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 2.5975 - actual_acc: 0.4838 - val_loss: 1.7999 - val_actual_acc: 0.3794\n",
      "Epoch 150/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.2473 - actual_acc: 0.5456 - val_loss: 1.8149 - val_actual_acc: 0.3837\n",
      "Epoch 151/500\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 2.1337 - actual_acc: 0.5706 - val_loss: 1.9844 - val_actual_acc: 0.3336\n",
      "Epoch 152/500\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 2.6295 - actual_acc: 0.4913 - val_loss: 1.8318 - val_actual_acc: 0.3394\n",
      "Epoch 153/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.7788 - actual_acc: 0.4231 - val_loss: 2.1316 - val_actual_acc: 0.3009\n",
      "Epoch 154/500\n",
      "100/100 [==============================] - 13s 129ms/step - loss: 2.4557 - actual_acc: 0.4988 - val_loss: 2.1838 - val_actual_acc: 0.2820\n",
      "Epoch 155/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1622 - actual_acc: 0.5525 - val_loss: 2.0069 - val_actual_acc: 0.3743\n",
      "Epoch 156/500\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 2.1223 - actual_acc: 0.5931 - val_loss: 1.9561 - val_actual_acc: 0.3815\n",
      "Epoch 157/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 3.1725 - actual_acc: 0.3700 - val_loss: 1.8642 - val_actual_acc: 0.3350\n",
      "Epoch 158/500\n",
      "100/100 [==============================] - 13s 126ms/step - loss: 2.8841 - actual_acc: 0.4312 - val_loss: 1.9049 - val_actual_acc: 0.3605\n",
      "Epoch 159/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.5278 - actual_acc: 0.4881 - val_loss: 1.7818 - val_actual_acc: 0.3983\n",
      "Epoch 160/500\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 2.3427 - actual_acc: 0.5356 - val_loss: 1.7427 - val_actual_acc: 0.3968\n",
      "Epoch 161/500\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 2.6969 - actual_acc: 0.4631 - val_loss: 1.6158 - val_actual_acc: 0.4055\n",
      "Epoch 162/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.4738 - actual_acc: 0.4881 - val_loss: 1.9728 - val_actual_acc: 0.3089\n",
      "Epoch 163/500\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 2.3529 - actual_acc: 0.5294 - val_loss: 1.9149 - val_actual_acc: 0.3372\n",
      "Epoch 164/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1994 - actual_acc: 0.5394 - val_loss: 1.5470 - val_actual_acc: 0.4688\n",
      "Epoch 165/500\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 2.5185 - actual_acc: 0.4850 - val_loss: 1.8483 - val_actual_acc: 0.3910\n",
      "Epoch 166/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.2685 - actual_acc: 0.3275 - val_loss: 2.0870 - val_actual_acc: 0.3328\n",
      "Epoch 167/500\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 2.8691 - actual_acc: 0.4250 - val_loss: 2.0271 - val_actual_acc: 0.3176\n",
      "Epoch 168/500\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 2.6433 - actual_acc: 0.4637 - val_loss: 2.0584 - val_actual_acc: 0.3067\n",
      "Epoch 169/500\n",
      "100/100 [==============================] - 8s 81ms/step - loss: 2.5965 - actual_acc: 0.5012 - val_loss: 1.9389 - val_actual_acc: 0.3074\n",
      "Epoch 170/500\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 3.3183 - actual_acc: 0.3556 - val_loss: 1.9154 - val_actual_acc: 0.3365\n",
      "Epoch 171/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 3.0684 - actual_acc: 0.3850 - val_loss: 1.8852 - val_actual_acc: 0.3510\n",
      "Epoch 172/500\n",
      "100/100 [==============================] - 13s 130ms/step - loss: 3.0290 - actual_acc: 0.4069 - val_loss: 1.9634 - val_actual_acc: 0.3081\n",
      "Epoch 173/500\n",
      "100/100 [==============================] - 16s 155ms/step - loss: 2.8264 - actual_acc: 0.4375 - val_loss: 1.9287 - val_actual_acc: 0.3634\n",
      "Epoch 174/500\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 2.8187 - actual_acc: 0.4244 - val_loss: 1.8435 - val_actual_acc: 0.2842\n",
      "Epoch 175/500\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 2.4622 - actual_acc: 0.4875 - val_loss: 1.8799 - val_actual_acc: 0.3249\n",
      "Epoch 176/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.1547 - actual_acc: 0.5588 - val_loss: 1.7327 - val_actual_acc: 0.3997\n",
      "Epoch 177/500\n",
      "100/100 [==============================] - 14s 142ms/step - loss: 2.0718 - actual_acc: 0.5812 - val_loss: 1.8787 - val_actual_acc: 0.3910\n",
      "Epoch 178/500\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 2.2630 - actual_acc: 0.5475 - val_loss: 1.9561 - val_actual_acc: 0.3205\n",
      "Epoch 179/500\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 3.0019 - actual_acc: 0.3813 - val_loss: 1.9010 - val_actual_acc: 0.3372\n",
      "Epoch 180/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.7576 - actual_acc: 0.4525 - val_loss: 1.8296 - val_actual_acc: 0.3648\n",
      "Epoch 181/500\n",
      "100/100 [==============================] - 13s 133ms/step - loss: 2.4655 - actual_acc: 0.5006 - val_loss: 2.0162 - val_actual_acc: 0.2776\n",
      "Epoch 182/500\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 2.3600 - actual_acc: 0.5350 - val_loss: 2.0535 - val_actual_acc: 0.3009\n",
      "Epoch 183/500\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 3.1257 - actual_acc: 0.3912 - val_loss: 2.1356 - val_actual_acc: 0.2871\n",
      "Epoch 184/500\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 3.0218 - actual_acc: 0.4025 - val_loss: 2.2229 - val_actual_acc: 0.2885\n",
      "Epoch 185/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.9042 - actual_acc: 0.4312 - val_loss: 1.9633 - val_actual_acc: 0.2951\n",
      "Epoch 186/500\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 2.6439 - actual_acc: 0.4625 - val_loss: 2.0879 - val_actual_acc: 0.2849\n",
      "Epoch 187/500\n",
      "100/100 [==============================] - 14s 138ms/step - loss: 2.9232 - actual_acc: 0.4050 - val_loss: 2.0740 - val_actual_acc: 0.2776\n",
      "Epoch 188/500\n",
      "100/100 [==============================] - 15s 153ms/step - loss: 3.0850 - actual_acc: 0.3806 - val_loss: 2.0468 - val_actual_acc: 0.3089\n",
      "Epoch 189/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 2.8830 - actual_acc: 0.4350 - val_loss: 1.9825 - val_actual_acc: 0.3154\n",
      "Epoch 190/500\n",
      "100/100 [==============================] - 13s 125ms/step - loss: 2.7304 - actual_acc: 0.4412 - val_loss: 2.1516 - val_actual_acc: 0.3096\n",
      "Epoch 191/500\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 2.7716 - actual_acc: 0.4450 - val_loss: 2.2720 - val_actual_acc: 0.3488\n",
      "Epoch 192/500\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 3.1173 - actual_acc: 0.3669 - val_loss: 1.9082 - val_actual_acc: 0.3169\n",
      "Epoch 193/500\n",
      "100/100 [==============================] - 16s 157ms/step - loss: 2.8459 - actual_acc: 0.4231 - val_loss: 2.1179 - val_actual_acc: 0.2914\n",
      "Epoch 194/500\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 2.6093 - actual_acc: 0.4819 - val_loss: 2.0452 - val_actual_acc: 0.2616\n",
      "Epoch 195/500\n",
      "100/100 [==============================] - 15s 148ms/step - loss: 2.4836 - actual_acc: 0.4906 - val_loss: 1.8550 - val_actual_acc: 0.3299\n",
      "Epoch 196/500\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 3.1254 - actual_acc: 0.3663 - val_loss: 1.6887 - val_actual_acc: 0.4062\n",
      "Epoch 197/500\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 3.2563 - actual_acc: 0.3277"
     ]
    }
   ],
   "source": [
    "class_weight = {0: 1.0,\n",
    "                 1: 1.62,\n",
    "                 2: 2.68,\n",
    "                 3: 3.36,\n",
    "                 4: 2.51,\n",
    "                 5: 1.53,\n",
    "                 6: 1.0,\n",
    "                 7: 1.37,\n",
    "                 8: 2.16,\n",
    "                 9: 2.61,\n",
    "                 10: 2.04,\n",
    "                 11: 1.3}\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log_dir\\\\' + model_name\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name + '.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.1,                              \n",
    "        patience=50, \n",
    "        min_lr=0.00001\n",
    "    )\n",
    "]\n",
    "\n",
    "steps_per_epoch = 100\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=500,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=int(round(steps_per_epoch/data_ratio*(1-data_ratio))),\n",
    "                            shuffle=True,\n",
    "                            class_weight=class_weight,\n",
    "                            callbacks=callbacks\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
