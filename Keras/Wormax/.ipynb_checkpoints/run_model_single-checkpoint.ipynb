{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_size = 10\n",
    "input_width = 160\n",
    "input_height = 100\n",
    "channels = 3\n",
    "class_number = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 98, 158, 32)       896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 16, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                6156      \n",
      "=================================================================\n",
      "Total params: 2,344,652\n",
      "Trainable params: 2,344,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import keras.backend as K\n",
    "def actual_acc(y_true, y_pred):\n",
    "    return K.equal(K.argmax(y_pred), K.argmax(y_true))\n",
    "\n",
    "model = load_model('models/worm_single_large_adam.h5',custom_objects={'actual_acc':actual_acc})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start/Pause action with Alt+T\n",
      "Start action in 3 sec.\n",
      "3\n",
      "2\n",
      "1\n",
      "action!\n",
      "Took 7077 ms\n",
      "Took 88 ms\n",
      "Took 40 ms\n",
      "Took 30 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 38 ms\n",
      "Took 28 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 42 ms\n",
      "Took 41 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 36 ms\n",
      "Took 31 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 37 ms\n",
      "Took 30 ms\n",
      "Took 33 ms\n",
      "Took 49 ms\n",
      "Took 37 ms\n",
      "Took 31 ms\n",
      "Took 43 ms\n",
      "Took 43 ms\n",
      "Took 32 ms\n",
      "Took 42 ms\n",
      "Took 55 ms\n",
      "Took 46 ms\n",
      "Took 67 ms\n",
      "Took 67 ms\n",
      "Took 50 ms\n",
      "Took 67 ms\n",
      "Took 84 ms\n",
      "Took 66 ms\n",
      "Took 50 ms\n",
      "Took 66 ms\n",
      "Took 50 ms\n",
      "Took 67 ms\n",
      "Took 66 ms\n",
      "Took 67 ms\n",
      "Took 67 ms\n",
      "Took 67 ms\n",
      "Took 100 ms\n",
      "Took 49 ms\n",
      "Took 50 ms\n",
      "Took 49 ms\n",
      "Took 42 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 45 ms\n",
      "Took 40 ms\n",
      "Took 43 ms\n",
      "Took 53 ms\n",
      "Took 38 ms\n",
      "Took 31 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 35 ms\n",
      "Took 40 ms\n",
      "Took 49 ms\n",
      "Took 56 ms\n",
      "Took 42 ms\n",
      "Took 30 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 46 ms\n",
      "Took 37 ms\n",
      "Took 33 ms\n",
      "Took 36 ms\n",
      "Took 31 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 47 ms\n",
      "Took 36 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 43 ms\n",
      "Took 48 ms\n",
      "Took 56 ms\n",
      "Took 43 ms\n",
      "Took 43 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 34 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 44 ms\n",
      "Took 40 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 32 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 32 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 34 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Took 33 ms\n",
      "Stop action, press Alt+T to continue\n"
     ]
    }
   ],
   "source": [
    "from screen_consts import WIDTH, HEIGHT, get_coordinates_from_direction\n",
    "from grabscreen import grab_screen\n",
    "from image_preproc import preproc_img\n",
    "from getkeys import key_check\n",
    "from image_preproc import prepare_image\n",
    "import win32api, win32con\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def mouse_down(x,y):\n",
    "    win32api.SetCursorPos((x,y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, x, y, 0, 0)\n",
    "\n",
    "def mouse_up(x, y):\n",
    "    win32api.SetCursorPos((x, y))\n",
    "    win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, x, y, 0, 0)\n",
    "\n",
    "    \n",
    "from PIL import ImageGrab\n",
    "def get_image():\n",
    "    img = np.array(ImageGrab.grab())\n",
    "    img = preproc_img(img)\n",
    "    return img\n",
    "\n",
    "#def get_image():\n",
    "#    img = grab_screen()\n",
    "#    img = preproc_img(img)\n",
    "#    return img\n",
    "\n",
    "class_number = 12\n",
    "img = grab_screen()\n",
    "scr_W, scr_H = len(img[0]), len(img)\n",
    "\n",
    "\n",
    "print(\"Start/Pause action with Alt+T\")\n",
    "paused = True\n",
    "    \n",
    "while True:\n",
    "    clock_prev = time.clock()\n",
    "    keys = key_check()\n",
    "    if \"ALT\" in keys and \"T\" in keys:\n",
    "        paused ^= 1\n",
    "        if paused:\n",
    "            print(\"Stop action, press Alt+T to continue\")\n",
    "        else:\n",
    "            print(\"Start action in 3 sec.\")\n",
    "            for i in list(range(3))[::-1]:\n",
    "                time.sleep(1)\n",
    "                print(i + 1)\n",
    "            print(\"action!\")\n",
    "        time.sleep(1)\n",
    "    if \"C\" in keys:\n",
    "        offset = -70\n",
    "        mouse_up(scr_W//2, scr_H//2+offset)\n",
    "        mouse_down(scr_W//2, scr_H//2+offset)\n",
    "        mouse_up(scr_W//2, scr_H//2+offset)\n",
    "        \n",
    "    img = get_image().reshape(-1,input_height, input_width,3)/255\n",
    "        \n",
    "    if not paused:              \n",
    "        prediction_raw = model.predict(img)\n",
    "        prediction = np.argmax(prediction_raw)\n",
    "        x, y = get_coordinates_from_direction(prediction, scr_W, scr_H, class_number)\n",
    "        mouse_up(x, y)\n",
    "        #print(np.round(model.predict(prep_img), 2), prediction)\n",
    "        #print('Took {} ms'.format(round((time.clock() - clock_prev)*1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIEW INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def grab_frame():\n",
    "    return get_image()\n",
    "\n",
    "#create two subplots\n",
    "gridsize = (2, 1)\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "ax1 = plt.subplot2grid(gridsize, (0, 0))\n",
    "\n",
    "#create two image plots\n",
    "im1 = ax1.imshow(grab_frame(), cmap='Greys_r')\n",
    "\n",
    "def update(i):    \n",
    "    im1.set_data(grab_frame())\n",
    "\n",
    "ani = FuncAnimation(plt.gcf(), update, interval=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
