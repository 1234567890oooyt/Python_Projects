{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRY\n",
    "top_k_categorical_accuracy\n",
    "https://stackoverflow.com/questions/47887533/keras-convolution-along-samples\n",
    "https://keras.io/layers/wrappers/#timedistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training for new target(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "input_width = 160\n",
    "input_height = 100\n",
    "channels = 3\n",
    "rotations_count = 2\n",
    "data_path = \"D:\\\\Python\\\\Keras\\\\Wormax\\\\data_prepared\\\\\"\n",
    "model_name = 'models/worm_single_regr_xception_7.h5'\n",
    "look_forward = 0\n",
    "use_rotation = True\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers, models, optimizers\n",
    "import keras.backend as K\n",
    "\n",
    "# Radians, please\n",
    "def mean_angle_error(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.abs(tf.atan2(tf.sin(y_true - y_pred), tf.cos(y_true - y_pred))))\n",
    "\n",
    "'''def define_model():\n",
    "    model = models.Sequential()\n",
    "        \n",
    "    model.add(layers.Convolution2D(32, (8, 8), strides=(2, 2), activation='relu',\n",
    "                            input_shape=(input_height, input_width, channels)))\n",
    "    model.add(layers.Convolution2D(32, (8, 8), activation='relu'))\n",
    "    model.add(layers.Convolution2D(64, (4, 4), strides=(2, 2), activation='relu'))\n",
    "    model.add(layers.Convolution2D(64, (4, 4), activation='relu'))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "           \n",
    "    model.compile(optimizer=optimizers.Adam(lr=5e-4),\n",
    "                  loss=mean_angle_error)\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def define_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(keras.applications.mobilenetv2.MobileNetV2(include_top=False, \n",
    "                                                       weights=None, \n",
    "                                                       input_tensor=None, \n",
    "                                                       input_shape=(input_height, input_width, channels), \n",
    "                                                       pooling=None))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(lr=1e-5),\n",
    "                  loss=mean_angle_error)\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_100 (Model) (None, 4, 5, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 15,366,209\n",
      "Trainable params: 15,332,097\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little prepocessing\n",
    "from math import atan2, pi\n",
    "import cv2\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return atan2(y, x)\n",
    "\n",
    "def get_direction(x, y, n_classes = 12):\n",
    "    return round(get_angle(x, y)/2/pi*n_classes)%n_classes\n",
    "\n",
    "# Rotating frame and direction counter-clockwise\n",
    "def get_rotated_frame(img, rotation, target_angle, rotations_count):\n",
    "    if rotation != 0:\n",
    "        rows, cols = len(img),len(img[0])\n",
    "        rot_M = cv2.getRotationMatrix2D((cols/2, rows/2), rotation*360/rotations_count, 1)\n",
    "        img = cv2.warpAffine(img, rot_M, (cols, rows))\n",
    "        target_angle = (target_angle + rotation/rotations_count*2*pi)%(2*pi)\n",
    "    return img, target_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Training and validation\n",
    "data_ratio = 0.7\n",
    "\n",
    "def generator(data_dir, rotations_count, role, shuffle=True, batch_size=128):\n",
    "    \n",
    "    listdir = []\n",
    "    listdir = filter(lambda x: os.path.isfile, os.listdir(data_dir))\n",
    "    listdir = np.array(list(listdir))\n",
    "    random.shuffle(listdir)\n",
    "    \n",
    "    #print('Found {} files for {}'.format(len(listdir), role))\n",
    "    \n",
    "    file_i = 0\n",
    "    while 1:\n",
    "        arr = np.load(data_dir + listdir[file_i])        \n",
    "        file_i = (file_i+1) if file_i+1<len(listdir) else 0\n",
    "        \n",
    "        # Expanding blocks\n",
    "        data = []        \n",
    "        for i in arr:\n",
    "            for j in i:\n",
    "                data.append(j)\n",
    "        data = np.array(data)\n",
    "\n",
    "        \n",
    "        if role == 'train':\n",
    "            data = data[:int(round(len(data)*data_ratio))]\n",
    "        elif role == 'validation':\n",
    "            data = data[int(round(len(data)*data_ratio)):]\n",
    "        else:\n",
    "            raise 'bad role parameter'\n",
    "        \n",
    "        # Generating y\n",
    "        data_targets = np.zeros((len(data)-look_forward))\n",
    "        for i in range(len(data_targets)):\n",
    "            data_targets[i] = get_angle(*data[i+look_forward][1][:2])\n",
    "            #data_targets[i] = np.array(to_categorical(get_direction(*data[i+look_forward][1][:2]), num_classes=num_classes))\n",
    "        data = data[:len(data)-look_forward]\n",
    "        \n",
    "        # Only X\n",
    "        data_features = np.zeros((len(data), input_height, input_width, channels))\n",
    "        for i in range(len(data)):\n",
    "            data_features[i] = data[i][0][0]\n",
    "        \n",
    "        indexes = np.arange(len(data_features)-look_forward)        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(indexes)\n",
    "        \n",
    "        # Rotating cycle(no rotation for validation)\n",
    "        rotate_times = rotations_count if role == 'train' and use_rotation else 1\n",
    "        for rot_i in range(rotate_times):\n",
    "            # Batches forming cycle\n",
    "            for i in range(0, len(data)-look_forward-batch_size, batch_size):\n",
    "                samples = data_features.take(indexes[i:i+batch_size], axis=0)\n",
    "                targets = data_targets.take(indexes[i:i+batch_size], axis=0)\n",
    "                samples_rot = np.zeros_like(samples)\n",
    "                targets_rot = np.zeros((batch_size))\n",
    "                \n",
    "                # Rotating\n",
    "                for j in range(batch_size):\n",
    "                    if use_rotation:\n",
    "                        rotation = (rot_i+j+i)%rotations_count\n",
    "                        img, target = get_rotated_frame(samples[j], rotation, targets[j], rotations_count)\n",
    "                    else:\n",
    "                        img, target = samples[j], targets[j]\n",
    "                    samples_rot[j] = img\n",
    "                    targets_rot[j] = target\n",
    "                    \n",
    "                # Normilize\n",
    "                samples_rot = samples_rot / 255\n",
    "                yield samples_rot, targets_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 100, 160, 3)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_generator = generator(data_path, rotations_count, 'train', batch_size=16)\n",
    "validation_generator = generator(data_path, rotations_count, 'validation', batch_size=32)\n",
    "\n",
    "print(next(train_generator)[0].shape)\n",
    "print(next(train_generator)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count class instances count for balancing\n",
    "if False:\n",
    "    i = 0\n",
    "    classes = np.zeros((class_number))\n",
    "    for samples, targets in generator(data_path, class_number, 'train', batch_size=1024):\n",
    "        for j in targets:\n",
    "            classes += j\n",
    "        i += 1\n",
    "        if i == 100:\n",
    "            break\n",
    "    print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### tensorboard --logdir=D:\\Python\\Keras\\Wormax\\log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "    1) make shuffled rotations\n",
    "    2) tune look_forward\n",
    "    3) change target to angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch = 0\n",
    "if not True:\n",
    "    model.load_weights(model_name)\n",
    "    initial_epoch = 176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.6024 - val_loss: 1.5868\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 1.5668 - val_loss: 1.5592\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 1.5764 - val_loss: 1.6206\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.5536 - val_loss: 1.5227s - loss: 1 - ETA: \n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5275 - val_loss: 1.5693\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5726 - val_loss: 1.6016\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5642 - val_loss: 1.6000\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 1.5138 - val_loss: 1.6006\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5817 - val_loss: 1.5361 loss: 1.59 - ETA: 3s -  - ETA: 1s - loss: \n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 1.5581 - val_loss: 1.5867\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5864 - val_loss: 1.5510\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5763 - val_loss: 1.5615\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5573 - val_loss: 1.5489\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5829 - val_loss: 1.5823\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5902 - val_loss: 1.5106\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5552 - val_loss: 1.5619\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 1.6002 - val_loss: 1.5639\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.6065 - val_loss: 1.6096\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5692 - val_loss: 1.5837 1s - los\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5841 - val_loss: 1.5731 loss: 1.5 - ETA: 2s - l\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5473 - val_loss: 1.6030\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.6096 - val_loss: 1.5648\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5728 - val_loss: 1.5580\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.6147 - val_loss: 1.5382\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5895 - val_loss: 1.5711\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.5720 - val_loss: 1.5774\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5516 - val_loss: 1.5792\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 1.5835 - val_loss: 1.5772A: 0s - loss: 1.\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5969 - val_loss: 1.5402A: 8s - loss: 1 - ETA: 7s - loss - ETA: 6s  - E\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.5747 - val_loss: 1.6235\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.5854 - val_loss: 1.5621\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.5599 - val_loss: 1.5419  - - ETA: 6s - \n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5553 - val_loss: 1.5671\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5740 - val_loss: 1.6039\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5460 - val_loss: 1.5931\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.6064 - val_loss: 1.5862\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5951 - val_loss: 1.5702\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5874 - val_loss: 1.6030\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5522 - val_loss: 1.5848\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 1.5969 - val_loss: 1.6002\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 1.5602 - val_loss: 1.5840\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5531 - val_loss: 1.6021: 1s - loss:\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 28s 275ms/step - loss: 1.5841 - val_loss: 1.5715\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5473 - val_loss: 1.6072\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.5779 - val_loss: 1.5873oss:  - ETA - ETA: 6 - ETA: 3s - loss: 1.5 - ETA: 2s - loss - ETA: 1s - loss: \n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 1.5686 - val_loss: 1.5736\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.5592 - val_loss: 1.5775\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5641 - val_loss: 1.6147\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5643 - val_loss: 1.5711\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.5873 - val_loss: 1.5829\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5548 - val_loss: 1.5723\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.6034 - val_loss: 1.5531\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5757 - val_loss: 1.5870\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 1.5697 - val_loss: 1.5753\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5634 - val_loss: 1.5626 - l\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5888 - val_loss: 1.5709\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 1.5690 - val_loss: 1.5995\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5404 - val_loss: 1.6057\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 1.5733 - val_loss: 1.5526\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5843 - val_loss: 1.5693\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5427 - val_loss: 1.5512\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5683 - val_loss: 1.5552\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 1.5209 - val_loss: 1.5975\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 1.5745 - val_loss: 1.5811\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5777 - val_loss: 1.5508\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5503 - val_loss: 1.6177\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5538 - val_loss: 1.5705\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5457 - val_loss: 1.5571\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5903 - val_loss: 1.5496\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 1.6046 - val_loss: 1.5565\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5387 - val_loss: 1.5848\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5939 - val_loss: 1.5546\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5724 - val_loss: 1.6191\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5813 - val_loss: 1.5235s: - ETA: 4s - l - ETA: 2s - loss: 1.59 - ETA: 1s - loss: 1.59 - ETA: 1s - loss:\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5647 - val_loss: 1.5341\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5971 - val_loss: 1.6054\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 1.5433 - val_loss: 1.5793\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.6069 - val_loss: 1.5659 - ETA: 4s - ETA: 1s - lo\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5801 - val_loss: 1.5339ETA: 4s - lo - ETA: 2s\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5686 - val_loss: 1.5382A: 8s - loss: 1 - ETA: 7s - l - ETA: 5s - loss: 1. \n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.6194 - val_loss: 1.5999\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5695 - val_loss: 1.5428\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5868 - val_loss: 1.6093\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5567 - val_loss: 1.5719\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5639 - val_loss: 1.5883\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5545 - val_loss: 1.5508 ETA: 0s - loss: 1.555\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5320 - val_loss: 1.5869\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5789 - val_loss: 1.5865\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5893 - val_loss: 1.5547\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5464 - val_loss: 1.6066 1\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5748 - val_loss: 1.5814\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5694 - val_loss: 1.5612\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.5584 - val_loss: 1.5384\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5650 - val_loss: 1.5120\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5840 - val_loss: 1.5765\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5578 - val_loss: 1.5771\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.5601 - val_loss: 1.5671\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5496 - val_loss: 1.5986\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 1.5714 - val_loss: 1.5543\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 1.5585 - val_loss: 1.5445\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5407 - val_loss: 1.5557ETA: 4s\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.5912 - val_loss: 1.5962\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5296 - val_loss: 1.5504: 0s - loss: 1.527 - ETA: 0s - loss: 1.5\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.5243 - val_loss: 1.5517\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5646 - val_loss: 1.6245ETA: 1s - loss\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5672 - val_loss: 1.5613\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5468 - val_loss: 1.5486ETA: 0s - loss: 1.\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5696 - val_loss: 1.5595\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5500 - val_loss: 1.5892\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5557 - val_loss: 1.5825\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5725 - val_loss: 1.5826ss:  - ETA: 7s - loss: 1.58 - ETA: 6s - loss: 1.588 - ETA: 6s - lo\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.5920 - val_loss: 1.5739\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5964 - val_loss: 1.5510\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 1.5425 - val_loss: 1.5700\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5883 - val_loss: 1.5290A: 2\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5624 - val_loss: 1.5707\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5320 - val_loss: 1.5227\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5420 - val_loss: 1.5730 - ETA: 3s -  - ETA: 1s - loss:\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.5638 - val_loss: 1.5627\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.5730 - val_loss: 1.6368\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.5698 - val_loss: 1.5947\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.5727 - val_loss: 1.5588\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5709 - val_loss: 1.5694\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 36s 363ms/step - loss: 1.5749 - val_loss: 1.5416\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5836 - val_loss: 1.6358\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5840 - val_loss: 1.5763ETA - ETA: - ETA: 2s - los - ETA: 0s - loss: 1.58 - ETA: 0s - loss: 1.58\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5950 - val_loss: 1.4895\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5406 - val_loss: 1.4963\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5567 - val_loss: 1.5268A: 1s - loss\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5715 - val_loss: 1.5466\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5581 - val_loss: 1.6094\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.6041 - val_loss: 1.6186\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.5679 - val_loss: 1.5804\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5834 - val_loss: 1.5367loss: 1.5\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.5933 - val_loss: 1.5734 1.583 - ETA: 2s - \n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5582 - val_loss: 1.5856\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5631 - val_loss: 1.6049\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5326 - val_loss: 1.6117\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.5730 - val_loss: 1.5454 1s - los\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5860 - val_loss: 1.5422\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5387 - val_loss: 1.5507\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5570 - val_loss: 1.5808\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.5393 - val_loss: 1.58202s -\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.5920 - val_loss: 1.5005\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5326 - val_loss: 1.6476\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 1.5852 - val_loss: 1.5967\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5934 - val_loss: 1.5766\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 34s 342ms/step - loss: 1.5993 - val_loss: 1.5791\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5514 - val_loss: 1.5904\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5653 - val_loss: 1.6078\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5489 - val_loss: 1.5853\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5829 - val_loss: 1.5864\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5836 - val_loss: 1.5782\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5796 - val_loss: 1.5729\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 1.5527 - val_loss: 1.5709\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5374 - val_loss: 1.5541\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5636 - val_loss: 1.5799ETA: 2s \n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5298 - val_loss: 1.6138\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5647 - val_loss: 1.6586\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5592 - val_loss: 1.5778\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5512 - val_loss: 1.6370ETA: 3s - loss: - ETA: 1s - lo\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.6003 - val_loss: 1.6075 2s - loss: 1 - ETA: 1s - loss:\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.5294 - val_loss: 1.5585 4\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.5752 - val_loss: 1.5332\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5714 - val_loss: 1.6009\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5476 - val_loss: 1.6084A: 3s - loss: 1.55 - ETA: \n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5713 - val_loss: 1.6438\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.5956 - val_loss: 1.5991\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5718 - val_loss: 1.5789\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.6025 - val_loss: 1.5475\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.5537 - val_loss: 1.5131\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 23s 227ms/step - loss: 1.5606 - val_loss: 1.5377\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5366 - val_loss: 1.6182\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5731 - val_loss: 1.5799s: 1\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5801 - val_loss: 1.5557\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5418 - val_loss: 1.5968\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5655 - val_loss: 1.5669\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 1.5547 - val_loss: 1.5975\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.5866 - val_loss: 1.5740l\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5827 - val_loss: 1.5521\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5031 - val_loss: 1.5560- loss: 1.519 - ETA:\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.4890 - val_loss: 1.5475\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5311 - val_loss: 1.5552\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5147 - val_loss: 1.5689\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.4726 - val_loss: 1.6008\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5118 - val_loss: 1.5439\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5406 - val_loss: 1.5775\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5760 - val_loss: 1.5311\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5432 - val_loss: 1.5316\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5821 - val_loss: 1.5330: 4s - loss: 1 - ETA: 3s - - ETA: 0s - loss: 1.\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.5546 - val_loss: 1.5902\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.5381 - val_loss: 1.5145\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 1.5702 - val_loss: 1.5841\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5941 - val_loss: 1.5414: 0s - loss: 1.5\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5457 - val_loss: 1.5926\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5327 - val_loss: 1.5758\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5837 - val_loss: 1.5702\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5368 - val_loss: 1.5905A: 2s - loss: - ETA: 1s - los\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5316 - val_loss: 1.5189\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5623 - val_loss: 1.5544\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5918 - val_loss: 1.5781ETA: 3s - loss - ETA: 2s - \n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5796 - val_loss: 1.5458\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5747 - val_loss: 1.5457\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5606 - val_loss: 1.5232\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 1.5658 - val_loss: 1.5959TA: 0s - loss: 1.\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.5708 - val_loss: 1.5614oss: 1.575 - ETA: 0s - loss: 1.574\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5980 - val_loss: 1.5875\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.6016 - val_loss: 1.5614\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5798 - val_loss: 1.5934\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 32s 322ms/step - loss: 1.5784 - val_loss: 1.6062\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5333 - val_loss: 1.5828\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5886 - val_loss: 1.6144 loss\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5787 - val_loss: 1.6230A: 11s  -  - ETA: 5s - lo - ETA: 4s - loss: 1 - ETA: \n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5970 - val_loss: 1.5775\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5688 - val_loss: 1.5967\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 1.5712 - val_loss: 1.5577\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5556 - val_loss: 1.5610\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5706 - val_loss: 1.5451\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.5768 - val_loss: 1.57481s - loss: 1 - ETA: 0s - loss: 1.574\n",
      "Epoch 220/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5788 - val_loss: 1.5535\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.6126 - val_loss: 1.5759 5s - loss - ETA\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5838 - val_loss: 1.6051s: 1 - ETA: 1s - loss\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5603 - val_loss: 1.5830\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5689 - val_loss: 1.5607TA: 2s - l\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5933 - val_loss: 1.5798\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5774 - val_loss: 1.5556\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5328 - val_loss: 1.5559\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5652 - val_loss: 1.5254\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5628 - val_loss: 1.5802\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5272 - val_loss: 1.5962\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5624 - val_loss: 1.5712\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5413 - val_loss: 1.5676\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5766 - val_loss: 1.5109\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5888 - val_loss: 1.5934- ETA: 1s - loss:\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5439 - val_loss: 1.6056\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5521 - val_loss: 1.5750\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5789 - val_loss: 1.5504\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5952 - val_loss: 1.5518\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.5845 - val_loss: 1.5972\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5069 - val_loss: 1.5420ETA: 11s - loss:  - ETA: 1 - ETA: 9s - l - ETA: 7\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 1.5459 - val_loss: 1.5567\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5573 - val_loss: 1.5327\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.5603 - val_loss: 1.5128\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5759 - val_loss: 1.6607\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.6003 - val_loss: 1.6011\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5526 - val_loss: 1.5579\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.5723 - val_loss: 1.5621\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5509 - val_loss: 1.5544\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5903 - val_loss: 1.5705TA: 3s - loss - ETA: 2s - l - ETA: 0s - loss: 1.589\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5692 - val_loss: 1.5757\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5871 - val_loss: 1.5412\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5416 - val_loss: 1.5668oss: 1.52 - ETA: 9s - loss: 1.5 - ETA: 9s  - ETA: 6s - lo\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5836 - val_loss: 1.5558\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.5735 - val_loss: 1.5463\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5554 - val_loss: 1.5894TA: 1s - loss: 1.\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.5714 - val_loss: 1.5675\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5882 - val_loss: 1.5449\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5579 - val_loss: 1.6020A: 2s - \n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.5806 - val_loss: 1.6288\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 1.5351 - val_loss: 1.5621\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5976 - val_loss: 1.5606\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5901 - val_loss: 1.5505ETA: 1s - lo\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.5509 - val_loss: 1.5524\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5384 - val_loss: 1.5577\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5889 - val_loss: 1.5603\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 1.5880 - val_loss: 1.5525\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 1.5901 - val_loss: 1.5666\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.5778 - val_loss: 1.5572A:  - ETA: 0s - loss: 1\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5903 - val_loss: 1.5339\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.5777 - val_loss: 1.5110ss: - ETA: \n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 1.5808 - val_loss: 1.5501\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5407 - val_loss: 1.5744\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5581 - val_loss: 1.5421A: 2s - loss: 1. - ETA: 2s - l\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5520 - val_loss: 1.5655\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5649 - val_loss: 1.5900\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.6037 - val_loss: 1.5732\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5638 - val_loss: 1.5495\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5258 - val_loss: 1.5541A: 9s - loss: 1.50 -\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 35s 353ms/step - loss: 1.6009 - val_loss: 1.5831\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5161 - val_loss: 1.5350\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5646 - val_loss: 1.5755ETA: 0s - loss: 1.561\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5725 - val_loss: 1.5340\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5582 - val_loss: 1.5367\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5648 - val_loss: 1.5639\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.6147 - val_loss: 1.6029oss: - ETA: 0s - loss: 1.6\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5475 - val_loss: 1.5845\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5646 - val_loss: 1.5356\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5688 - val_loss: 1.5228\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.5686 - val_loss: 1.5533ETA: 12s - loss:  - ETA: 11s - loss - ETA: 11 - ETA: 4s - loss: 1 - ETA:\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.6112 - val_loss: 1.5705\n",
      "Epoch 291/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5685 - val_loss: 1.5587\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5595 - val_loss: 1.5739A: 6s -  - ETA: 3s - - ETA: 1s - loss\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5406 - val_loss: 1.59234s - - ETA: 2s - loss: 1.540 - ETA: 2s - loss: 1.53 - ETA: 1s - lo\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.5604 - val_loss: 1.5522\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 1.5820 - val_loss: 1.5806ss: 1.58\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 33s 331ms/step - loss: 1.5615 - val_loss: 1.5677\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5443 - val_loss: 1.5432\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5516 - val_loss: 1.5361- loss: 1.5 - ETA: 2s - l - ETA: 0s - loss: 1.5\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5858 - val_loss: 1.6392\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5612 - val_loss: 1.6044\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5829 - val_loss: 1.5510\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5623 - val_loss: 1.5841\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5755 - val_loss: 1.5356\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 33s 330ms/step - loss: 1.5694 - val_loss: 1.5800\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5553 - val_loss: 1.5932\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 1.5899 - val_loss: 1.5708\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.6169 - val_loss: 1.6394\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.5833 - val_loss: 1.5598\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5927 - val_loss: 1.5114\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5385 - val_loss: 1.5148A: 7 -\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.5522 - val_loss: 1.5568ETA: 0s - loss: 1.54\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5472 - val_loss: 1.5718\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5910 - val_loss: 1.5644  - ETA: 2s - \n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5866 - val_loss: 1.5677: 4s - loss: 1 - ETA: 3s - l - ETA: 1s - lo\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5519 - val_loss: 1.5377- loss: 1. - ETA: 5s - - ETA:\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 1.5565 - val_loss: 1.5392\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.5658 - val_loss: 1.6020\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5667 - val_loss: 1.6005\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 33s 332ms/step - loss: 1.5777 - val_loss: 1.5503\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5513 - val_loss: 1.5640\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5818 - val_loss: 1.5735\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5330 - val_loss: 1.5971 - loss: - ETA: 0s - loss: 1.5\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5557 - val_loss: 1.6154 10s - - E\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.6010 - val_loss: 1.6193ETA:\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.5352 - val_loss: 1.5773\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5806 - val_loss: 1.5727\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 35s 354ms/step - loss: 1.5860 - val_loss: 1.5629\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5375 - val_loss: 1.6161\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 1.5474 - val_loss: 1.5229\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.5786 - val_loss: 1.6039\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.5381 - val_loss: 1.5842\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.5955 - val_loss: 1.5693\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5904 - val_loss: 1.5577ss: 1.57 - ETA: 6s - lo\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5455 - val_loss: 1.5449ss: 1.54\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 34s 339ms/step - loss: 1.5644 - val_loss: 1.6042- ETA: 1s - loss: \n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5560 - val_loss: 1.5994 11s - lo - E - ETA: 1s - lo\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5572 - val_loss: 1.5727\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5769 - val_loss: 1.5740\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.5791 - val_loss: 1.5485\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5204 - val_loss: 1.5713:  - - ETA: 1s - loss:\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 1.5869 - val_loss: 1.5776\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5464 - val_loss: 1.5742\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5630 - val_loss: 1.5566\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5753 - val_loss: 1.5603\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5515 - val_loss: 1.5979\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5353 - val_loss: 1.6043TA: 3s - loss:  - ETA: 2s -\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5617 - val_loss: 1.5504\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5391 - val_loss: 1.5917\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 1.5415 - val_loss: 1.5576s - los\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5655 - val_loss: 1.5573 ETA: 2s - loss: 1.5 - ETA: 2s - loss - ETA: 0s - loss: 1.\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5455 - val_loss: 1.6058\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.6049 - val_loss: 1.5618TA: 3s - loss: 1.589 - ETA: 3s - loss: 1.59 - ETA: 2s - loss: 1 - ETA: 2s - loss: 1.612 - ETA: 1s - lo\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5759 - val_loss: 1.5446\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.6118 - val_loss: 1.5723\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5948 - val_loss: 1.5251\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.6151 - val_loss: 1.5868\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.5357 - val_loss: 1.5678ss: 1.5\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 1.5470 - val_loss: 1.6093\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5410 - val_loss: 1.5784\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5732 - val_loss: 1.5819\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.6290 - val_loss: 1.5929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/1000\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.5681 - val_loss: 1.5647\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5555 - val_loss: 1.5843\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5947 - val_loss: 1.5757 1 - ETA: 0s - loss: 1.59\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.5424 - val_loss: 1.57457s - ETA: 4s - loss: 1.550 - ETA: 4s - loss - ETA: 2s - loss: 1. - ETA: 1s - lo\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.5781 - val_loss: 1.5456\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.5837 - val_loss: 1.5665\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.6081 - val_loss: 1.5416\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.5757 - val_loss: 1.5996\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5676 - val_loss: 1.5854\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5799 - val_loss: 1.5891\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 1.5547 - val_loss: 1.5688\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.5596 - val_loss: 1.5711\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5435 - val_loss: 1.6181l\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5762 - val_loss: 1.553473\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5517 - val_loss: 1.6093A: 2s - loss: - ETA: 0s - loss: 1.\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5868 - val_loss: 1.56340s - loss: 1\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5546 - val_loss: 1.5514\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 1.5778 - val_loss: 1.5690 - ETA: 1s - loss: \n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.6080 - val_loss: 1.5279\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5511 - val_loss: 1.5519\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5846 - val_loss: 1.5851\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 31s 305ms/step - loss: 1.6106 - val_loss: 1.5966\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5868 - val_loss: 1.5211\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5698 - val_loss: 1.5871\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5495 - val_loss: 1.5665\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5699 - val_loss: 1.6129\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5576 - val_loss: 1.5690 - loss: 1.\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 1.5635 - val_loss: 1.5671ET - ETA\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5589 - val_loss: 1.5464\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.6182 - val_loss: 1.6044\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5398 - val_loss: 1.5934\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5477 - val_loss: 1.5285\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.5608 - val_loss: 1.5799\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 1.5978 - val_loss: 1.5756\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.6000 - val_loss: 1.5696\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5932 - val_loss: 1.5682A: 1s - los\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5364 - val_loss: 1.5828\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5360 - val_loss: 1.5593\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.6001 - val_loss: 1.5455\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5957 - val_loss: 1.5596- ETA: 5s - loss - ETA: 3 - ETA: 0s - loss: 1\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.5837 - val_loss: 1.5683\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5924 - val_loss: 1.6028\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5848 - val_loss: 1.5888\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5598 - val_loss: 1.6177\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 1.5687 - val_loss: 1.5760\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5930 - val_loss: 1.5773\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.5816 - val_loss: 1.6104\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5706 - val_loss: 1.5916A: 0s - loss: 1\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5316 - val_loss: 1.5340\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5846 - val_loss: 1.5684\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5549 - val_loss: 1.5675ETA: 2\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5725 - val_loss: 1.5647\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.5818 - val_loss: 1.6018\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5842 - val_loss: 1.5768\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5560 - val_loss: 1.5127\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.6147 - val_loss: 1.5614\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 30s 295ms/step - loss: 1.5457 - val_loss: 1.5947\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5379 - val_loss: 1.5999\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.6248 - val_loss: 1.5828\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5620 - val_loss: 1.6008 1.56\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5593 - val_loss: 1.5703\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5779 - val_loss: 1.5544\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5571 - val_loss: 1.5443\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5827 - val_loss: 1.5302\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 1.5621 - val_loss: 1.5939A: 0s - loss: 1.56\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 1.5527 - val_loss: 1.5723\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5500 - val_loss: 1.5922- loss: 1. - ETA: 1s - loss: \n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.6060 - val_loss: 1.5771\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5811 - val_loss: 1.5627\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5900 - val_loss: 1.5596\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5872 - val_loss: 1.5825\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5958 - val_loss: 1.5700\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5460 - val_loss: 1.5946s  - ETA: 1s - loss: 1.\n",
      "Epoch 435/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 26s 262ms/step - loss: 1.5499 - val_loss: 1.5705\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 1.5650 - val_loss: 1.5530loss: 1.548 - ETA: 3s - los - ETA: 1s - lo\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5819 - val_loss: 1.5693\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.5447 - val_loss: 1.5895\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5894 - val_loss: 1.5588\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.5479 - val_loss: 1.5455\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5505 - val_loss: 1.6309\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 35s 355ms/step - loss: 1.5258 - val_loss: 1.5534\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5503 - val_loss: 1.5970\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5338 - val_loss: 1.5326o - ETA: 5s - loss: 1 - \n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5573 - val_loss: 1.5686\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5824 - val_loss: 1.5784\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5397 - val_loss: 1.5966\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5599 - val_loss: 1.5549\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5634 - val_loss: 1.5693\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 35s 349ms/step - loss: 1.5621 - val_loss: 1.5701\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5267 - val_loss: 1.5642\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.6088 - val_loss: 1.5860\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5907 - val_loss: 1.5271\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.5678 - val_loss: 1.6036\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5951 - val_loss: 1.60585798 - ETA: 4s - ETA: 2s - l\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5890 - val_loss: 1.6135\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5868 - val_loss: 1.5217TA: 0s - loss: 1.58\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5944 - val_loss: 1.5419\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5783 - val_loss: 1.5862\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 1.5530 - val_loss: 1.5303oss: - ETA: 1s - loss:\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5998 - val_loss: 1.6010\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 1.5703 - val_loss: 1.5216\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5975 - val_loss: 1.5341\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5532 - val_loss: 1.5286ETA: 8s - loss: 1.51 - ETA\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 34s 343ms/step - loss: 1.5648 - val_loss: 1.5476 ETA - ETA: 1s - loss:\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5706 - val_loss: 1.5937s - - ETA: 0s - loss: 1\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 1.5882 - val_loss: 1.5848ETA:  - ETA: 1s - loss:\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5951 - val_loss: 1.6071\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5954 - val_loss: 1.5614\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5991 - val_loss: 1.5669\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5852 - val_loss: 1.5807\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5804 - val_loss: 1.5768\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 35s 346ms/step - loss: 1.6108 - val_loss: 1.5770\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5618 - val_loss: 1.5235\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 1.5827 - val_loss: 1.5702\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5693 - val_loss: 1.5564\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5645 - val_loss: 1.5702\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5903 - val_loss: 1.58692s - l\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 31s 310ms/step - loss: 1.5773 - val_loss: 1.6052\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5299 - val_loss: 1.5597\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 36s 363ms/step - loss: 1.5673 - val_loss: 1.5567\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5681 - val_loss: 1.5512A: 0s - loss: 1.56\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.6089 - val_loss: 1.5585\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5557 - val_loss: 1.6126\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5930 - val_loss: 1.5794\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5520 - val_loss: 1.5684\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 28s 280ms/step - loss: 1.5513 - val_loss: 1.5628\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5973 - val_loss: 1.5488\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5875 - val_loss: 1.5903\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5591 - val_loss: 1.5878\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5639 - val_loss: 1.5152\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5489 - val_loss: 1.5457TA: 8s - los - ETA: 2s - \n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5646 - val_loss: 1.5823A: 11 - ETA: - ETA: 2s\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5470 - val_loss: 1.5497\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5510 - val_loss: 1.5622\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 36s 358ms/step - loss: 1.5823 - val_loss: 1.5904\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5645 - val_loss: 1.6133\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.6220 - val_loss: 1.5831\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5586 - val_loss: 1.5533\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.5740 - val_loss: 1.5911\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5635 - val_loss: 1.5174\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5817 - val_loss: 1.5788\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5588 - val_loss: 1.5502A: 0s - loss: 1.\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 34s 342ms/step - loss: 1.5357 - val_loss: 1.5437\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5749 - val_loss: 1.5888\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5258 - val_loss: 1.5788\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5823 - val_loss: 1.5559\n",
      "Epoch 508/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 231ms/step - loss: 1.5685 - val_loss: 1.5396\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.6019 - val_loss: 1.5390\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.5677 - val_loss: 1.5444TA: 2s - loss\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 1.5807 - val_loss: 1.6224\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5403 - val_loss: 1.5996\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5649 - val_loss: 1.5676 loss: 1. - ETA: 1s - loss:\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5595 - val_loss: 1.5815\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.6065 - val_loss: 1.5524loss: 1\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5974 - val_loss: 1.5514: \n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5542 - val_loss: 1.5972\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5877 - val_loss: 1.5505\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.5934 - val_loss: 1.5891\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5375 - val_loss: 1.5961 4s - loss - ETA: 2s\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5952 - val_loss: 1.5631\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5853 - val_loss: 1.5724\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5386 - val_loss: 1.5813\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5304 - val_loss: 1.5456A: 13s  - ETA: 12s -  - ETA: 1\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5584 - val_loss: 1.5546\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5747 - val_loss: 1.5521ETA: 0s - loss: 1.5\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5790 - val_loss: 1.5560A: 7s -\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5538 - val_loss: 1.5548\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5508 - val_loss: 1.5590\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5951 - val_loss: 1.5915\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5765 - val_loss: 1.5766\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5742 - val_loss: 1.5453\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 1.5278 - val_loss: 1.5538 - ETA: 6s - loss\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.6016 - val_loss: 1.5670 ETA: 0s - loss: 1.60\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 1.5830 - val_loss: 1.5710\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 1.5520 - val_loss: 1.6215\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5399 - val_loss: 1.5665\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 28s 284ms/step - loss: 1.5669 - val_loss: 1.58001s - loss: 1.57 - ETA: 1s - loss: \n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5951 - val_loss: 1.5870\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.6159 - val_loss: 1.6264\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.6072 - val_loss: 1.6144\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5584 - val_loss: 1.5787\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5740 - val_loss: 1.5284\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5865 - val_loss: 1.5574\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.5982 - val_loss: 1.5881\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 1.5461 - val_loss: 1.5807\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5563 - val_loss: 1.5806\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.5566 - val_loss: 1.5866\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.5650 - val_loss: 1.6033\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.5526 - val_loss: 1.5303\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.6238 - val_loss: 1.5330TA: 5s - loss: 1.634 - ETA: 5s - loss: 1. -\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.5864 - val_loss: 1.5645: 1s - loss: 1.59 - ETA: 1s - loss:\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5460 - val_loss: 1.5599\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 1.5668 - val_loss: 1.5579\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.6175 - val_loss: 1.58141.61\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 30s 298ms/step - loss: 1.5922 - val_loss: 1.5769s - lo\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5426 - val_loss: 1.5718\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 36s 356ms/step - loss: 1.5486 - val_loss: 1.5124\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5457 - val_loss: 1.5949\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5464 - val_loss: 1.6072\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5461 - val_loss: 1.6023loss:  - ETA: 0s - loss: 1.548\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5683 - val_loss: 1.5766\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.6139 - val_loss: 1.5847\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5656 - val_loss: 1.5887\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 1.6037 - val_loss: 1.5729\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 1.5549 - val_loss: 1.6094\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5657 - val_loss: 1.5786\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5548 - val_loss: 1.5536\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.5696 - val_loss: 1.5474\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.6004 - val_loss: 1.6037\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.6028 - val_loss: 1.5623\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5542 - val_loss: 1.6070\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 30s 296ms/step - loss: 1.5819 - val_loss: 1.5561 ETA: 1s - loss: \n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5754 - val_loss: 1.5680\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5679 - val_loss: 1.5631\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5547 - val_loss: 1.5883\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5802 - val_loss: 1.5566\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5666 - val_loss: 1.5808\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 1.5709 - val_loss: 1.5635\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5881 - val_loss: 1.5620\n",
      "Epoch 581/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 246ms/step - loss: 1.5732 - val_loss: 1.5710\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 32s 319ms/step - loss: 1.5619 - val_loss: 1.5603: 0s - loss: 1.\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5899 - val_loss: 1.5786ETA: 3s  - ETA: 0s - loss: 1.\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 31s 311ms/step - loss: 1.5473 - val_loss: 1.5721s -  - ETA - ETA: 2s - l\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5542 - val_loss: 1.5281\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.6001 - val_loss: 1.6041\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5599 - val_loss: 1.5748\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5765 - val_loss: 1.5705\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 1.5837 - val_loss: 1.5293\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 27s 274ms/step - loss: 1.5704 - val_loss: 1.5717\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 1.5978 - val_loss: 1.5383\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5435 - val_loss: 1.5399: 1.54 - ETA: 2s - l\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5435 - val_loss: 1.5628\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 29s 294ms/step - loss: 1.5773 - val_loss: 1.5664\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5827 - val_loss: 1.5887\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5511 - val_loss: 1.5433\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5613 - val_loss: 1.6116\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 1.6003 - val_loss: 1.5956s - loss\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.5821 - val_loss: 1.5631\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 29s 288ms/step - loss: 1.5814 - val_loss: 1.6198TA: 2s - \n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5591 - val_loss: 1.5657\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.5777 - val_loss: 1.5773\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5861 - val_loss: 1.6167oss: 1.5 - ETA:  - ETA: 4s -  - ETA: 2s \n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5712 - val_loss: 1.5171\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5895 - val_loss: 1.5650 0s - loss: 1.59\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 1.5915 - val_loss: 1.6107oss: 1\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5715 - val_loss: 1.5172A: 2s - l\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 1.5414 - val_loss: 1.5835\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5580 - val_loss: 1.5706\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.6186 - val_loss: 1.5521\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 28s 285ms/step - loss: 1.5777 - val_loss: 1.5624\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5885 - val_loss: 1.5802\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 1.5782 - val_loss: 1.6506\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5542 - val_loss: 1.6028\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5865 - val_loss: 1.5891 - loss\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5670 - val_loss: 1.5559- ETA: 2s - loss: 1.574 - ETA: 2s - loss: 1.574 - ETA: 2s - l\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5552 - val_loss: 1.5476\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5807 - val_loss: 1.5583\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 29s 289ms/step - loss: 1.5937 - val_loss: 1.5415\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 22s 217ms/step - loss: 1.5534 - val_loss: 1.5845\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 38s 377ms/step - loss: 1.5311 - val_loss: 1.5588\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 21s 208ms/step - loss: 1.6002 - val_loss: 1.5389\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.6132 - val_loss: 1.5736\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5298 - val_loss: 1.5817ETA: 1s - loss: \n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 30s 303ms/step - loss: 1.5805 - val_loss: 1.5627\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5651 - val_loss: 1.5641\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 30s 299ms/step - loss: 1.5548 - val_loss: 1.59898s - - ETA: 1s - loss: \n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.6052 - val_loss: 1.5725\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 32s 323ms/step - loss: 1.5348 - val_loss: 1.6125\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.6477 - val_loss: 1.5828\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 27s 272ms/step - loss: 1.5828 - val_loss: 1.5380\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5928 - val_loss: 1.5404\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 27s 275ms/step - loss: 1.6013 - val_loss: 1.6119\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 1.5521 - val_loss: 1.5884\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 37s 367ms/step - loss: 1.5604 - val_loss: 1.5938 4s - loss:  - ETA: 2s - l\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5317 - val_loss: 1.5779\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5799 - val_loss: 1.5835\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5900 - val_loss: 1.6074\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5340 - val_loss: 1.5562\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5686 - val_loss: 1.5783-  - ET - ETA: 0s - loss: 1.564\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 1.6001 - val_loss: 1.5485oss: 1.60\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.5729 - val_loss: 1.5938\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 1.5556 - val_loss: 1.5672- ETA: 6s - \n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5826 - val_loss: 1.5504\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5426 - val_loss: 1.5865\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.5795 - val_loss: 1.5571\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5708 - val_loss: 1.6071loss:  - ETA: 1s - loss: 1.57 - ETA: 1s - loss: \n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5609 - val_loss: 1.5726\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5979 - val_loss: 1.5344\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 30s 304ms/step - loss: 1.5659 - val_loss: 1.5864E - ETA: 1s - loss: 1.567 - ETA: 1s - loss:\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5693 - val_loss: 1.5828\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 1.5772 - val_loss: 1.5719\n",
      "Epoch 653/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 253ms/step - loss: 1.5937 - val_loss: 1.5745\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 1.5613 - val_loss: 1.5811\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 1.6106 - val_loss: 1.5762\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5877 - val_loss: 1.4830 loss: 1 - ETA: 0s - loss: 1.5\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 1.5359 - val_loss: 1.5744\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5350 - val_loss: 1.6186\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5786 - val_loss: 1.5202\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 27s 269ms/step - loss: 1.5468 - val_loss: 1.5758\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 28s 279ms/step - loss: 1.5627 - val_loss: 1.6041\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5788 - val_loss: 1.6048 11s - lo - ET - ETA: 6s - los - ETA: 4s - loss: 1.59 - ETA: 4s - loss: 1 - ETA: 3s - ETA: 0s - loss: 1.\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 29s 291ms/step - loss: 1.5376 - val_loss: 1.5880\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5250 - val_loss: 1.5376\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.5918 - val_loss: 1.5873\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 1.5734 - val_loss: 1.5796\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 28s 283ms/step - loss: 1.6102 - val_loss: 1.5485\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5398 - val_loss: 1.5893\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 30s 300ms/step - loss: 1.5759 - val_loss: 1.6012\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 21s 214ms/step - loss: 1.5330 - val_loss: 1.5422\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 1.5556 - val_loss: 1.5902\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5912 - val_loss: 1.6137ETA: 9s - loss: 1  - ETA: - ETA: 0s - loss: 1.58\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 30s 301ms/step - loss: 1.5625 - val_loss: 1.5327\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 29s 295ms/step - loss: 1.5789 - val_loss: 1.5523\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5437 - val_loss: 1.5563\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5698 - val_loss: 1.5687A: 0s - loss: 1.\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 1.5839 - val_loss: 1.5646\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5878 - val_loss: 1.5215\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.5379 - val_loss: 1.5673TA: 1s - lo\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5508 - val_loss: 1.5473\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 1.5766 - val_loss: 1.5656\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 33s 333ms/step - loss: 1.5950 - val_loss: 1.5629\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5653 - val_loss: 1.5416\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 1.5768 - val_loss: 1.5504\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5356 - val_loss: 1.5680\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 28s 282ms/step - loss: 1.5674 - val_loss: 1.5858\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 22s 216ms/step - loss: 1.6065 - val_loss: 1.5481\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5702 - val_loss: 1.5849\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 1.5489 - val_loss: 1.5897\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 34s 338ms/step - loss: 1.5908 - val_loss: 1.5201ss: 1.589\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 22s 215ms/step - loss: 1.5644 - val_loss: 1.5664\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 1.5570 - val_loss: 1.5919\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 1.5595 - val_loss: 1.5707\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 1.5633 - val_loss: 1.5949\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 21s 207ms/step - loss: 1.5826 - val_loss: 1.5243\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 29s 287ms/step - loss: 1.6111 - val_loss: 1.5464\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 1.5983 - val_loss: 1.5841\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 39s 390ms/step - loss: 1.5534 - val_loss: 1.5884 4s\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5081 - val_loss: 1.5644\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 9744s 97s/step - loss: 1.5808 - val_loss: 1.6047\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 21s 215ms/step - loss: 1.5851 - val_loss: 1.5532A: 7 - ETA: 3s - - ETA: 1s - loss\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 1.5704 - val_loss: 1.5566\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 21s 206ms/step - loss: 1.5663 - val_loss: 1.5871 - loss: - ETA: 0s - loss: 1.57 - ETA: 0s - loss: 1.5\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 28s 278ms/step - loss: 1.6136 - val_loss: 1.6017\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 1.5873 - val_loss: 1.6126\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 35s 352ms/step - loss: 1.5404 - val_loss: 1.5764ETA - ETA: 15s -   \n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 21s 210ms/step - loss: 1.5798 - val_loss: 1.5829\n",
      "Epoch 708/1000\n",
      " 15/100 [===>..........................] - ETA: 15s - loss: 1.4062"
     ]
    }
   ],
   "source": [
    "'''class_weight = {0: 1.15,\n",
    "                 1: 1.13,\n",
    "                 2: 1.27,\n",
    "                 3: 1.51,\n",
    "                 4: 1.46,\n",
    "                 5: 1.19,\n",
    "                 6: 1.0,\n",
    "                 7: 1.04,\n",
    "                 8: 1.11,\n",
    "                 9: 1.2,\n",
    "                 10: 1.27,\n",
    "                 11: 1.34}'''\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='log_dir\\\\' + model_name\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_name,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    )\n",
    "    \n",
    "]\n",
    "'''keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', \n",
    "        factor=0.5,                              \n",
    "        patience=70, \n",
    "        min_lr=0.00001\n",
    "    )'''\n",
    "\n",
    "steps_per_epoch = 100\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=1000,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=int(round(steps_per_epoch/data_ratio*(1-data_ratio))),\n",
    "                            shuffle=True,\n",
    "                            #class_weight=class_weight,\n",
    "                            callbacks=callbacks,\n",
    "                            initial_epoch=initial_epoch\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
