{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TRY\n",
    "top_k_categorical_accuracy\n",
    "https://stackoverflow.com/questions/47887533/keras-convolution-along-samples\n",
    "https://keras.io/layers/wrappers/#timedistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_size = 10\n",
    "input_width = 160\n",
    "input_height = 100\n",
    "channels = 2\n",
    "class_number = 12\n",
    "data_path = \"D:\\\\Python\\\\Wormax_learn2\\\\preprocessed_data_local_notshuffled_2ch\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers, Input\n",
    "import keras.backend as K\n",
    "\n",
    "def actual_acc(y_true, y_pred):\n",
    "    return K.equal(K.argmax(y_pred), K.argmax(y_true))\n",
    "        \n",
    "def convolution_feature_extractor(input_height, input_width, channels):\n",
    "    input_tensor = Input(shape=(input_height, input_width, channels))\n",
    "    \n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(input_tensor)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    #x = layers.Dropout(0.5)(x)\n",
    "    output_tensor = layers.Dense(512, activation='relu')(x)\n",
    "    \n",
    "    model = Model(input_tensor, output_tensor)    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def define_model():\n",
    "    input_tensor = Input(shape=(sequence_size, input_height, input_width, channels))\n",
    "        \n",
    "    x = layers.TimeDistributed(\n",
    "            convolution_feature_extractor(input_height, input_width, channels))(input_tensor)\n",
    "    x = layers.GRU(32,\n",
    "    #        dropout=0.1,\n",
    "    #        recurrent_dropout=0.5,\n",
    "            return_sequences=True\n",
    "                  )(x)\n",
    "    x = layers.GRU(64, activation='relu',\n",
    "    #        dropout=0.1,\n",
    "    #        recurrent_dropout=0.5\n",
    "                  )(x)\n",
    "    \n",
    "    output_tensor = layers.Dense(class_number, activation='softmax')(x)\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "   \n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "                  metrics=[actual_acc])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100, 160, 2)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 98, 158, 32)       608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 47, 77, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 36, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 16, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               2097664   \n",
      "=================================================================\n",
      "Total params: 2,338,208\n",
      "Trainable params: 2,338,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 100, 160, 2)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 10, 512)           2338208   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 10, 32)            52320     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 64)                18624     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                780       \n",
      "=================================================================\n",
      "Total params: 2,409,932\n",
      "Trainable params: 2,409,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = define_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# little prepocessing\n",
    "from math import atan2, pi\n",
    "\n",
    "def get_angle(x, y):\n",
    "    return atan2(y, x)\n",
    "\n",
    "def get_direction(x, y, n_classes = 12):\n",
    "    return round(get_angle(x, y)/2/pi*n_classes)%n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from functools import reduce\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Training and validation\n",
    "data_ratio = 0.7\n",
    "\n",
    "# Generator done for not to overflow MEM\n",
    "# holds one data file for every instance(train and validation)\n",
    "def generator(data_dir, sequence_size, num_classes, role, batch_size=128):\n",
    "    \n",
    "    listdir = []\n",
    "    listdir = filter(lambda x: os.path.isfile, os.listdir(data_dir))\n",
    "    listdir = np.array(list(listdir))\n",
    "    random.shuffle(listdir)\n",
    "    \n",
    "    #print('Found {} files for {}'.format(len(listdir), role))\n",
    "    \n",
    "    file_i = 0\n",
    "    while 1:\n",
    "        data = np.load(data_dir + listdir[file_i])\n",
    "        file_i = (file_i+1) if file_i+1<len(listdir) else 0\n",
    "        \n",
    "        if role == 'train':\n",
    "            data = data[:int(round(len(data)*data_ratio))]\n",
    "        elif role == 'validation':\n",
    "            data = data[int(round(len(data)*data_ratio)):]\n",
    "        else:\n",
    "            raise 'bad role parameter'\n",
    "            \n",
    "        i = 0\n",
    "        while i + batch_size + sequence_size + 1 < len(data):\n",
    "            samples = np.zeros((batch_size, sequence_size, input_height, input_width, channels))\n",
    "            targets = np.zeros((batch_size, num_classes))\n",
    "            for j in range(batch_size):\n",
    "                # some issue with shapes(dummy reshape)\n",
    "                sample = np.zeros((sequence_size, input_height, input_width, channels))\n",
    "                for k, dt in enumerate(data[i + j:i + j + sequence_size, 0]):\n",
    "                    sample[k] = dt\n",
    "                samples[j] = sample\n",
    "                targets[j] = to_categorical(get_direction(*data[i + j + sequence_size][1][:2]), num_classes=num_classes)\n",
    "            i += batch_size\n",
    "            yield samples, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 100, 160, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_generator = generator(data_path, sequence_size, class_number, 'train', batch_size=10)\n",
    "validation_generator = generator(data_path, sequence_size, class_number, 'validation', batch_size=10)\n",
    "\n",
    "print(next(train_generator)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.581914981007576, 0.1303000006750226]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate_generator(validation_generator, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10, 100, 160, 2)\n",
      "Epoch 1/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.4109 - actual_acc: 0.2180 - val_loss: 2.2076 - val_actual_acc: 0.4326\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.4097 - actual_acc: 0.1460 - val_loss: 2.4065 - val_actual_acc: 0.1698\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 2.4483 - actual_acc: 0.1200 - val_loss: 2.4551 - val_actual_acc: 0.2349\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.4129 - actual_acc: 0.2070 - val_loss: 2.4602 - val_actual_acc: 0.1721\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 2.4701 - actual_acc: 0.1120 - val_loss: 2.3319 - val_actual_acc: 0.0605\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 21s 212ms/step - loss: 2.3588 - actual_acc: 0.1720 - val_loss: 2.5122 - val_actual_acc: 0.0744\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 2.4558 - actual_acc: 0.1580 - val_loss: 2.6149 - val_actual_acc: 0.0419\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3923 - actual_acc: 0.1540 - val_loss: 2.6739 - val_actual_acc: 0.0651\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4701 - actual_acc: 0.1200 - val_loss: 2.3259 - val_actual_acc: 0.1930\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5028 - actual_acc: 0.1070 - val_loss: 2.4524 - val_actual_acc: 0.1651\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4911 - actual_acc: 0.1080 - val_loss: 2.4073 - val_actual_acc: 0.1767\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 2.4237 - actual_acc: 0.1680 - val_loss: 2.4245 - val_actual_acc: 0.0814\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4500 - actual_acc: 0.1520 - val_loss: 2.4814 - val_actual_acc: 0.0698\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 21s 209ms/step - loss: 2.3383 - actual_acc: 0.2130 - val_loss: 2.5330 - val_actual_acc: 0.0488\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4697 - actual_acc: 0.0950 - val_loss: 2.3905 - val_actual_acc: 0.1209\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4615 - actual_acc: 0.1640 - val_loss: 2.4875 - val_actual_acc: 0.0721\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 2.3274 - actual_acc: 0.1680 - val_loss: 2.6009 - val_actual_acc: 0.0302\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4572 - actual_acc: 0.1280 - val_loss: 2.5693 - val_actual_acc: 0.0558\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3406 - actual_acc: 0.1930 - val_loss: 2.5020 - val_actual_acc: 0.0860\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4219 - actual_acc: 0.1300 - val_loss: 2.5513 - val_actual_acc: 0.0698\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 2.4400 - actual_acc: 0.1130 - val_loss: 2.4672 - val_actual_acc: 0.0465\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3633 - actual_acc: 0.1210 - val_loss: 2.5041 - val_actual_acc: 0.0233\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 2.3162 - actual_acc: 0.1790 - val_loss: 2.6515 - val_actual_acc: 0.0372\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4011 - actual_acc: 0.1860 - val_loss: 2.2587 - val_actual_acc: 0.3116\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3542 - actual_acc: 0.0860 - val_loss: 2.5521 - val_actual_acc: 0.0233\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4948 - actual_acc: 0.1350 - val_loss: 2.3999 - val_actual_acc: 0.2977\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4807 - actual_acc: 0.1330 - val_loss: 2.4940 - val_actual_acc: 0.1465\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 2.3573 - actual_acc: 0.2110 - val_loss: 2.5289 - val_actual_acc: 0.0512\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 22s 223ms/step - loss: 2.3195 - actual_acc: 0.1940 - val_loss: 2.5132 - val_actual_acc: 0.1419\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4574 - actual_acc: 0.0820 - val_loss: 2.4970 - val_actual_acc: 0.1116\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4528 - actual_acc: 0.1730 - val_loss: 2.5313 - val_actual_acc: 0.1000\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.2727 - actual_acc: 0.2510 - val_loss: 2.6597 - val_actual_acc: 0.1395\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3612 - actual_acc: 0.1120 - val_loss: 2.3156 - val_actual_acc: 0.1512\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.3718 - actual_acc: 0.2110 - val_loss: 2.5439 - val_actual_acc: 0.1186\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3700 - actual_acc: 0.1510 - val_loss: 2.5051 - val_actual_acc: 0.1116\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4242 - actual_acc: 0.1590 - val_loss: 2.4363 - val_actual_acc: 0.1395\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4072 - actual_acc: 0.1390 - val_loss: 2.6259 - val_actual_acc: 0.0326\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4960 - actual_acc: 0.0990 - val_loss: 2.4415 - val_actual_acc: 0.1791\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3912 - actual_acc: 0.1530 - val_loss: 2.2593 - val_actual_acc: 0.1698\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 2.4411 - actual_acc: 0.1480 - val_loss: 2.4098 - val_actual_acc: 0.1465\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4205 - actual_acc: 0.1560 - val_loss: 2.3940 - val_actual_acc: 0.1581\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 21s 213ms/step - loss: 2.4980 - actual_acc: 0.0800 - val_loss: 2.5545 - val_actual_acc: 0.0512\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4518 - actual_acc: 0.1430 - val_loss: 2.2795 - val_actual_acc: 0.3140\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4427 - actual_acc: 0.1330 - val_loss: 2.4864 - val_actual_acc: 0.1674\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4872 - actual_acc: 0.1370 - val_loss: 2.4101 - val_actual_acc: 0.0907\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 2.4858 - actual_acc: 0.0980 - val_loss: 2.4705 - val_actual_acc: 0.1651\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.4280 - actual_acc: 0.1060 - val_loss: 2.5516 - val_actual_acc: 0.1302\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4606 - actual_acc: 0.0860 - val_loss: 2.5704 - val_actual_acc: 0.0349\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 21s 211ms/step - loss: 2.4110 - actual_acc: 0.1480 - val_loss: 2.5233 - val_actual_acc: 0.1349\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4333 - actual_acc: 0.2010 - val_loss: 2.2837 - val_actual_acc: 0.2465\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.4248 - actual_acc: 0.1220 - val_loss: 2.3601 - val_actual_acc: 0.0953\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3256 - actual_acc: 0.1450 - val_loss: 2.4435 - val_actual_acc: 0.1930\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4460 - actual_acc: 0.1110 - val_loss: 2.4040 - val_actual_acc: 0.1907\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3460 - actual_acc: 0.1870 - val_loss: 2.3135 - val_actual_acc: 0.2279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4121 - actual_acc: 0.1620 - val_loss: 2.3865 - val_actual_acc: 0.1023\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.4590 - actual_acc: 0.1280 - val_loss: 2.2438 - val_actual_acc: 0.2767\n",
      "Epoch 57/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.3577 - actual_acc: 0.1670 - val_loss: 2.3028 - val_actual_acc: 0.2093\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3281 - actual_acc: 0.1150 - val_loss: 2.5203 - val_actual_acc: 0.0953\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4748 - actual_acc: 0.1300 - val_loss: 2.3144 - val_actual_acc: 0.1698\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2500 - actual_acc: 0.2260 - val_loss: 2.4833 - val_actual_acc: 0.1140\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3264 - actual_acc: 0.1240 - val_loss: 2.4299 - val_actual_acc: 0.1326\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4475 - actual_acc: 0.1580 - val_loss: 2.4904 - val_actual_acc: 0.1279\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 2.3056 - actual_acc: 0.1400 - val_loss: 2.4237 - val_actual_acc: 0.1302\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4526 - actual_acc: 0.0960 - val_loss: 2.4951 - val_actual_acc: 0.1256\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3948 - actual_acc: 0.1910 - val_loss: 2.3817 - val_actual_acc: 0.1651\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3400 - actual_acc: 0.2230 - val_loss: 2.3266 - val_actual_acc: 0.0674\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3046 - actual_acc: 0.2030 - val_loss: 2.7302 - val_actual_acc: 0.0698\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.4024 - actual_acc: 0.1080 - val_loss: 2.4051 - val_actual_acc: 0.0628\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3466 - actual_acc: 0.1420 - val_loss: 2.4494 - val_actual_acc: 0.0116\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 27s 270ms/step - loss: 2.3045 - actual_acc: 0.1480 - val_loss: 2.7591 - val_actual_acc: 0.0070\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3511 - actual_acc: 0.2010 - val_loss: 2.4086 - val_actual_acc: 0.0442\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4385 - actual_acc: 0.1010 - val_loss: 2.4581 - val_actual_acc: 0.0581\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4447 - actual_acc: 0.0990 - val_loss: 2.4321 - val_actual_acc: 0.0349\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4202 - actual_acc: 0.1270 - val_loss: 2.3817 - val_actual_acc: 0.1116\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5008 - actual_acc: 0.0950 - val_loss: 2.3876 - val_actual_acc: 0.3535\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4206 - actual_acc: 0.1080 - val_loss: 2.4777 - val_actual_acc: 0.1047\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 22s 221ms/step - loss: 2.4315 - actual_acc: 0.2000 - val_loss: 2.4137 - val_actual_acc: 0.1535\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5303 - actual_acc: 0.0710 - val_loss: 2.4129 - val_actual_acc: 0.1326\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4358 - actual_acc: 0.1260 - val_loss: 2.4286 - val_actual_acc: 0.1535\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.4117 - actual_acc: 0.1930 - val_loss: 2.3405 - val_actual_acc: 0.1488\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4040 - actual_acc: 0.1040 - val_loss: 2.3328 - val_actual_acc: 0.2395\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3421 - actual_acc: 0.2070 - val_loss: 2.4595 - val_actual_acc: 0.1512\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5109 - actual_acc: 0.1230 - val_loss: 2.4173 - val_actual_acc: 0.1070\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 23s 226ms/step - loss: 2.4217 - actual_acc: 0.1910 - val_loss: 2.4605 - val_actual_acc: 0.2093\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.4247 - actual_acc: 0.0970 - val_loss: 2.4981 - val_actual_acc: 0.1302\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3975 - actual_acc: 0.1290 - val_loss: 2.3177 - val_actual_acc: 0.2907\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3395 - actual_acc: 0.1990 - val_loss: 2.2108 - val_actual_acc: 0.1349\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5088 - actual_acc: 0.1240 - val_loss: 2.2722 - val_actual_acc: 0.3163\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5571 - actual_acc: 0.0510 - val_loss: 2.4488 - val_actual_acc: 0.1140\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4738 - actual_acc: 0.1410 - val_loss: 2.4490 - val_actual_acc: 0.0930\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 30s 297ms/step - loss: 2.4182 - actual_acc: 0.0970 - val_loss: 2.4307 - val_actual_acc: 0.1837\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4272 - actual_acc: 0.1710 - val_loss: 2.4027 - val_actual_acc: 0.1326\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3475 - actual_acc: 0.1400 - val_loss: 2.4405 - val_actual_acc: 0.0372\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4290 - actual_acc: 0.1740 - val_loss: 2.4498 - val_actual_acc: 0.1535\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3884 - actual_acc: 0.1580 - val_loss: 2.5333 - val_actual_acc: 0.0442\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3986 - actual_acc: 0.1400 - val_loss: 2.4473 - val_actual_acc: 0.0535\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.5246 - actual_acc: 0.0590 - val_loss: 2.2883 - val_actual_acc: 0.1233\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.3540 - actual_acc: 0.1500 - val_loss: 2.4911 - val_actual_acc: 0.0907\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3336 - actual_acc: 0.2030 - val_loss: 2.4083 - val_actual_acc: 0.1116\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5774 - actual_acc: 0.0600 - val_loss: 2.5374 - val_actual_acc: 0.0767\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3808 - actual_acc: 0.1460 - val_loss: 2.5756 - val_actual_acc: 0.0651\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.5442 - actual_acc: 0.0830 - val_loss: 2.4452 - val_actual_acc: 0.2093\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3797 - actual_acc: 0.1730 - val_loss: 2.5215 - val_actual_acc: 0.0744\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3254 - actual_acc: 0.1910 - val_loss: 2.4532 - val_actual_acc: 0.1674\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 2.4267 - actual_acc: 0.2010 - val_loss: 2.2713 - val_actual_acc: 0.2930\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3699 - actual_acc: 0.1640 - val_loss: 2.5958 - val_actual_acc: 0.0907\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4088 - actual_acc: 0.1080 - val_loss: 2.3201 - val_actual_acc: 0.1186\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.4419 - actual_acc: 0.1310 - val_loss: 2.4903 - val_actual_acc: 0.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3900 - actual_acc: 0.1750 - val_loss: 2.4350 - val_actual_acc: 0.0860\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4099 - actual_acc: 0.1280 - val_loss: 2.5985 - val_actual_acc: 0.0814\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2574 - actual_acc: 0.2340 - val_loss: 2.3484 - val_actual_acc: 0.1558\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 2.3971 - actual_acc: 0.0930 - val_loss: 2.4124 - val_actual_acc: 0.2070\n",
      "Epoch 113/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5422 - actual_acc: 0.0240 - val_loss: 2.5220 - val_actual_acc: 0.0372\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 23s 228ms/step - loss: 2.4580 - actual_acc: 0.1660 - val_loss: 2.3439 - val_actual_acc: 0.2419\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2511 - actual_acc: 0.2380 - val_loss: 2.5191 - val_actual_acc: 0.0814\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4194 - actual_acc: 0.2000 - val_loss: 2.7622 - val_actual_acc: 0.0884\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5155 - actual_acc: 0.0840 - val_loss: 2.5361 - val_actual_acc: 0.1233\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4861 - actual_acc: 0.1480 - val_loss: 2.4509 - val_actual_acc: 0.0581\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 30s 302ms/step - loss: 2.4329 - actual_acc: 0.1090 - val_loss: 2.4395 - val_actual_acc: 0.0465\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4405 - actual_acc: 0.1250 - val_loss: 2.4614 - val_actual_acc: 0.2023\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3968 - actual_acc: 0.1430 - val_loss: 2.3910 - val_actual_acc: 0.1535\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4718 - actual_acc: 0.1190 - val_loss: 2.4294 - val_actual_acc: 0.2023\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4612 - actual_acc: 0.1480 - val_loss: 2.4138 - val_actual_acc: 0.1047\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4113 - actual_acc: 0.1500 - val_loss: 2.5034 - val_actual_acc: 0.0419\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.4030 - actual_acc: 0.1320 - val_loss: 2.4129 - val_actual_acc: 0.1558\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4389 - actual_acc: 0.0870 - val_loss: 2.3584 - val_actual_acc: 0.1233\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4090 - actual_acc: 0.1540 - val_loss: 2.3715 - val_actual_acc: 0.3023\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4351 - actual_acc: 0.1520 - val_loss: 2.3832 - val_actual_acc: 0.1326\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4737 - actual_acc: 0.0890 - val_loss: 2.4252 - val_actual_acc: 0.1233\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4406 - actual_acc: 0.1330 - val_loss: 2.5207 - val_actual_acc: 0.0581\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.4090 - actual_acc: 0.1380 - val_loss: 2.4664 - val_actual_acc: 0.1512\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4191 - actual_acc: 0.1060 - val_loss: 2.4857 - val_actual_acc: 0.1651\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.3800 - actual_acc: 0.1450 - val_loss: 2.4050 - val_actual_acc: 0.1372\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.2711 - actual_acc: 0.2310 - val_loss: 2.5507 - val_actual_acc: 0.1233\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5209 - actual_acc: 0.0970 - val_loss: 2.3663 - val_actual_acc: 0.1907\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.3889 - actual_acc: 0.1540 - val_loss: 2.1879 - val_actual_acc: 0.2256\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3931 - actual_acc: 0.1730 - val_loss: 2.5401 - val_actual_acc: 0.1326\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4178 - actual_acc: 0.1190 - val_loss: 2.4551 - val_actual_acc: 0.1698\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4267 - actual_acc: 0.0560 - val_loss: 2.4395 - val_actual_acc: 0.1372\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 22s 222ms/step - loss: 2.4916 - actual_acc: 0.1120 - val_loss: 2.4907 - val_actual_acc: 0.1163\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4115 - actual_acc: 0.1710 - val_loss: 2.4735 - val_actual_acc: 0.0581\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4215 - actual_acc: 0.1280 - val_loss: 2.4633 - val_actual_acc: 0.0977\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3548 - actual_acc: 0.1640 - val_loss: 2.4170 - val_actual_acc: 0.1395\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4438 - actual_acc: 0.1030 - val_loss: 2.4746 - val_actual_acc: 0.1279\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4834 - actual_acc: 0.0950 - val_loss: 2.4618 - val_actual_acc: 0.1140\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4171 - actual_acc: 0.1690 - val_loss: 2.4394 - val_actual_acc: 0.1512\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.3686 - actual_acc: 0.1900 - val_loss: 2.5143 - val_actual_acc: 0.0930\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.3765 - actual_acc: 0.1480 - val_loss: 2.2931 - val_actual_acc: 0.1558\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4587 - actual_acc: 0.1120 - val_loss: 2.4311 - val_actual_acc: 0.1349\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4303 - actual_acc: 0.1330 - val_loss: 2.4078 - val_actual_acc: 0.1209\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4095 - actual_acc: 0.1520 - val_loss: 2.4694 - val_actual_acc: 0.0651\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4428 - actual_acc: 0.1350 - val_loss: 2.3816 - val_actual_acc: 0.1791\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.3854 - actual_acc: 0.2340 - val_loss: 2.4009 - val_actual_acc: 0.1767\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.3815 - actual_acc: 0.1420 - val_loss: 2.3530 - val_actual_acc: 0.2698\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3654 - actual_acc: 0.1880 - val_loss: 2.3240 - val_actual_acc: 0.3349\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4706 - actual_acc: 0.1340 - val_loss: 2.2633 - val_actual_acc: 0.3860\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3757 - actual_acc: 0.1940 - val_loss: 2.4693 - val_actual_acc: 0.1093\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4138 - actual_acc: 0.1550 - val_loss: 2.4088 - val_actual_acc: 0.1279\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.4009 - actual_acc: 0.1520 - val_loss: 2.5215 - val_actual_acc: 0.0512\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4659 - actual_acc: 0.0580 - val_loss: 2.3970 - val_actual_acc: 0.0070\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.4588 - actual_acc: 0.0840 - val_loss: 2.3769 - val_actual_acc: 0.0651\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4372 - actual_acc: 0.0830 - val_loss: 2.4020 - val_actual_acc: 0.1256\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4157 - actual_acc: 0.0770 - val_loss: 2.3533 - val_actual_acc: 0.2209\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3995 - actual_acc: 0.0850 - val_loss: 2.4022 - val_actual_acc: 0.1442\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4277 - actual_acc: 0.1010 - val_loss: 2.4205 - val_actual_acc: 0.1674\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4327 - actual_acc: 0.1120 - val_loss: 2.4877 - val_actual_acc: 0.0953\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4116 - actual_acc: 0.1290 - val_loss: 2.4059 - val_actual_acc: 0.1721\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 2.4609 - actual_acc: 0.0900 - val_loss: 2.2837 - val_actual_acc: 0.3442\n",
      "Epoch 169/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3467 - actual_acc: 0.1770 - val_loss: 2.4737 - val_actual_acc: 0.1233\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4463 - actual_acc: 0.1100 - val_loss: 2.4865 - val_actual_acc: 0.0558\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3808 - actual_acc: 0.1120 - val_loss: 2.3497 - val_actual_acc: 0.2442\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4927 - actual_acc: 0.0970 - val_loss: 2.4456 - val_actual_acc: 0.0721\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4424 - actual_acc: 0.1500 - val_loss: 2.5094 - val_actual_acc: 0.0884\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5269 - actual_acc: 0.0820 - val_loss: 2.3685 - val_actual_acc: 0.2093\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.3982 - actual_acc: 0.1050 - val_loss: 2.4384 - val_actual_acc: 0.1116\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.3881 - actual_acc: 0.2600 - val_loss: 2.4741 - val_actual_acc: 0.0651\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3777 - actual_acc: 0.1660 - val_loss: 2.2778 - val_actual_acc: 0.3512\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4583 - actual_acc: 0.0680 - val_loss: 2.3942 - val_actual_acc: 0.0860\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4265 - actual_acc: 0.1280 - val_loss: 2.5405 - val_actual_acc: 0.0256\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4333 - actual_acc: 0.0540 - val_loss: 2.4366 - val_actual_acc: 0.2140\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4837 - actual_acc: 0.1450 - val_loss: 2.5393 - val_actual_acc: 0.1140\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 29s 286ms/step - loss: 2.6042 - actual_acc: 0.0780 - val_loss: 2.4147 - val_actual_acc: 0.1907\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4291 - actual_acc: 0.3210 - val_loss: 2.4301 - val_actual_acc: 0.0465\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4599 - actual_acc: 0.1420 - val_loss: 2.4357 - val_actual_acc: 0.0767\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4262 - actual_acc: 0.1100 - val_loss: 2.4960 - val_actual_acc: 0.1209\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.5085 - actual_acc: 0.1250 - val_loss: 2.2329 - val_actual_acc: 0.3000\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4163 - actual_acc: 0.0870 - val_loss: 2.2901 - val_actual_acc: 0.4860\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3400 - actual_acc: 0.2010 - val_loss: 2.3579 - val_actual_acc: 0.3140\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.4035 - actual_acc: 0.1730 - val_loss: 2.2922 - val_actual_acc: 0.2186\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4380 - actual_acc: 0.0900 - val_loss: 2.4097 - val_actual_acc: 0.1326\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.4389 - actual_acc: 0.1330 - val_loss: 2.4297 - val_actual_acc: 0.0140\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3896 - actual_acc: 0.1050 - val_loss: 2.4699 - val_actual_acc: 0.0721\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3481 - actual_acc: 0.1930 - val_loss: 2.5960 - val_actual_acc: 0.0465\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.2640 - actual_acc: 0.2750 - val_loss: 2.4586 - val_actual_acc: 0.1209\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3886 - actual_acc: 0.1570 - val_loss: 2.3451 - val_actual_acc: 0.0791\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.3750 - actual_acc: 0.1400 - val_loss: 2.4263 - val_actual_acc: 0.1488\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.4405 - actual_acc: 0.0980 - val_loss: 2.3810 - val_actual_acc: 0.2209\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4278 - actual_acc: 0.1000 - val_loss: 2.5838 - val_actual_acc: 0.1023\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4790 - actual_acc: 0.0970 - val_loss: 2.5675 - val_actual_acc: 0.0814\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4957 - actual_acc: 0.0850 - val_loss: 2.4142 - val_actual_acc: 0.1907\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 22s 219ms/step - loss: 2.4563 - actual_acc: 0.0800 - val_loss: 2.5000 - val_actual_acc: 0.0860\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.4062 - actual_acc: 0.1910 - val_loss: 2.2643 - val_actual_acc: 0.1674\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3985 - actual_acc: 0.1650 - val_loss: 2.3915 - val_actual_acc: 0.0953\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4090 - actual_acc: 0.1090 - val_loss: 2.5464 - val_actual_acc: 0.0535\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3012 - actual_acc: 0.0790 - val_loss: 2.3680 - val_actual_acc: 0.2465\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3575 - actual_acc: 0.1720 - val_loss: 2.3424 - val_actual_acc: 0.1047\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3788 - actual_acc: 0.2120 - val_loss: 2.4005 - val_actual_acc: 0.0884\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 31s 312ms/step - loss: 2.4544 - actual_acc: 0.1390 - val_loss: 2.3540 - val_actual_acc: 0.1326\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5006 - actual_acc: 0.1120 - val_loss: 2.4561 - val_actual_acc: 0.1744\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4459 - actual_acc: 0.1520 - val_loss: 2.2838 - val_actual_acc: 0.2000\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2766 - actual_acc: 0.2590 - val_loss: 2.4535 - val_actual_acc: 0.0698\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3555 - actual_acc: 0.1830 - val_loss: 2.2996 - val_actual_acc: 0.1907\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4981 - actual_acc: 0.1050 - val_loss: 2.3204 - val_actual_acc: 0.1767\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3861 - actual_acc: 0.1280 - val_loss: 2.4649 - val_actual_acc: 0.1349\n",
      "Epoch 215/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 245ms/step - loss: 2.3770 - actual_acc: 0.1850 - val_loss: 2.6687 - val_actual_acc: 0.0140\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4573 - actual_acc: 0.1550 - val_loss: 2.3618 - val_actual_acc: 0.1349\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4280 - actual_acc: 0.0890 - val_loss: 2.2915 - val_actual_acc: 0.1070\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3820 - actual_acc: 0.1590 - val_loss: 2.5310 - val_actual_acc: 0.1326\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4808 - actual_acc: 0.0610 - val_loss: 2.5411 - val_actual_acc: 0.1023\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3345 - actual_acc: 0.1750 - val_loss: 2.1507 - val_actual_acc: 0.2884\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4198 - actual_acc: 0.1360 - val_loss: 2.2492 - val_actual_acc: 0.1558\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 23s 233ms/step - loss: 2.4505 - actual_acc: 0.1390 - val_loss: 2.7436 - val_actual_acc: 0.0744\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5740 - actual_acc: 0.0570 - val_loss: 2.2895 - val_actual_acc: 0.2419\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4126 - actual_acc: 0.1110 - val_loss: 2.3856 - val_actual_acc: 0.0674\n",
      "Epoch 225/1000\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.4302 - actual_acc: 0.1000 - val_loss: 2.3561 - val_actual_acc: 0.1093\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4396 - actual_acc: 0.1300 - val_loss: 2.3507 - val_actual_acc: 0.1860\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5614 - actual_acc: 0.0770 - val_loss: 2.2324 - val_actual_acc: 0.1698\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4653 - actual_acc: 0.1580 - val_loss: 2.4919 - val_actual_acc: 0.1256\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.4681 - actual_acc: 0.1500 - val_loss: 2.4268 - val_actual_acc: 0.2721\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4366 - actual_acc: 0.1330 - val_loss: 2.2480 - val_actual_acc: 0.0884\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.4907 - actual_acc: 0.1260 - val_loss: 2.3819 - val_actual_acc: 0.0814\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4667 - actual_acc: 0.1180 - val_loss: 2.2605 - val_actual_acc: 0.3233\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5134 - actual_acc: 0.1030 - val_loss: 2.5042 - val_actual_acc: 0.0744\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2763 - actual_acc: 0.2480 - val_loss: 2.3478 - val_actual_acc: 0.2000\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4681 - actual_acc: 0.0840 - val_loss: 2.4972 - val_actual_acc: 0.0558\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 30s 305ms/step - loss: 2.3528 - actual_acc: 0.0660 - val_loss: 2.5519 - val_actual_acc: 0.0884\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3575 - actual_acc: 0.1220 - val_loss: 2.4936 - val_actual_acc: 0.0442\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3673 - actual_acc: 0.1630 - val_loss: 2.3999 - val_actual_acc: 0.2651\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4198 - actual_acc: 0.1350 - val_loss: 2.5827 - val_actual_acc: 0.1209\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4157 - actual_acc: 0.1510 - val_loss: 2.4173 - val_actual_acc: 0.1163\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4464 - actual_acc: 0.1650 - val_loss: 2.1184 - val_actual_acc: 0.1977\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3761 - actual_acc: 0.2060 - val_loss: 2.5371 - val_actual_acc: 0.1209\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.3246 - actual_acc: 0.2540 - val_loss: 2.3429 - val_actual_acc: 0.1581\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4498 - actual_acc: 0.1710 - val_loss: 2.5002 - val_actual_acc: 0.0744\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5183 - actual_acc: 0.0850 - val_loss: 2.2921 - val_actual_acc: 0.1791\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4180 - actual_acc: 0.1220 - val_loss: 2.3964 - val_actual_acc: 0.2605\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5494 - actual_acc: 0.1280 - val_loss: 2.3009 - val_actual_acc: 0.2209\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.4389 - actual_acc: 0.1190 - val_loss: 2.3455 - val_actual_acc: 0.2558\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4827 - actual_acc: 0.1220 - val_loss: 2.4600 - val_actual_acc: 0.1116\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 2.4611 - actual_acc: 0.1240 - val_loss: 2.3988 - val_actual_acc: 0.1000\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4187 - actual_acc: 0.1340 - val_loss: 2.5654 - val_actual_acc: 0.0791\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4301 - actual_acc: 0.1470 - val_loss: 2.4680 - val_actual_acc: 0.1163\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.2709 - actual_acc: 0.1650 - val_loss: 2.4527 - val_actual_acc: 0.1070\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3971 - actual_acc: 0.2110 - val_loss: 2.6554 - val_actual_acc: 0.0628\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4105 - actual_acc: 0.1430 - val_loss: 2.3355 - val_actual_acc: 0.1674\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3430 - actual_acc: 0.2370 - val_loss: 2.5890 - val_actual_acc: 0.0930\n",
      "Epoch 257/1000\n",
      "  2/100 [..............................] - ETA: 31s - loss: 1.8390 - actual_acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.185918). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 23s 230ms/step - loss: 2.4164 - actual_acc: 0.1140 - val_loss: 2.3478 - val_actual_acc: 0.1302\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4712 - actual_acc: 0.1110 - val_loss: 2.4099 - val_actual_acc: 0.1395\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.3764 - actual_acc: 0.1190 - val_loss: 2.5607 - val_actual_acc: 0.1488\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3569 - actual_acc: 0.1660 - val_loss: 2.3683 - val_actual_acc: 0.1349\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4308 - actual_acc: 0.1320 - val_loss: 2.4740 - val_actual_acc: 0.1651\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4680 - actual_acc: 0.1410 - val_loss: 2.4096 - val_actual_acc: 0.1791\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.4240 - actual_acc: 0.1690 - val_loss: 2.5004 - val_actual_acc: 0.0977\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4921 - actual_acc: 0.0710 - val_loss: 2.4304 - val_actual_acc: 0.1488\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 2.3422 - actual_acc: 0.0820 - val_loss: 2.4126 - val_actual_acc: 0.1581\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5224 - actual_acc: 0.0930 - val_loss: 2.3973 - val_actual_acc: 0.0070\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5284 - actual_acc: 0.0950 - val_loss: 2.3753 - val_actual_acc: 0.1535\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3729 - actual_acc: 0.1190 - val_loss: 2.4285 - val_actual_acc: 0.0698\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3246 - actual_acc: 0.1580 - val_loss: 2.4790 - val_actual_acc: 0.1349\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 31s 315ms/step - loss: 2.4261 - actual_acc: 0.1420 - val_loss: 2.6155 - val_actual_acc: 0.0372\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3313 - actual_acc: 0.2250 - val_loss: 2.2649 - val_actual_acc: 0.0512\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4881 - actual_acc: 0.0430 - val_loss: 2.3966 - val_actual_acc: 0.0651\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4670 - actual_acc: 0.1180 - val_loss: 2.4708 - val_actual_acc: 0.2349\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3838 - actual_acc: 0.1420 - val_loss: 2.4983 - val_actual_acc: 0.0488\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2653 - actual_acc: 0.2000 - val_loss: 2.2916 - val_actual_acc: 0.0581\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3317 - actual_acc: 0.2560 - val_loss: 2.3719 - val_actual_acc: 0.1326\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4004 - actual_acc: 0.1280 - val_loss: 2.5443 - val_actual_acc: 0.0372\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4102 - actual_acc: 0.1490 - val_loss: 2.5690 - val_actual_acc: 0.0651\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3375 - actual_acc: 0.0660 - val_loss: 2.3240 - val_actual_acc: 0.2000\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3982 - actual_acc: 0.1690 - val_loss: 2.4059 - val_actual_acc: 0.1279\n",
      "Epoch 281/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3158 - actual_acc: 0.0750 - val_loss: 2.2550 - val_actual_acc: 0.1930\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4379 - actual_acc: 0.1060 - val_loss: 2.3929 - val_actual_acc: 0.2791\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3894 - actual_acc: 0.1140 - val_loss: 2.4703 - val_actual_acc: 0.1930\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 2.3319 - actual_acc: 0.2940 - val_loss: 2.5601 - val_actual_acc: 0.1093\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4275 - actual_acc: 0.1750 - val_loss: 2.4516 - val_actual_acc: 0.1209\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3812 - actual_acc: 0.1270 - val_loss: 2.4754 - val_actual_acc: 0.0721\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4011 - actual_acc: 0.1440 - val_loss: 2.5669 - val_actual_acc: 0.1605\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4147 - actual_acc: 0.1720 - val_loss: 2.5850 - val_actual_acc: 0.0721\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4692 - actual_acc: 0.0510 - val_loss: 2.4421 - val_actual_acc: 0.0860\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3961 - actual_acc: 0.1330 - val_loss: 2.5426 - val_actual_acc: 0.0698\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.5634 - actual_acc: 0.0860 - val_loss: 2.3912 - val_actual_acc: 0.0465\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3535 - actual_acc: 0.1230 - val_loss: 2.5281 - val_actual_acc: 0.1698\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 2.3209 - actual_acc: 0.2310 - val_loss: 2.4185 - val_actual_acc: 0.1070\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3081 - actual_acc: 0.2500 - val_loss: 2.3762 - val_actual_acc: 0.3116\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3556 - actual_acc: 0.0990 - val_loss: 2.5562 - val_actual_acc: 0.1349\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3799 - actual_acc: 0.1250 - val_loss: 2.4421 - val_actual_acc: 0.1023\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4218 - actual_acc: 0.1890 - val_loss: 2.5276 - val_actual_acc: 0.1465\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 2.3831 - actual_acc: 0.1730 - val_loss: 2.5149 - val_actual_acc: 0.0512\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4707 - actual_acc: 0.1150 - val_loss: 2.4589 - val_actual_acc: 0.1419\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4557 - actual_acc: 0.1700 - val_loss: 2.5144 - val_actual_acc: 0.0930\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5140 - actual_acc: 0.0670 - val_loss: 2.5584 - val_actual_acc: 0.0884\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4202 - actual_acc: 0.1300 - val_loss: 2.6076 - val_actual_acc: 0.0186\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4394 - actual_acc: 0.1360 - val_loss: 2.3802 - val_actual_acc: 0.1651\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.4808 - actual_acc: 0.1170 - val_loss: 2.4707 - val_actual_acc: 0.1186\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4281 - actual_acc: 0.1840 - val_loss: 2.4330 - val_actual_acc: 0.1256\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5006 - actual_acc: 0.0770 - val_loss: 2.4684 - val_actual_acc: 0.1395\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5231 - actual_acc: 0.0830 - val_loss: 2.7187 - val_actual_acc: 0.0186\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4594 - actual_acc: 0.1200 - val_loss: 2.4530 - val_actual_acc: 0.1791\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3720 - actual_acc: 0.0870 - val_loss: 2.2527 - val_actual_acc: 0.2791\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3419 - actual_acc: 0.2260 - val_loss: 2.4259 - val_actual_acc: 0.1465\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2408 - actual_acc: 0.2780 - val_loss: 2.3746 - val_actual_acc: 0.1581\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.2444 - actual_acc: 0.2970 - val_loss: 2.6918 - val_actual_acc: 0.0512\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.1672 - actual_acc: 0.4490 - val_loss: 2.2117 - val_actual_acc: 0.1605\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3879 - actual_acc: 0.0690 - val_loss: 2.4973 - val_actual_acc: 0.1256\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4525 - actual_acc: 0.0820 - val_loss: 2.2911 - val_actual_acc: 0.2419\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.3186 - actual_acc: 0.0840 - val_loss: 2.5276 - val_actual_acc: 0.0558\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.1647 - actual_acc: 0.1940 - val_loss: 2.5591 - val_actual_acc: 0.0651\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3644 - actual_acc: 0.1250 - val_loss: 2.7300 - val_actual_acc: 0.0349\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.5266 - actual_acc: 0.1070 - val_loss: 2.5666 - val_actual_acc: 0.1349\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3197 - actual_acc: 0.1620 - val_loss: 2.2486 - val_actual_acc: 0.2465\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.5017 - actual_acc: 0.0960 - val_loss: 2.3632 - val_actual_acc: 0.1372\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3732 - actual_acc: 0.2810 - val_loss: 2.3985 - val_actual_acc: 0.1209\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3739 - actual_acc: 0.2300 - val_loss: 2.3961 - val_actual_acc: 0.1907\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5293 - actual_acc: 0.1380 - val_loss: 2.3457 - val_actual_acc: 0.2279\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3589 - actual_acc: 0.1060 - val_loss: 2.3939 - val_actual_acc: 0.1023\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3108 - actual_acc: 0.1590 - val_loss: 2.2433 - val_actual_acc: 0.2767\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4465 - actual_acc: 0.1720 - val_loss: 2.3365 - val_actual_acc: 0.2093\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3084 - actual_acc: 0.0590 - val_loss: 2.4854 - val_actual_acc: 0.0953\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3588 - actual_acc: 0.1940 - val_loss: 2.3060 - val_actual_acc: 0.1698\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.1240 - actual_acc: 0.3420 - val_loss: 2.3835 - val_actual_acc: 0.1140\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4070 - actual_acc: 0.1350 - val_loss: 2.4098 - val_actual_acc: 0.1326\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5553 - actual_acc: 0.1060 - val_loss: 2.4886 - val_actual_acc: 0.1279\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 31s 315ms/step - loss: 2.5331 - actual_acc: 0.0780 - val_loss: 2.4051 - val_actual_acc: 0.1302\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3911 - actual_acc: 0.1480 - val_loss: 2.5073 - val_actual_acc: 0.0512\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3759 - actual_acc: 0.1500 - val_loss: 2.3772 - val_actual_acc: 0.1651\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5050 - actual_acc: 0.1680 - val_loss: 2.3547 - val_actual_acc: 0.0674\n",
      "Epoch 337/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3767 - actual_acc: 0.1080 - val_loss: 2.6533 - val_actual_acc: 0.0698\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4710 - actual_acc: 0.1050 - val_loss: 2.4183 - val_actual_acc: 0.0628\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4752 - actual_acc: 0.1060 - val_loss: 2.4315 - val_actual_acc: 0.0116\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.5088 - actual_acc: 0.0960 - val_loss: 2.6431 - val_actual_acc: 0.0814\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3749 - actual_acc: 0.1190 - val_loss: 2.4039 - val_actual_acc: 0.0442\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4571 - actual_acc: 0.1380 - val_loss: 2.4535 - val_actual_acc: 0.0581\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.6134 - actual_acc: 0.1220 - val_loss: 2.4618 - val_actual_acc: 0.0349\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.5520 - actual_acc: 0.0860 - val_loss: 2.3704 - val_actual_acc: 0.1395\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3587 - actual_acc: 0.1950 - val_loss: 2.3338 - val_actual_acc: 0.0860\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4464 - actual_acc: 0.1150 - val_loss: 2.5105 - val_actual_acc: 0.0512\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.3627 - actual_acc: 0.1350 - val_loss: 2.4280 - val_actual_acc: 0.1302\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4689 - actual_acc: 0.1310 - val_loss: 2.3689 - val_actual_acc: 0.2093\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4995 - actual_acc: 0.1650 - val_loss: 2.4804 - val_actual_acc: 0.0767\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 2.4624 - actual_acc: 0.0450 - val_loss: 2.3242 - val_actual_acc: 0.2116\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3798 - actual_acc: 0.0950 - val_loss: 2.3419 - val_actual_acc: 0.1698\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3207 - actual_acc: 0.2750 - val_loss: 2.4137 - val_actual_acc: 0.1791\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4619 - actual_acc: 0.1260 - val_loss: 2.3428 - val_actual_acc: 0.2419\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.4468 - actual_acc: 0.1330 - val_loss: 2.5333 - val_actual_acc: 0.0442\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4396 - actual_acc: 0.0480 - val_loss: 2.5587 - val_actual_acc: 0.0209\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3733 - actual_acc: 0.1310 - val_loss: 2.3695 - val_actual_acc: 0.1140\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3435 - actual_acc: 0.2270 - val_loss: 2.2133 - val_actual_acc: 0.3628\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4169 - actual_acc: 0.1120 - val_loss: 2.2730 - val_actual_acc: 0.1279\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5309 - actual_acc: 0.0970 - val_loss: 2.4556 - val_actual_acc: 0.1093\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4219 - actual_acc: 0.2050 - val_loss: 2.4416 - val_actual_acc: 0.1349\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 32s 316ms/step - loss: 2.3442 - actual_acc: 0.2110 - val_loss: 2.4665 - val_actual_acc: 0.1023\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3500 - actual_acc: 0.1920 - val_loss: 2.3812 - val_actual_acc: 0.1558\n",
      "Epoch 363/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4244 - actual_acc: 0.1220 - val_loss: 2.4331 - val_actual_acc: 0.1628\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4141 - actual_acc: 0.0860 - val_loss: 2.4178 - val_actual_acc: 0.1395\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3214 - actual_acc: 0.1530 - val_loss: 2.5587 - val_actual_acc: 0.0186\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3543 - actual_acc: 0.1850 - val_loss: 2.4043 - val_actual_acc: 0.1884\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3493 - actual_acc: 0.1870 - val_loss: 2.2054 - val_actual_acc: 0.2907\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 2.3882 - actual_acc: 0.1330 - val_loss: 2.4872 - val_actual_acc: 0.1163\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4402 - actual_acc: 0.1810 - val_loss: 2.4537 - val_actual_acc: 0.0209\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4168 - actual_acc: 0.1270 - val_loss: 2.5906 - val_actual_acc: 0.0860\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4611 - actual_acc: 0.1520 - val_loss: 2.6023 - val_actual_acc: 0.0651\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4009 - actual_acc: 0.1420 - val_loss: 2.4343 - val_actual_acc: 0.1070\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4249 - actual_acc: 0.1530 - val_loss: 2.5134 - val_actual_acc: 0.0744\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4522 - actual_acc: 0.1630 - val_loss: 2.4533 - val_actual_acc: 0.1674\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.5299 - actual_acc: 0.0710 - val_loss: 2.2645 - val_actual_acc: 0.2930\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4201 - actual_acc: 0.1110 - val_loss: 2.5391 - val_actual_acc: 0.0907\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5073 - actual_acc: 0.1110 - val_loss: 2.2936 - val_actual_acc: 0.1186\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.5115 - actual_acc: 0.0960 - val_loss: 2.4915 - val_actual_acc: 0.1721\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5419 - actual_acc: 0.0850 - val_loss: 2.4263 - val_actual_acc: 0.2070\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3936 - actual_acc: 0.1040 - val_loss: 2.6076 - val_actual_acc: 0.0698\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4732 - actual_acc: 0.0980 - val_loss: 2.3524 - val_actual_acc: 0.1558\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3846 - actual_acc: 0.1560 - val_loss: 2.4172 - val_actual_acc: 0.1163\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4331 - actual_acc: 0.1750 - val_loss: 2.5665 - val_actual_acc: 0.0372\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.3945 - actual_acc: 0.1490 - val_loss: 2.2850 - val_actual_acc: 0.2419\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3275 - actual_acc: 0.1430 - val_loss: 2.4614 - val_actual_acc: 0.1698\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4653 - actual_acc: 0.0800 - val_loss: 2.7105 - val_actual_acc: 0.0140\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3502 - actual_acc: 0.2180 - val_loss: 2.5970 - val_actual_acc: 0.0488\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4329 - actual_acc: 0.1090 - val_loss: 2.4403 - val_actual_acc: 0.1419\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 31s 307ms/step - loss: 2.4886 - actual_acc: 0.1480 - val_loss: 2.4112 - val_actual_acc: 0.2628\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3120 - actual_acc: 0.1470 - val_loss: 2.4890 - val_actual_acc: 0.0465\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3878 - actual_acc: 0.1260 - val_loss: 2.3673 - val_actual_acc: 0.1535\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4106 - actual_acc: 0.1420 - val_loss: 2.4500 - val_actual_acc: 0.0884\n",
      "Epoch 393/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.2785 - actual_acc: 0.2030 - val_loss: 2.4155 - val_actual_acc: 0.1047\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3507 - actual_acc: 0.1660 - val_loss: 2.5168 - val_actual_acc: 0.0419\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4129 - actual_acc: 0.1580 - val_loss: 2.4188 - val_actual_acc: 0.1558\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.3209 - actual_acc: 0.1350 - val_loss: 2.3553 - val_actual_acc: 0.1233\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4439 - actual_acc: 0.1280 - val_loss: 2.3743 - val_actual_acc: 0.0535\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3621 - actual_acc: 0.2300 - val_loss: 2.3633 - val_actual_acc: 0.2047\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3790 - actual_acc: 0.1650 - val_loss: 2.4002 - val_actual_acc: 0.1465\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2891 - actual_acc: 0.2070 - val_loss: 2.6045 - val_actual_acc: 0.1070\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.3983 - actual_acc: 0.1020 - val_loss: 2.4816 - val_actual_acc: 0.0837\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3456 - actual_acc: 0.1360 - val_loss: 2.5046 - val_actual_acc: 0.1651\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.2849 - actual_acc: 0.1910 - val_loss: 2.3992 - val_actual_acc: 0.1372\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3608 - actual_acc: 0.1730 - val_loss: 2.5135 - val_actual_acc: 0.1233\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4061 - actual_acc: 0.1000 - val_loss: 2.3256 - val_actual_acc: 0.1488\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 2.4868 - actual_acc: 0.1420 - val_loss: 2.1641 - val_actual_acc: 0.2140\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4431 - actual_acc: 0.0900 - val_loss: 2.5801 - val_actual_acc: 0.0047\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5233 - actual_acc: 0.1080 - val_loss: 2.5175 - val_actual_acc: 0.0628\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4710 - actual_acc: 0.1300 - val_loss: 2.4382 - val_actual_acc: 0.1372\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 2.4500 - actual_acc: 0.1120 - val_loss: 2.5354 - val_actual_acc: 0.1163\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5976 - actual_acc: 0.0700 - val_loss: 2.7473 - val_actual_acc: 0.0581\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.3749 - actual_acc: 0.1440 - val_loss: 2.5243 - val_actual_acc: 0.0977\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4112 - actual_acc: 0.1690 - val_loss: 2.3609 - val_actual_acc: 0.1395\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4206 - actual_acc: 0.1020 - val_loss: 2.5042 - val_actual_acc: 0.1279\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3455 - actual_acc: 0.2360 - val_loss: 2.4845 - val_actual_acc: 0.1140\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.5533 - actual_acc: 0.0910 - val_loss: 2.4288 - val_actual_acc: 0.1512\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4240 - actual_acc: 0.1910 - val_loss: 2.5402 - val_actual_acc: 0.0767\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 2.4092 - actual_acc: 0.1040 - val_loss: 2.2394 - val_actual_acc: 0.2814\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3260 - actual_acc: 0.1600 - val_loss: 2.4218 - val_actual_acc: 0.1349\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3554 - actual_acc: 0.2060 - val_loss: 2.3986 - val_actual_acc: 0.1209\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5560 - actual_acc: 0.0810 - val_loss: 2.4811 - val_actual_acc: 0.0651\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.6356 - actual_acc: 0.0630 - val_loss: 2.3573 - val_actual_acc: 0.1791\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4950 - actual_acc: 0.1320 - val_loss: 2.3664 - val_actual_acc: 0.1767\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4374 - actual_acc: 0.1030 - val_loss: 2.3391 - val_actual_acc: 0.2698\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3852 - actual_acc: 0.1960 - val_loss: 2.2773 - val_actual_acc: 0.3349\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3446 - actual_acc: 0.1520 - val_loss: 2.2772 - val_actual_acc: 0.3860\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4039 - actual_acc: 0.2000 - val_loss: 2.5297 - val_actual_acc: 0.1093\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4431 - actual_acc: 0.1110 - val_loss: 2.3486 - val_actual_acc: 0.1279\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 2.4435 - actual_acc: 0.1150 - val_loss: 2.5583 - val_actual_acc: 0.0512\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4816 - actual_acc: 0.0730 - val_loss: 2.3850 - val_actual_acc: 0.0070\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.3599 - actual_acc: 0.1300 - val_loss: 2.3688 - val_actual_acc: 0.0651\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3660 - actual_acc: 0.2000 - val_loss: 2.3947 - val_actual_acc: 0.1256\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5505 - actual_acc: 0.0860 - val_loss: 2.3288 - val_actual_acc: 0.2209\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3775 - actual_acc: 0.1490 - val_loss: 2.3983 - val_actual_acc: 0.1442\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.6107 - actual_acc: 0.0530 - val_loss: 2.4361 - val_actual_acc: 0.1674\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.2977 - actual_acc: 0.1790 - val_loss: 2.4617 - val_actual_acc: 0.0953\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3652 - actual_acc: 0.1060 - val_loss: 2.3851 - val_actual_acc: 0.1186\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.4277 - actual_acc: 0.2010 - val_loss: 2.2135 - val_actual_acc: 0.1814\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3331 - actual_acc: 0.1860 - val_loss: 2.5225 - val_actual_acc: 0.0674\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.4297 - actual_acc: 0.1040 - val_loss: 2.5165 - val_actual_acc: 0.0744\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4280 - actual_acc: 0.1310 - val_loss: 2.3347 - val_actual_acc: 0.0977\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3744 - actual_acc: 0.1790 - val_loss: 2.4480 - val_actual_acc: 0.1047\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3921 - actual_acc: 0.1610 - val_loss: 2.4951 - val_actual_acc: 0.1651\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2789 - actual_acc: 0.1790 - val_loss: 2.3413 - val_actual_acc: 0.1349\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 2.3865 - actual_acc: 0.1480 - val_loss: 2.4282 - val_actual_acc: 0.1116\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.5945 - actual_acc: 0.0510 - val_loss: 2.5465 - val_actual_acc: 0.0651\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4493 - actual_acc: 0.1220 - val_loss: 2.2046 - val_actual_acc: 0.2698\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2571 - actual_acc: 0.2390 - val_loss: 2.3980 - val_actual_acc: 0.0302\n",
      "Epoch 449/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3977 - actual_acc: 0.1740 - val_loss: 2.4907 - val_actual_acc: 0.1744\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5941 - actual_acc: 0.0840 - val_loss: 2.3738 - val_actual_acc: 0.2140\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5429 - actual_acc: 0.1160 - val_loss: 2.5515 - val_actual_acc: 0.1326\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 29s 293ms/step - loss: 2.3878 - actual_acc: 0.1050 - val_loss: 2.4066 - val_actual_acc: 0.1907\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4617 - actual_acc: 0.0690 - val_loss: 2.4209 - val_actual_acc: 0.0465\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3701 - actual_acc: 0.2050 - val_loss: 2.4268 - val_actual_acc: 0.0767\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5236 - actual_acc: 0.0910 - val_loss: 2.4758 - val_actual_acc: 0.1209\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.4931 - actual_acc: 0.1330 - val_loss: 2.1878 - val_actual_acc: 0.3000\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3417 - actual_acc: 0.1760 - val_loss: 2.2425 - val_actual_acc: 0.4860\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4397 - actual_acc: 0.1120 - val_loss: 2.3511 - val_actual_acc: 0.3140\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.4071 - actual_acc: 0.1130 - val_loss: 2.2473 - val_actual_acc: 0.2186\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3944 - actual_acc: 0.2090 - val_loss: 2.4262 - val_actual_acc: 0.1047\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4440 - actual_acc: 0.1240 - val_loss: 2.4208 - val_actual_acc: 0.0140\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.5110 - actual_acc: 0.0870 - val_loss: 2.4966 - val_actual_acc: 0.1023\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4330 - actual_acc: 0.1280 - val_loss: 2.6345 - val_actual_acc: 0.0465\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.3865 - actual_acc: 0.1300 - val_loss: 2.4563 - val_actual_acc: 0.1209\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4208 - actual_acc: 0.0800 - val_loss: 2.3312 - val_actual_acc: 0.2116\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.3855 - actual_acc: 0.1390 - val_loss: 2.4371 - val_actual_acc: 0.1488\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3271 - actual_acc: 0.1960 - val_loss: 2.3829 - val_actual_acc: 0.2209\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4874 - actual_acc: 0.1200 - val_loss: 2.5891 - val_actual_acc: 0.1023\n",
      "Epoch 469/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3848 - actual_acc: 0.1510 - val_loss: 2.5785 - val_actual_acc: 0.0814\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3714 - actual_acc: 0.1990 - val_loss: 2.4036 - val_actual_acc: 0.1907\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4070 - actual_acc: 0.0970 - val_loss: 2.5085 - val_actual_acc: 0.1419\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4810 - actual_acc: 0.0570 - val_loss: 2.2469 - val_actual_acc: 0.1674\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4780 - actual_acc: 0.0870 - val_loss: 2.3724 - val_actual_acc: 0.1837\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4020 - actual_acc: 0.1720 - val_loss: 2.5508 - val_actual_acc: 0.1721\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3790 - actual_acc: 0.1240 - val_loss: 2.3662 - val_actual_acc: 0.1116\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3014 - actual_acc: 0.1900 - val_loss: 2.3578 - val_actual_acc: 0.2023\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4776 - actual_acc: 0.0770 - val_loss: 2.3789 - val_actual_acc: 0.2023\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 28s 277ms/step - loss: 2.4550 - actual_acc: 0.0950 - val_loss: 2.3507 - val_actual_acc: 0.2233\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3740 - actual_acc: 0.2230 - val_loss: 2.4728 - val_actual_acc: 0.0605\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.3531 - actual_acc: 0.0870 - val_loss: 2.2671 - val_actual_acc: 0.2581\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3775 - actual_acc: 0.1370 - val_loss: 2.4462 - val_actual_acc: 0.1698\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4461 - actual_acc: 0.1190 - val_loss: 2.2933 - val_actual_acc: 0.1977\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4160 - actual_acc: 0.1380 - val_loss: 2.3098 - val_actual_acc: 0.1791\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.4375 - actual_acc: 0.1490 - val_loss: 2.4280 - val_actual_acc: 0.1116\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4457 - actual_acc: 0.1460 - val_loss: 2.6986 - val_actual_acc: 0.1163\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3395 - actual_acc: 0.2160 - val_loss: 2.3650 - val_actual_acc: 0.1837\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 23s 230ms/step - loss: 2.3727 - actual_acc: 0.1680 - val_loss: 2.2670 - val_actual_acc: 0.2465\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3351 - actual_acc: 0.1860 - val_loss: 2.5695 - val_actual_acc: 0.0977\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.5063 - actual_acc: 0.1440 - val_loss: 2.5698 - val_actual_acc: 0.1186\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3722 - actual_acc: 0.1670 - val_loss: 2.1382 - val_actual_acc: 0.3349\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4114 - actual_acc: 0.1680 - val_loss: 2.2195 - val_actual_acc: 0.2558\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3839 - actual_acc: 0.1350 - val_loss: 2.7962 - val_actual_acc: 0.0395\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4771 - actual_acc: 0.0770 - val_loss: 2.2790 - val_actual_acc: 0.2093\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.4581 - actual_acc: 0.0690 - val_loss: 2.3880 - val_actual_acc: 0.0907\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.4518 - actual_acc: 0.0950 - val_loss: 2.3590 - val_actual_acc: 0.1093\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4355 - actual_acc: 0.1290 - val_loss: 2.3525 - val_actual_acc: 0.0791\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4017 - actual_acc: 0.0970 - val_loss: 2.2099 - val_actual_acc: 0.3233\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4470 - actual_acc: 0.0870 - val_loss: 2.5185 - val_actual_acc: 0.0674\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4104 - actual_acc: 0.1150 - val_loss: 2.5095 - val_actual_acc: 0.0116\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3965 - actual_acc: 0.1370 - val_loss: 2.2210 - val_actual_acc: 0.3953\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 29s 292ms/step - loss: 2.4928 - actual_acc: 0.0920 - val_loss: 2.3738 - val_actual_acc: 0.2140\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3528 - actual_acc: 0.1540 - val_loss: 2.2551 - val_actual_acc: 0.1465\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4399 - actual_acc: 0.1740 - val_loss: 2.5101 - val_actual_acc: 0.1465\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3698 - actual_acc: 0.1150 - val_loss: 2.3426 - val_actual_acc: 0.1093\n",
      "Epoch 505/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4980 - actual_acc: 0.0940 - val_loss: 2.5006 - val_actual_acc: 0.1465\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.5112 - actual_acc: 0.0940 - val_loss: 2.5670 - val_actual_acc: 0.0884\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4867 - actual_acc: 0.0710 - val_loss: 2.4810 - val_actual_acc: 0.0628\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.4349 - actual_acc: 0.1060 - val_loss: 2.4186 - val_actual_acc: 0.0791\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3563 - actual_acc: 0.2600 - val_loss: 2.5925 - val_actual_acc: 0.0395\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3932 - actual_acc: 0.1610 - val_loss: 2.3908 - val_actual_acc: 0.1163\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4529 - actual_acc: 0.0770 - val_loss: 2.1415 - val_actual_acc: 0.1977\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4377 - actual_acc: 0.1180 - val_loss: 2.5777 - val_actual_acc: 0.1209\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4011 - actual_acc: 0.1420 - val_loss: 2.3303 - val_actual_acc: 0.1674\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5110 - actual_acc: 0.1540 - val_loss: 2.4918 - val_actual_acc: 0.2000\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.6792 - actual_acc: 0.0670 - val_loss: 2.3136 - val_actual_acc: 0.2744\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3792 - actual_acc: 0.3430 - val_loss: 2.4301 - val_actual_acc: 0.0326\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4678 - actual_acc: 0.1350 - val_loss: 2.3189 - val_actual_acc: 0.2163\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.4543 - actual_acc: 0.1030 - val_loss: 2.3754 - val_actual_acc: 0.0674\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4620 - actual_acc: 0.1170 - val_loss: 2.4636 - val_actual_acc: 0.0744\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4300 - actual_acc: 0.1250 - val_loss: 2.3827 - val_actual_acc: 0.1674\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3461 - actual_acc: 0.1820 - val_loss: 2.5807 - val_actual_acc: 0.0163\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.3998 - actual_acc: 0.1760 - val_loss: 2.4733 - val_actual_acc: 0.1070\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.5068 - actual_acc: 0.0680 - val_loss: 2.4477 - val_actual_acc: 0.1651\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3779 - actual_acc: 0.1690 - val_loss: 2.6875 - val_actual_acc: 0.0302\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3935 - actual_acc: 0.1180 - val_loss: 2.3141 - val_actual_acc: 0.1651\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3173 - actual_acc: 0.1480 - val_loss: 2.6070 - val_actual_acc: 0.0930\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2653 - actual_acc: 0.2300 - val_loss: 2.3513 - val_actual_acc: 0.1302\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3821 - actual_acc: 0.1680 - val_loss: 2.4200 - val_actual_acc: 0.1395\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 2.3704 - actual_acc: 0.1580 - val_loss: 2.5688 - val_actual_acc: 0.1488\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4485 - actual_acc: 0.0890 - val_loss: 2.3628 - val_actual_acc: 0.1349\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4581 - actual_acc: 0.0930 - val_loss: 2.4785 - val_actual_acc: 0.0744\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4565 - actual_acc: 0.1150 - val_loss: 2.3913 - val_actual_acc: 0.1302\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5060 - actual_acc: 0.0810 - val_loss: 2.5040 - val_actual_acc: 0.0512\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.4301 - actual_acc: 0.1210 - val_loss: 2.4245 - val_actual_acc: 0.1093\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.4335 - actual_acc: 0.1880 - val_loss: 2.4185 - val_actual_acc: 0.0930\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3805 - actual_acc: 0.1380 - val_loss: 2.3788 - val_actual_acc: 0.1953\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4004 - actual_acc: 0.1200 - val_loss: 2.3746 - val_actual_acc: 0.2000\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.2834 - actual_acc: 0.1140 - val_loss: 2.4200 - val_actual_acc: 0.0698\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3740 - actual_acc: 0.1190 - val_loss: 2.4917 - val_actual_acc: 0.1349\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.3914 - actual_acc: 0.2280 - val_loss: 2.6486 - val_actual_acc: 0.0372\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.4762 - actual_acc: 0.1440 - val_loss: 2.2722 - val_actual_acc: 0.0512\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5436 - actual_acc: 0.0930 - val_loss: 2.3976 - val_actual_acc: 0.0651\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3568 - actual_acc: 0.1900 - val_loss: 2.4386 - val_actual_acc: 0.2349\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3106 - actual_acc: 0.2390 - val_loss: 2.5203 - val_actual_acc: 0.0488\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3284 - actual_acc: 0.1950 - val_loss: 2.2695 - val_actual_acc: 0.2721\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.5447 - actual_acc: 0.0780 - val_loss: 2.3755 - val_actual_acc: 0.1372\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3354 - actual_acc: 0.1580 - val_loss: 2.5370 - val_actual_acc: 0.1163\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4386 - actual_acc: 0.1520 - val_loss: 2.5559 - val_actual_acc: 0.1140\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4213 - actual_acc: 0.1590 - val_loss: 2.3265 - val_actual_acc: 0.1930\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4200 - actual_acc: 0.0980 - val_loss: 2.3951 - val_actual_acc: 0.1721\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3877 - actual_acc: 0.1520 - val_loss: 2.2552 - val_actual_acc: 0.1930\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.5224 - actual_acc: 0.0530 - val_loss: 2.3763 - val_actual_acc: 0.0698\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3103 - actual_acc: 0.1800 - val_loss: 2.4513 - val_actual_acc: 0.0698\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.4192 - actual_acc: 0.1400 - val_loss: 2.5552 - val_actual_acc: 0.1093\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4631 - actual_acc: 0.1310 - val_loss: 2.4352 - val_actual_acc: 0.1209\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5868 - actual_acc: 0.0640 - val_loss: 2.4715 - val_actual_acc: 0.0721\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3906 - actual_acc: 0.1220 - val_loss: 2.5412 - val_actual_acc: 0.1605\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4294 - actual_acc: 0.0920 - val_loss: 2.5625 - val_actual_acc: 0.0721\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4639 - actual_acc: 0.1150 - val_loss: 2.4316 - val_actual_acc: 0.1930\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5669 - actual_acc: 0.0870 - val_loss: 2.5154 - val_actual_acc: 0.0860\n",
      "Epoch 561/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.4511 - actual_acc: 0.1720 - val_loss: 2.3871 - val_actual_acc: 0.2907\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4618 - actual_acc: 0.1270 - val_loss: 2.4992 - val_actual_acc: 0.1093\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 2.4487 - actual_acc: 0.1300 - val_loss: 2.4211 - val_actual_acc: 0.1488\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5265 - actual_acc: 0.1220 - val_loss: 2.3720 - val_actual_acc: 0.0698\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4492 - actual_acc: 0.1230 - val_loss: 2.5056 - val_actual_acc: 0.0605\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4686 - actual_acc: 0.1460 - val_loss: 2.4396 - val_actual_acc: 0.0558\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3177 - actual_acc: 0.2070 - val_loss: 2.5160 - val_actual_acc: 0.0860\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 2.4464 - actual_acc: 0.0840 - val_loss: 2.4849 - val_actual_acc: 0.0953\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.3561 - actual_acc: 0.0800 - val_loss: 2.4488 - val_actual_acc: 0.0186\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3288 - actual_acc: 0.1100 - val_loss: 2.4969 - val_actual_acc: 0.0930\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3731 - actual_acc: 0.1790 - val_loss: 2.5358 - val_actual_acc: 0.0884\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4416 - actual_acc: 0.1200 - val_loss: 2.5777 - val_actual_acc: 0.0186\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3889 - actual_acc: 0.2070 - val_loss: 2.3705 - val_actual_acc: 0.1512\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4736 - actual_acc: 0.1030 - val_loss: 2.4599 - val_actual_acc: 0.1442\n",
      "Epoch 575/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 24s 242ms/step - loss: 2.4134 - actual_acc: 0.2030 - val_loss: 2.4388 - val_actual_acc: 0.1116\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2533 - actual_acc: 0.2920 - val_loss: 2.4442 - val_actual_acc: 0.1186\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5112 - actual_acc: 0.1270 - val_loss: 2.7046 - val_actual_acc: 0.0326\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5084 - actual_acc: 0.0990 - val_loss: 2.4538 - val_actual_acc: 0.0977\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3913 - actual_acc: 0.1080 - val_loss: 2.2510 - val_actual_acc: 0.1698\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.5787 - actual_acc: 0.1310 - val_loss: 2.4186 - val_actual_acc: 0.2047\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4671 - actual_acc: 0.1160 - val_loss: 2.3757 - val_actual_acc: 0.2116\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.4447 - actual_acc: 0.1330 - val_loss: 2.6406 - val_actual_acc: 0.1000\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4454 - actual_acc: 0.1180 - val_loss: 2.2187 - val_actual_acc: 0.3140\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4202 - actual_acc: 0.1290 - val_loss: 2.4702 - val_actual_acc: 0.1674\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4127 - actual_acc: 0.1710 - val_loss: 2.3339 - val_actual_acc: 0.0907\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.2975 - actual_acc: 0.1570 - val_loss: 2.5025 - val_actual_acc: 0.1651\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4043 - actual_acc: 0.1980 - val_loss: 2.4904 - val_actual_acc: 0.1302\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4036 - actual_acc: 0.1400 - val_loss: 2.6565 - val_actual_acc: 0.0349\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 2.3375 - actual_acc: 0.2750 - val_loss: 2.5236 - val_actual_acc: 0.1349\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4287 - actual_acc: 0.0910 - val_loss: 2.2680 - val_actual_acc: 0.2465\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.4714 - actual_acc: 0.1200 - val_loss: 2.3770 - val_actual_acc: 0.0953\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3668 - actual_acc: 0.1000 - val_loss: 2.3961 - val_actual_acc: 0.1930\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3398 - actual_acc: 0.1830 - val_loss: 2.4071 - val_actual_acc: 0.1140\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4655 - actual_acc: 0.1160 - val_loss: 2.3948 - val_actual_acc: 0.0698\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4354 - actual_acc: 0.1690 - val_loss: 2.3983 - val_actual_acc: 0.1023\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.4328 - actual_acc: 0.1400 - val_loss: 2.2975 - val_actual_acc: 0.0977\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.4923 - actual_acc: 0.0790 - val_loss: 2.3621 - val_actual_acc: 0.1163\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3295 - actual_acc: 0.0740 - val_loss: 2.4604 - val_actual_acc: 0.1047\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.5177 - actual_acc: 0.0980 - val_loss: 2.3258 - val_actual_acc: 0.1349\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.5329 - actual_acc: 0.0850 - val_loss: 2.3791 - val_actual_acc: 0.0744\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3885 - actual_acc: 0.1190 - val_loss: 2.4038 - val_actual_acc: 0.1326\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3204 - actual_acc: 0.1610 - val_loss: 2.4623 - val_actual_acc: 0.1279\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 31s 308ms/step - loss: 2.4228 - actual_acc: 0.1560 - val_loss: 2.3943 - val_actual_acc: 0.1302\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3401 - actual_acc: 0.2120 - val_loss: 2.4832 - val_actual_acc: 0.0512\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4818 - actual_acc: 0.0420 - val_loss: 2.3822 - val_actual_acc: 0.1651\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4561 - actual_acc: 0.1050 - val_loss: 2.3487 - val_actual_acc: 0.0674\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4287 - actual_acc: 0.1450 - val_loss: 2.5868 - val_actual_acc: 0.0698\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.2123 - actual_acc: 0.2160 - val_loss: 2.3539 - val_actual_acc: 0.1372\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3544 - actual_acc: 0.2490 - val_loss: 2.3820 - val_actual_acc: 0.2860\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.3885 - actual_acc: 0.1600 - val_loss: 2.6262 - val_actual_acc: 0.0070\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4390 - actual_acc: 0.1090 - val_loss: 2.3923 - val_actual_acc: 0.2395\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3143 - actual_acc: 0.0650 - val_loss: 2.4313 - val_actual_acc: 0.1884\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3973 - actual_acc: 0.1840 - val_loss: 2.4346 - val_actual_acc: 0.2349\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3551 - actual_acc: 0.0690 - val_loss: 2.3496 - val_actual_acc: 0.1395\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3938 - actual_acc: 0.1290 - val_loss: 2.3448 - val_actual_acc: 0.0860\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3670 - actual_acc: 0.1140 - val_loss: 2.4998 - val_actual_acc: 0.1047\n",
      "Epoch 617/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.3905 - actual_acc: 0.2610 - val_loss: 2.4216 - val_actual_acc: 0.1302\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4199 - actual_acc: 0.1810 - val_loss: 2.3534 - val_actual_acc: 0.2093\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3544 - actual_acc: 0.1280 - val_loss: 2.4573 - val_actual_acc: 0.0767\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3859 - actual_acc: 0.1710 - val_loss: 2.3124 - val_actual_acc: 0.2116\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4602 - actual_acc: 0.1380 - val_loss: 2.3368 - val_actual_acc: 0.1698\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4683 - actual_acc: 0.0610 - val_loss: 2.4350 - val_actual_acc: 0.1791\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3986 - actual_acc: 0.1300 - val_loss: 2.3639 - val_actual_acc: 0.2419\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.5633 - actual_acc: 0.1090 - val_loss: 2.5248 - val_actual_acc: 0.0442\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.3199 - actual_acc: 0.1280 - val_loss: 2.5501 - val_actual_acc: 0.0209\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3532 - actual_acc: 0.2030 - val_loss: 2.3419 - val_actual_acc: 0.1140\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2879 - actual_acc: 0.2590 - val_loss: 2.2019 - val_actual_acc: 0.3628\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3317 - actual_acc: 0.1340 - val_loss: 2.2463 - val_actual_acc: 0.1279\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3988 - actual_acc: 0.1080 - val_loss: 2.4631 - val_actual_acc: 0.1093\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4596 - actual_acc: 0.1660 - val_loss: 2.4459 - val_actual_acc: 0.1349\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 2.3944 - actual_acc: 0.1700 - val_loss: 2.4709 - val_actual_acc: 0.1023\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4288 - actual_acc: 0.1210 - val_loss: 2.3903 - val_actual_acc: 0.1558\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4861 - actual_acc: 0.1660 - val_loss: 2.4302 - val_actual_acc: 0.1628\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4962 - actual_acc: 0.0660 - val_loss: 2.4190 - val_actual_acc: 0.1395\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4103 - actual_acc: 0.1460 - val_loss: 2.5546 - val_actual_acc: 0.0186\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4707 - actual_acc: 0.1280 - val_loss: 2.3912 - val_actual_acc: 0.1884\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4407 - actual_acc: 0.1260 - val_loss: 2.2101 - val_actual_acc: 0.2907\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4602 - actual_acc: 0.1630 - val_loss: 2.4789 - val_actual_acc: 0.1163\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4434 - actual_acc: 0.0770 - val_loss: 2.4110 - val_actual_acc: 0.0209\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5764 - actual_acc: 0.0830 - val_loss: 2.5702 - val_actual_acc: 0.0860\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4237 - actual_acc: 0.1230 - val_loss: 2.5876 - val_actual_acc: 0.0651\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 24s 243ms/step - loss: 2.3693 - actual_acc: 0.1160 - val_loss: 2.4340 - val_actual_acc: 0.1070\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3232 - actual_acc: 0.2160 - val_loss: 2.5160 - val_actual_acc: 0.0744\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.2357 - actual_acc: 0.2920 - val_loss: 2.4469 - val_actual_acc: 0.1674\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.2534 - actual_acc: 0.3190 - val_loss: 2.2498 - val_actual_acc: 0.2930\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.1482 - actual_acc: 0.3930 - val_loss: 2.5706 - val_actual_acc: 0.0907\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4452 - actual_acc: 0.0880 - val_loss: 2.2979 - val_actual_acc: 0.1186\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4311 - actual_acc: 0.0610 - val_loss: 2.5134 - val_actual_acc: 0.0721\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3120 - actual_acc: 0.1120 - val_loss: 2.4413 - val_actual_acc: 0.0860\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.1413 - actual_acc: 0.1800 - val_loss: 2.6605 - val_actual_acc: 0.0814\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3879 - actual_acc: 0.1110 - val_loss: 2.3276 - val_actual_acc: 0.1558\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.5539 - actual_acc: 0.0960 - val_loss: 2.4077 - val_actual_acc: 0.1163\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3261 - actual_acc: 0.1630 - val_loss: 2.6523 - val_actual_acc: 0.0372\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4784 - actual_acc: 0.1200 - val_loss: 2.2749 - val_actual_acc: 0.2488\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.3638 - actual_acc: 0.2770 - val_loss: 2.5064 - val_actual_acc: 0.0814\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4241 - actual_acc: 0.2160 - val_loss: 2.7723 - val_actual_acc: 0.0884\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4592 - actual_acc: 0.1620 - val_loss: 2.6348 - val_actual_acc: 0.0488\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.3891 - actual_acc: 0.0900 - val_loss: 2.4262 - val_actual_acc: 0.1419\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 32s 324ms/step - loss: 2.3392 - actual_acc: 0.1550 - val_loss: 2.4214 - val_actual_acc: 0.2628\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4259 - actual_acc: 0.1860 - val_loss: 2.5114 - val_actual_acc: 0.0465\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2675 - actual_acc: 0.0410 - val_loss: 2.3727 - val_actual_acc: 0.1535\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4116 - actual_acc: 0.2020 - val_loss: 2.4688 - val_actual_acc: 0.0884\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.0710 - actual_acc: 0.3340 - val_loss: 2.4054 - val_actual_acc: 0.1047\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4776 - actual_acc: 0.1350 - val_loss: 2.5283 - val_actual_acc: 0.0419\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.5588 - actual_acc: 0.1060 - val_loss: 2.4151 - val_actual_acc: 0.1558\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4880 - actual_acc: 0.0800 - val_loss: 2.3831 - val_actual_acc: 0.1233\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.3992 - actual_acc: 0.1530 - val_loss: 2.4066 - val_actual_acc: 0.0535\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3614 - actual_acc: 0.1810 - val_loss: 2.3582 - val_actual_acc: 0.2047\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4996 - actual_acc: 0.1560 - val_loss: 2.4010 - val_actual_acc: 0.1465\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4073 - actual_acc: 0.0970 - val_loss: 2.5989 - val_actual_acc: 0.1070\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4745 - actual_acc: 0.0900 - val_loss: 2.4863 - val_actual_acc: 0.0837\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4083 - actual_acc: 0.1390 - val_loss: 2.4968 - val_actual_acc: 0.1651\n",
      "Epoch 673/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.5294 - actual_acc: 0.0640 - val_loss: 2.3911 - val_actual_acc: 0.1372\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4101 - actual_acc: 0.1370 - val_loss: 2.4756 - val_actual_acc: 0.1233\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4410 - actual_acc: 0.1450 - val_loss: 2.3351 - val_actual_acc: 0.1488\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.6314 - actual_acc: 0.1070 - val_loss: 2.1541 - val_actual_acc: 0.2140\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.5319 - actual_acc: 0.0900 - val_loss: 2.5479 - val_actual_acc: 0.0047\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.3742 - actual_acc: 0.1990 - val_loss: 2.4856 - val_actual_acc: 0.0628\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4337 - actual_acc: 0.1260 - val_loss: 2.4519 - val_actual_acc: 0.1372\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4029 - actual_acc: 0.1100 - val_loss: 2.5372 - val_actual_acc: 0.0884\n",
      "Epoch 681/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4804 - actual_acc: 0.1260 - val_loss: 2.7127 - val_actual_acc: 0.0256\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4639 - actual_acc: 0.1930 - val_loss: 2.5323 - val_actual_acc: 0.0744\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4705 - actual_acc: 0.0240 - val_loss: 2.3741 - val_actual_acc: 0.1814\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.3569 - actual_acc: 0.1040 - val_loss: 2.4905 - val_actual_acc: 0.0419\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.3347 - actual_acc: 0.2860 - val_loss: 2.4653 - val_actual_acc: 0.1209\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4900 - actual_acc: 0.1020 - val_loss: 2.4298 - val_actual_acc: 0.1535\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 23s 232ms/step - loss: 2.4065 - actual_acc: 0.1300 - val_loss: 2.5367 - val_actual_acc: 0.0930\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.4335 - actual_acc: 0.0640 - val_loss: 2.2600 - val_actual_acc: 0.1558\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4158 - actual_acc: 0.1230 - val_loss: 2.4408 - val_actual_acc: 0.1442\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3336 - actual_acc: 0.2190 - val_loss: 2.4075 - val_actual_acc: 0.1837\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4115 - actual_acc: 0.1180 - val_loss: 2.4650 - val_actual_acc: 0.1698\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4995 - actual_acc: 0.0910 - val_loss: 2.3543 - val_actual_acc: 0.1465\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4544 - actual_acc: 0.2100 - val_loss: 2.3736 - val_actual_acc: 0.2140\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3109 - actual_acc: 0.2590 - val_loss: 2.3452 - val_actual_acc: 0.0814\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3619 - actual_acc: 0.1530 - val_loss: 2.3222 - val_actual_acc: 0.0930\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4211 - actual_acc: 0.1390 - val_loss: 2.2957 - val_actual_acc: 0.0209\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4060 - actual_acc: 0.0650 - val_loss: 2.5015 - val_actual_acc: 0.0651\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3404 - actual_acc: 0.1470 - val_loss: 2.3847 - val_actual_acc: 0.1442\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3802 - actual_acc: 0.1860 - val_loss: 2.5439 - val_actual_acc: 0.1256\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3506 - actual_acc: 0.1820 - val_loss: 2.3714 - val_actual_acc: 0.2093\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.3775 - actual_acc: 0.1550 - val_loss: 2.3528 - val_actual_acc: 0.2651\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4243 - actual_acc: 0.1760 - val_loss: 2.4166 - val_actual_acc: 0.1442\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3887 - actual_acc: 0.1380 - val_loss: 2.2978 - val_actual_acc: 0.1465\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4993 - actual_acc: 0.1330 - val_loss: 2.3915 - val_actual_acc: 0.1070\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.3920 - actual_acc: 0.1410 - val_loss: 2.4559 - val_actual_acc: 0.1209\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4125 - actual_acc: 0.1880 - val_loss: 2.5029 - val_actual_acc: 0.1023\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4291 - actual_acc: 0.1460 - val_loss: 2.3895 - val_actual_acc: 0.1186\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.5784 - actual_acc: 0.0620 - val_loss: 2.2140 - val_actual_acc: 0.1814\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 19s 185ms/step - loss: 2.4343 - actual_acc: 0.1050 - val_loss: 2.5125 - val_actual_acc: 0.0674\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.5039 - actual_acc: 0.1060 - val_loss: 2.5221 - val_actual_acc: 0.0744\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.5169 - actual_acc: 0.0850 - val_loss: 2.3349 - val_actual_acc: 0.2442\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.5021 - actual_acc: 0.1170 - val_loss: 2.4576 - val_actual_acc: 0.0721\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.3901 - actual_acc: 0.0920 - val_loss: 2.4964 - val_actual_acc: 0.0884\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.4928 - actual_acc: 0.0870 - val_loss: 2.3422 - val_actual_acc: 0.1349\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3852 - actual_acc: 0.1600 - val_loss: 2.4257 - val_actual_acc: 0.1116\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4313 - actual_acc: 0.1680 - val_loss: 2.5290 - val_actual_acc: 0.0651\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.3946 - actual_acc: 0.1530 - val_loss: 2.2070 - val_actual_acc: 0.3512\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 2.3318 - actual_acc: 0.1450 - val_loss: 2.3906 - val_actual_acc: 0.0860\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 2.4576 - actual_acc: 0.0800 - val_loss: 2.4809 - val_actual_acc: 0.1744\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 2.3522 - actual_acc: 0.2490 - val_loss: 2.3759 - val_actual_acc: 0.2140\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 19s 187ms/step - loss: 2.4755 - actual_acc: 0.0760 - val_loss: 2.5320 - val_actual_acc: 0.1140\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 31s 314ms/step - loss: 2.4412 - actual_acc: 0.1600 - val_loss: 2.4047 - val_actual_acc: 0.1907\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2912 - actual_acc: 0.1630 - val_loss: 2.4232 - val_actual_acc: 0.0465\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4043 - actual_acc: 0.1190 - val_loss: 2.4139 - val_actual_acc: 0.0767\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.4124 - actual_acc: 0.1360 - val_loss: 2.4782 - val_actual_acc: 0.1209\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.2554 - actual_acc: 0.1880 - val_loss: 2.1808 - val_actual_acc: 0.3000\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 2.3948 - actual_acc: 0.1750 - val_loss: 2.2567 - val_actual_acc: 0.4860\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 18s 185ms/step - loss: 2.3595 - actual_acc: 0.1820 - val_loss: 2.3617 - val_actual_acc: 0.3140\n",
      "Epoch 729/1000\n",
      "100/100 [==============================] - 25s 255ms/step - loss: 2.3479 - actual_acc: 0.1260 - val_loss: 2.2254 - val_actual_acc: 0.2186\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.4076 - actual_acc: 0.1040 - val_loss: 2.4495 - val_actual_acc: 0.1326\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3912 - actual_acc: 0.2800 - val_loss: 2.3803 - val_actual_acc: 0.2744\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 2.3769 - actual_acc: 0.1540 - val_loss: 2.5219 - val_actual_acc: 0.0721\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 19s 188ms/step - loss: 2.3187 - actual_acc: 0.1750 - val_loss: 2.7654 - val_actual_acc: 0.0256\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3976 - actual_acc: 0.0980 - val_loss: 2.4949 - val_actual_acc: 0.0698\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3220 - actual_acc: 0.1330 - val_loss: 2.3266 - val_actual_acc: 0.2116\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.3029 - actual_acc: 0.1940 - val_loss: 2.4541 - val_actual_acc: 0.1093\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3243 - actual_acc: 0.2200 - val_loss: 2.3801 - val_actual_acc: 0.1326\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4747 - actual_acc: 0.0500 - val_loss: 2.6488 - val_actual_acc: 0.1023\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4247 - actual_acc: 0.1600 - val_loss: 2.5780 - val_actual_acc: 0.1140\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4377 - actual_acc: 0.0720 - val_loss: 2.4318 - val_actual_acc: 0.1163\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5657 - actual_acc: 0.1130 - val_loss: 2.5014 - val_actual_acc: 0.0860\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.4933 - actual_acc: 0.1270 - val_loss: 2.2474 - val_actual_acc: 0.1674\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 2.4435 - actual_acc: 0.1180 - val_loss: 2.3904 - val_actual_acc: 0.1837\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5939 - actual_acc: 0.0650 - val_loss: 2.5288 - val_actual_acc: 0.1721\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3525 - actual_acc: 0.1620 - val_loss: 2.3739 - val_actual_acc: 0.1116\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4248 - actual_acc: 0.1650 - val_loss: 2.3365 - val_actual_acc: 0.2023\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3792 - actual_acc: 0.0970 - val_loss: 2.4142 - val_actual_acc: 0.2023\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.3724 - actual_acc: 0.2640 - val_loss: 2.3399 - val_actual_acc: 0.2233\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5782 - actual_acc: 0.0660 - val_loss: 2.4846 - val_actual_acc: 0.0605\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.4230 - actual_acc: 0.1760 - val_loss: 2.2795 - val_actual_acc: 0.2581\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3853 - actual_acc: 0.1070 - val_loss: 2.4282 - val_actual_acc: 0.1698\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3212 - actual_acc: 0.1620 - val_loss: 2.2945 - val_actual_acc: 0.1977\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3873 - actual_acc: 0.2010 - val_loss: 2.3131 - val_actual_acc: 0.1791\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 26s 264ms/step - loss: 2.5759 - actual_acc: 0.0810 - val_loss: 2.5038 - val_actual_acc: 0.1116\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5987 - actual_acc: 0.0720 - val_loss: 2.6499 - val_actual_acc: 0.1163\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4694 - actual_acc: 0.1340 - val_loss: 2.3507 - val_actual_acc: 0.1837\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 23s 229ms/step - loss: 2.4741 - actual_acc: 0.0970 - val_loss: 2.2883 - val_actual_acc: 0.2465\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3393 - actual_acc: 0.2120 - val_loss: 2.5354 - val_actual_acc: 0.0977\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3552 - actual_acc: 0.1520 - val_loss: 2.5395 - val_actual_acc: 0.1186\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4551 - actual_acc: 0.1790 - val_loss: 2.1563 - val_actual_acc: 0.3349\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4052 - actual_acc: 0.1110 - val_loss: 2.2498 - val_actual_acc: 0.2558\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4866 - actual_acc: 0.1150 - val_loss: 2.7416 - val_actual_acc: 0.0395\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4426 - actual_acc: 0.0910 - val_loss: 2.3145 - val_actual_acc: 0.2093\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.3474 - actual_acc: 0.1480 - val_loss: 2.4298 - val_actual_acc: 0.0907\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.3861 - actual_acc: 0.1820 - val_loss: 2.3375 - val_actual_acc: 0.2186\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5086 - actual_acc: 0.1170 - val_loss: 2.3136 - val_actual_acc: 0.1860\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4107 - actual_acc: 0.1000 - val_loss: 2.2062 - val_actual_acc: 0.1698\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.6268 - actual_acc: 0.0540 - val_loss: 2.4816 - val_actual_acc: 0.1256\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2696 - actual_acc: 0.1780 - val_loss: 2.3978 - val_actual_acc: 0.2721\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3816 - actual_acc: 0.1260 - val_loss: 2.1974 - val_actual_acc: 0.3953\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 31s 306ms/step - loss: 2.4187 - actual_acc: 0.2040 - val_loss: 2.3630 - val_actual_acc: 0.2140\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3289 - actual_acc: 0.1650 - val_loss: 2.2646 - val_actual_acc: 0.1465\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4171 - actual_acc: 0.1080 - val_loss: 2.4904 - val_actual_acc: 0.1465\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4304 - actual_acc: 0.1660 - val_loss: 2.3651 - val_actual_acc: 0.1093\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4277 - actual_acc: 0.1430 - val_loss: 2.5355 - val_actual_acc: 0.1465\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.3118 - actual_acc: 0.2080 - val_loss: 2.6510 - val_actual_acc: 0.0186\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2889 - actual_acc: 0.1270 - val_loss: 2.5115 - val_actual_acc: 0.0628\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 25s 247ms/step - loss: 2.4332 - actual_acc: 0.1640 - val_loss: 2.4051 - val_actual_acc: 0.0791\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5737 - actual_acc: 0.0350 - val_loss: 2.6183 - val_actual_acc: 0.0395\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4210 - actual_acc: 0.1710 - val_loss: 2.4225 - val_actual_acc: 0.0837\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2780 - actual_acc: 0.1900 - val_loss: 2.0615 - val_actual_acc: 0.4930\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4607 - actual_acc: 0.1740 - val_loss: 2.5513 - val_actual_acc: 0.1512\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5864 - actual_acc: 0.0910 - val_loss: 2.3409 - val_actual_acc: 0.1674\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4852 - actual_acc: 0.1410 - val_loss: 2.4904 - val_actual_acc: 0.0744\n",
      "Epoch 785/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 2.4294 - actual_acc: 0.0750 - val_loss: 2.2693 - val_actual_acc: 0.2744\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3834 - actual_acc: 0.1290 - val_loss: 2.4122 - val_actual_acc: 0.0326\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4338 - actual_acc: 0.1520 - val_loss: 2.2751 - val_actual_acc: 0.2163\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.5478 - actual_acc: 0.0920 - val_loss: 2.3710 - val_actual_acc: 0.0674\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4219 - actual_acc: 0.1750 - val_loss: 2.4793 - val_actual_acc: 0.0744\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3885 - actual_acc: 0.1510 - val_loss: 2.3880 - val_actual_acc: 0.1674\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4387 - actual_acc: 0.1000 - val_loss: 2.6096 - val_actual_acc: 0.0163\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.3648 - actual_acc: 0.1200 - val_loss: 2.4836 - val_actual_acc: 0.1163\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.4370 - actual_acc: 0.1920 - val_loss: 2.4606 - val_actual_acc: 0.1070\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4122 - actual_acc: 0.1350 - val_loss: 2.6771 - val_actual_acc: 0.0628\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5390 - actual_acc: 0.0770 - val_loss: 2.3431 - val_actual_acc: 0.1674\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4184 - actual_acc: 0.1430 - val_loss: 2.6158 - val_actual_acc: 0.0930\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3768 - actual_acc: 0.1150 - val_loss: 2.3549 - val_actual_acc: 0.1302\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4291 - actual_acc: 0.1010 - val_loss: 2.3955 - val_actual_acc: 0.1395\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 31s 309ms/step - loss: 2.3937 - actual_acc: 0.1400 - val_loss: 2.5704 - val_actual_acc: 0.1488\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3052 - actual_acc: 0.2290 - val_loss: 2.3804 - val_actual_acc: 0.1349\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5261 - actual_acc: 0.0590 - val_loss: 2.4832 - val_actual_acc: 0.1651\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3672 - actual_acc: 0.1660 - val_loss: 2.4060 - val_actual_acc: 0.1791\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3719 - actual_acc: 0.1960 - val_loss: 2.5110 - val_actual_acc: 0.0977\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4324 - actual_acc: 0.0900 - val_loss: 2.4314 - val_actual_acc: 0.1488\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.4359 - actual_acc: 0.0780 - val_loss: 2.4151 - val_actual_acc: 0.1581\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.5461 - actual_acc: 0.0700 - val_loss: 2.4003 - val_actual_acc: 0.0070\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3463 - actual_acc: 0.1830 - val_loss: 2.3588 - val_actual_acc: 0.1535\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3934 - actual_acc: 0.1270 - val_loss: 2.4197 - val_actual_acc: 0.1721\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3206 - actual_acc: 0.1700 - val_loss: 2.4773 - val_actual_acc: 0.0860\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 2.4615 - actual_acc: 0.0740 - val_loss: 2.6057 - val_actual_acc: 0.0140\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4469 - actual_acc: 0.1200 - val_loss: 2.2451 - val_actual_acc: 0.4326\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3651 - actual_acc: 0.2110 - val_loss: 2.3917 - val_actual_acc: 0.1465\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 23s 231ms/step - loss: 2.3834 - actual_acc: 0.0750 - val_loss: 2.4768 - val_actual_acc: 0.0395\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3265 - actual_acc: 0.1590 - val_loss: 2.5113 - val_actual_acc: 0.1651\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4420 - actual_acc: 0.1100 - val_loss: 2.2792 - val_actual_acc: 0.0581\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.4355 - actual_acc: 0.1410 - val_loss: 2.3730 - val_actual_acc: 0.1326\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4576 - actual_acc: 0.1390 - val_loss: 2.5406 - val_actual_acc: 0.0372\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4653 - actual_acc: 0.1430 - val_loss: 2.5647 - val_actual_acc: 0.0651\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2791 - actual_acc: 0.2560 - val_loss: 2.3391 - val_actual_acc: 0.2000\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4103 - actual_acc: 0.1400 - val_loss: 2.4007 - val_actual_acc: 0.1279\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3202 - actual_acc: 0.1960 - val_loss: 2.2272 - val_actual_acc: 0.2000\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 2.5424 - actual_acc: 0.1180 - val_loss: 2.3726 - val_actual_acc: 0.2791\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3246 - actual_acc: 0.1850 - val_loss: 2.4578 - val_actual_acc: 0.1930\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4277 - actual_acc: 0.1550 - val_loss: 2.5955 - val_actual_acc: 0.0395\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3778 - actual_acc: 0.1330 - val_loss: 2.4355 - val_actual_acc: 0.1256\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4999 - actual_acc: 0.0920 - val_loss: 2.4704 - val_actual_acc: 0.1465\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 31s 315ms/step - loss: 2.4352 - actual_acc: 0.0510 - val_loss: 2.5482 - val_actual_acc: 0.0023\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4665 - actual_acc: 0.1190 - val_loss: 2.5448 - val_actual_acc: 0.0721\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4265 - actual_acc: 0.1100 - val_loss: 2.4511 - val_actual_acc: 0.0860\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4212 - actual_acc: 0.0960 - val_loss: 2.5317 - val_actual_acc: 0.0698\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4281 - actual_acc: 0.0980 - val_loss: 2.4068 - val_actual_acc: 0.0465\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4092 - actual_acc: 0.1090 - val_loss: 2.5066 - val_actual_acc: 0.1698\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.4236 - actual_acc: 0.1450 - val_loss: 2.4148 - val_actual_acc: 0.1070\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 27s 265ms/step - loss: 2.4480 - actual_acc: 0.0780 - val_loss: 2.3591 - val_actual_acc: 0.3116\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3831 - actual_acc: 0.1870 - val_loss: 2.4926 - val_actual_acc: 0.1349\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4376 - actual_acc: 0.1720 - val_loss: 2.4117 - val_actual_acc: 0.1023\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3666 - actual_acc: 0.1060 - val_loss: 2.5234 - val_actual_acc: 0.1465\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4974 - actual_acc: 0.0690 - val_loss: 2.4871 - val_actual_acc: 0.0512\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 24s 235ms/step - loss: 2.5198 - actual_acc: 0.0940 - val_loss: 2.4454 - val_actual_acc: 0.0186\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4781 - actual_acc: 0.0880 - val_loss: 2.5016 - val_actual_acc: 0.0930\n",
      "Epoch 841/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 2.4737 - actual_acc: 0.0910 - val_loss: 2.5498 - val_actual_acc: 0.1000\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3324 - actual_acc: 0.2630 - val_loss: 2.5856 - val_actual_acc: 0.1395\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3717 - actual_acc: 0.1560 - val_loss: 2.3708 - val_actual_acc: 0.1512\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.4629 - actual_acc: 0.0830 - val_loss: 2.4400 - val_actual_acc: 0.1442\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4411 - actual_acc: 0.1170 - val_loss: 2.4237 - val_actual_acc: 0.1116\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4029 - actual_acc: 0.1460 - val_loss: 2.4384 - val_actual_acc: 0.1395\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5078 - actual_acc: 0.1750 - val_loss: 2.7123 - val_actual_acc: 0.0186\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 23s 234ms/step - loss: 2.6977 - actual_acc: 0.0370 - val_loss: 2.4605 - val_actual_acc: 0.1791\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3585 - actual_acc: 0.3740 - val_loss: 2.2671 - val_actual_acc: 0.2791\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 25s 245ms/step - loss: 2.4743 - actual_acc: 0.1200 - val_loss: 2.4222 - val_actual_acc: 0.1465\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4325 - actual_acc: 0.1360 - val_loss: 2.3923 - val_actual_acc: 0.1581\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4811 - actual_acc: 0.0680 - val_loss: 2.6576 - val_actual_acc: 0.0512\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4283 - actual_acc: 0.1250 - val_loss: 2.2267 - val_actual_acc: 0.1605\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3660 - actual_acc: 0.1830 - val_loss: 2.4915 - val_actual_acc: 0.1256\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.3766 - actual_acc: 0.1810 - val_loss: 2.3208 - val_actual_acc: 0.2419\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4996 - actual_acc: 0.0620 - val_loss: 2.5067 - val_actual_acc: 0.0558\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3645 - actual_acc: 0.1710 - val_loss: 2.4478 - val_actual_acc: 0.0651\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4197 - actual_acc: 0.1260 - val_loss: 2.6179 - val_actual_acc: 0.0349\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2891 - actual_acc: 0.1670 - val_loss: 2.5194 - val_actual_acc: 0.1349\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2993 - actual_acc: 0.2220 - val_loss: 2.2707 - val_actual_acc: 0.2465\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 2.3485 - actual_acc: 0.1700 - val_loss: 2.4040 - val_actual_acc: 0.0953\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 24s 236ms/step - loss: 2.3904 - actual_acc: 0.1370 - val_loss: 2.3830 - val_actual_acc: 0.1930\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4365 - actual_acc: 0.0890 - val_loss: 2.3867 - val_actual_acc: 0.1907\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4637 - actual_acc: 0.1100 - val_loss: 2.3907 - val_actual_acc: 0.2279\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4751 - actual_acc: 0.0980 - val_loss: 2.4061 - val_actual_acc: 0.1023\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 2.4810 - actual_acc: 0.0950 - val_loss: 2.2833 - val_actual_acc: 0.2767\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 25s 248ms/step - loss: 2.4218 - actual_acc: 0.1320 - val_loss: 2.3333 - val_actual_acc: 0.2093\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4919 - actual_acc: 0.1600 - val_loss: 2.4536 - val_actual_acc: 0.0953\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3620 - actual_acc: 0.1380 - val_loss: 2.3147 - val_actual_acc: 0.1698\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3622 - actual_acc: 0.1280 - val_loss: 2.3848 - val_actual_acc: 0.1140\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.2865 - actual_acc: 0.1340 - val_loss: 2.3964 - val_actual_acc: 0.1326\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3927 - actual_acc: 0.1160 - val_loss: 2.4543 - val_actual_acc: 0.1279\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 2.3778 - actual_acc: 0.2170 - val_loss: 2.3941 - val_actual_acc: 0.1302\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.4880 - actual_acc: 0.1520 - val_loss: 2.4791 - val_actual_acc: 0.0512\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.5499 - actual_acc: 0.0800 - val_loss: 2.3842 - val_actual_acc: 0.1651\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3190 - actual_acc: 0.2140 - val_loss: 2.3731 - val_actual_acc: 0.0674\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 2.3204 - actual_acc: 0.2470 - val_loss: 2.5872 - val_actual_acc: 0.0698\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 2.3655 - actual_acc: 0.1580 - val_loss: 2.4015 - val_actual_acc: 0.0628\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 2.5245 - actual_acc: 0.0790 - val_loss: 2.4228 - val_actual_acc: 0.0116\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 2.3406 - actual_acc: 0.1740 - val_loss: 2.6206 - val_actual_acc: 0.0814\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4542 - actual_acc: 0.1450 - val_loss: 2.4158 - val_actual_acc: 0.0442\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4385 - actual_acc: 0.1470 - val_loss: 2.4481 - val_actual_acc: 0.0581\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4033 - actual_acc: 0.0980 - val_loss: 2.4577 - val_actual_acc: 0.0349\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 2.3869 - actual_acc: 0.1660 - val_loss: 2.3704 - val_actual_acc: 0.1395\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.4918 - actual_acc: 0.0510 - val_loss: 2.3360 - val_actual_acc: 0.0860\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3305 - actual_acc: 0.2050 - val_loss: 2.5044 - val_actual_acc: 0.0512\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4335 - actual_acc: 0.1060 - val_loss: 2.4192 - val_actual_acc: 0.1302\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4394 - actual_acc: 0.1510 - val_loss: 2.3537 - val_actual_acc: 0.2093\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.5942 - actual_acc: 0.0500 - val_loss: 2.4510 - val_actual_acc: 0.0767\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 2.3703 - actual_acc: 0.1110 - val_loss: 2.3261 - val_actual_acc: 0.2116\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4200 - actual_acc: 0.1220 - val_loss: 2.3369 - val_actual_acc: 0.2395\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5121 - actual_acc: 0.0880 - val_loss: 2.4033 - val_actual_acc: 0.1512\n",
      "Epoch 893/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5501 - actual_acc: 0.1080 - val_loss: 2.3661 - val_actual_acc: 0.1070\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4471 - actual_acc: 0.1690 - val_loss: 2.4994 - val_actual_acc: 0.2093\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.4276 - actual_acc: 0.1520 - val_loss: 2.5384 - val_actual_acc: 0.1302\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4910 - actual_acc: 0.0920 - val_loss: 2.3481 - val_actual_acc: 0.2907\n",
      "Epoch 897/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5370 - actual_acc: 0.1150 - val_loss: 2.2654 - val_actual_acc: 0.1349\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4502 - actual_acc: 0.1280 - val_loss: 2.2680 - val_actual_acc: 0.3163\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4546 - actual_acc: 0.1610 - val_loss: 2.4417 - val_actual_acc: 0.1140\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3122 - actual_acc: 0.2040 - val_loss: 2.4285 - val_actual_acc: 0.0930\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 34s 343ms/step - loss: 2.4464 - actual_acc: 0.0680 - val_loss: 2.4458 - val_actual_acc: 0.1837\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.3599 - actual_acc: 0.0790 - val_loss: 2.3752 - val_actual_acc: 0.1326\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.2974 - actual_acc: 0.1640 - val_loss: 2.4212 - val_actual_acc: 0.1628\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3893 - actual_acc: 0.1240 - val_loss: 2.4089 - val_actual_acc: 0.1395\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4337 - actual_acc: 0.1500 - val_loss: 2.5243 - val_actual_acc: 0.0442\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4014 - actual_acc: 0.2150 - val_loss: 2.3980 - val_actual_acc: 0.0535\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 2.5076 - actual_acc: 0.0720 - val_loss: 2.2343 - val_actual_acc: 0.1233\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 27s 268ms/step - loss: 2.3496 - actual_acc: 0.2690 - val_loss: 2.4726 - val_actual_acc: 0.0907\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.3222 - actual_acc: 0.2310 - val_loss: 2.4182 - val_actual_acc: 0.1116\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.5082 - actual_acc: 0.1170 - val_loss: 2.5666 - val_actual_acc: 0.0767\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4624 - actual_acc: 0.0970 - val_loss: 2.5959 - val_actual_acc: 0.1163\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 25s 251ms/step - loss: 2.4364 - actual_acc: 0.1210 - val_loss: 2.4151 - val_actual_acc: 0.2093\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5511 - actual_acc: 0.1250 - val_loss: 2.4964 - val_actual_acc: 0.2279\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4729 - actual_acc: 0.1090 - val_loss: 2.4517 - val_actual_acc: 0.0791\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.4451 - actual_acc: 0.1450 - val_loss: 2.2809 - val_actual_acc: 0.1442\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4322 - actual_acc: 0.1080 - val_loss: 2.5516 - val_actual_acc: 0.0256\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3996 - actual_acc: 0.1940 - val_loss: 2.2878 - val_actual_acc: 0.2814\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 26s 263ms/step - loss: 2.4149 - actual_acc: 0.1040 - val_loss: 2.4865 - val_actual_acc: 0.1721\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3368 - actual_acc: 0.1700 - val_loss: 2.4228 - val_actual_acc: 0.2070\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3969 - actual_acc: 0.1940 - val_loss: 2.6124 - val_actual_acc: 0.0698\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4056 - actual_acc: 0.1370 - val_loss: 2.3331 - val_actual_acc: 0.2488\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.3321 - actual_acc: 0.2780 - val_loss: 2.4198 - val_actual_acc: 0.1163\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4216 - actual_acc: 0.1110 - val_loss: 2.6076 - val_actual_acc: 0.0372\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 2.4611 - actual_acc: 0.0910 - val_loss: 2.2840 - val_actual_acc: 0.2419\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3961 - actual_acc: 0.1070 - val_loss: 2.4633 - val_actual_acc: 0.1698\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3057 - actual_acc: 0.1930 - val_loss: 2.7216 - val_actual_acc: 0.0140\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4824 - actual_acc: 0.1230 - val_loss: 2.6055 - val_actual_acc: 0.1233\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4402 - actual_acc: 0.1760 - val_loss: 2.4273 - val_actual_acc: 0.0581\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 33s 327ms/step - loss: 2.4205 - actual_acc: 0.1140 - val_loss: 2.4456 - val_actual_acc: 0.0465\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4839 - actual_acc: 0.0810 - val_loss: 2.4679 - val_actual_acc: 0.2023\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3816 - actual_acc: 0.0670 - val_loss: 2.3766 - val_actual_acc: 0.1326\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5266 - actual_acc: 0.1020 - val_loss: 2.4465 - val_actual_acc: 0.2023\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.5180 - actual_acc: 0.1010 - val_loss: 2.3974 - val_actual_acc: 0.1209\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3432 - actual_acc: 0.1120 - val_loss: 2.4791 - val_actual_acc: 0.0419\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 2.3382 - actual_acc: 0.1740 - val_loss: 2.4250 - val_actual_acc: 0.1558\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.4259 - actual_acc: 0.1440 - val_loss: 2.3807 - val_actual_acc: 0.1233\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3437 - actual_acc: 0.2000 - val_loss: 2.3967 - val_actual_acc: 0.0535\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4641 - actual_acc: 0.0640 - val_loss: 2.3688 - val_actual_acc: 0.2047\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4306 - actual_acc: 0.1160 - val_loss: 2.3930 - val_actual_acc: 0.1465\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4759 - actual_acc: 0.1340 - val_loss: 2.5665 - val_actual_acc: 0.1070\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 2.1629 - actual_acc: 0.2500 - val_loss: 2.4614 - val_actual_acc: 0.1512\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3587 - actual_acc: 0.2380 - val_loss: 2.5320 - val_actual_acc: 0.0721\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.4397 - actual_acc: 0.1270 - val_loss: 2.4000 - val_actual_acc: 0.1116\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4010 - actual_acc: 0.0950 - val_loss: 2.4616 - val_actual_acc: 0.0674\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3801 - actual_acc: 0.0650 - val_loss: 2.3314 - val_actual_acc: 0.1907\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 2.3628 - actual_acc: 0.1900 - val_loss: 2.1571 - val_actual_acc: 0.2256\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3459 - actual_acc: 0.0730 - val_loss: 2.5086 - val_actual_acc: 0.0047\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4020 - actual_acc: 0.1290 - val_loss: 2.4812 - val_actual_acc: 0.0628\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3697 - actual_acc: 0.1210 - val_loss: 2.4437 - val_actual_acc: 0.1372\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 24s 239ms/step - loss: 2.3521 - actual_acc: 0.2830 - val_loss: 2.5507 - val_actual_acc: 0.0884\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4374 - actual_acc: 0.1590 - val_loss: 2.7489 - val_actual_acc: 0.0256\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 2.3782 - actual_acc: 0.1110 - val_loss: 2.5302 - val_actual_acc: 0.0744\n",
      "Epoch 953/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3672 - actual_acc: 0.1960 - val_loss: 2.3621 - val_actual_acc: 0.1814\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4901 - actual_acc: 0.1130 - val_loss: 2.5147 - val_actual_acc: 0.0419\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4099 - actual_acc: 0.0780 - val_loss: 2.4746 - val_actual_acc: 0.1209\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4596 - actual_acc: 0.1350 - val_loss: 2.4353 - val_actual_acc: 0.1535\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 2.5235 - actual_acc: 0.0870 - val_loss: 2.5445 - val_actual_acc: 0.0930\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 25s 252ms/step - loss: 2.3031 - actual_acc: 0.1760 - val_loss: 2.2419 - val_actual_acc: 0.1558\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3786 - actual_acc: 0.1690 - val_loss: 2.4258 - val_actual_acc: 0.1442\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3173 - actual_acc: 0.2580 - val_loss: 2.3997 - val_actual_acc: 0.1837\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3264 - actual_acc: 0.1210 - val_loss: 2.4824 - val_actual_acc: 0.1698\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3763 - actual_acc: 0.1080 - val_loss: 2.3502 - val_actual_acc: 0.1465\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 26s 259ms/step - loss: 2.4493 - actual_acc: 0.1960 - val_loss: 2.3719 - val_actual_acc: 0.2140\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 2.4067 - actual_acc: 0.1570 - val_loss: 2.3432 - val_actual_acc: 0.0814\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4217 - actual_acc: 0.1450 - val_loss: 2.2985 - val_actual_acc: 0.0930\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4819 - actual_acc: 0.1370 - val_loss: 2.2708 - val_actual_acc: 0.0209\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4796 - actual_acc: 0.0660 - val_loss: 2.5053 - val_actual_acc: 0.0651\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4572 - actual_acc: 0.1390 - val_loss: 2.3842 - val_actual_acc: 0.1442\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4656 - actual_acc: 0.1310 - val_loss: 2.5451 - val_actual_acc: 0.1256\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4331 - actual_acc: 0.1440 - val_loss: 2.3759 - val_actual_acc: 0.2093\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 2.4632 - actual_acc: 0.1570 - val_loss: 2.3502 - val_actual_acc: 0.2651\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4229 - actual_acc: 0.0810 - val_loss: 2.4063 - val_actual_acc: 0.1442\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.5783 - actual_acc: 0.0590 - val_loss: 2.3131 - val_actual_acc: 0.1465\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4179 - actual_acc: 0.1270 - val_loss: 2.3919 - val_actual_acc: 0.1070\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.3864 - actual_acc: 0.1220 - val_loss: 2.4567 - val_actual_acc: 0.1209\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3269 - actual_acc: 0.2220 - val_loss: 2.4913 - val_actual_acc: 0.1023\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.2195 - actual_acc: 0.3330 - val_loss: 2.3852 - val_actual_acc: 0.1186\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 25s 246ms/step - loss: 2.1982 - actual_acc: 0.3610 - val_loss: 2.2021 - val_actual_acc: 0.1814\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.2199 - actual_acc: 0.2940 - val_loss: 2.5447 - val_actual_acc: 0.0674\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 25s 254ms/step - loss: 2.4217 - actual_acc: 0.1060 - val_loss: 2.5417 - val_actual_acc: 0.0744\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4388 - actual_acc: 0.0430 - val_loss: 2.3369 - val_actual_acc: 0.0977\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.3418 - actual_acc: 0.1260 - val_loss: 2.4660 - val_actual_acc: 0.1047\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.1026 - actual_acc: 0.1890 - val_loss: 2.5055 - val_actual_acc: 0.1651\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 2.3994 - actual_acc: 0.0900 - val_loss: 2.3339 - val_actual_acc: 0.2093\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 24s 240ms/step - loss: 2.5421 - actual_acc: 0.1000 - val_loss: 2.4363 - val_actual_acc: 0.1116\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 2.3489 - actual_acc: 0.1570 - val_loss: 2.5780 - val_actual_acc: 0.0651\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4836 - actual_acc: 0.1430 - val_loss: 2.1626 - val_actual_acc: 0.2698\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3678 - actual_acc: 0.2580 - val_loss: 2.4115 - val_actual_acc: 0.0302\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4169 - actual_acc: 0.2410 - val_loss: 2.4695 - val_actual_acc: 0.1744\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.4274 - actual_acc: 0.1610 - val_loss: 2.3649 - val_actual_acc: 0.2140\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3751 - actual_acc: 0.0850 - val_loss: 2.5806 - val_actual_acc: 0.1140\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 29s 290ms/step - loss: 2.3943 - actual_acc: 0.1320 - val_loss: 2.4162 - val_actual_acc: 0.1907\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.4420 - actual_acc: 0.1870 - val_loss: 2.4515 - val_actual_acc: 0.0465\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.2357 - actual_acc: 0.0400 - val_loss: 2.4340 - val_actual_acc: 0.0767\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 2.3567 - actual_acc: 0.2870 - val_loss: 2.5066 - val_actual_acc: 0.1209\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 24s 238ms/step - loss: 2.1400 - actual_acc: 0.2490 - val_loss: 2.1333 - val_actual_acc: 0.3000\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.4819 - actual_acc: 0.1420 - val_loss: 2.1944 - val_actual_acc: 0.4860\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 2.6118 - actual_acc: 0.0990 - val_loss: 2.2806 - val_actual_acc: 0.3140\n",
      "Epoch 999/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 25s 253ms/step - loss: 2.4165 - actual_acc: 0.0880 - val_loss: 2.2234 - val_actual_acc: 0.2186\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 2.3922 - actual_acc: 0.1600 - val_loss: 2.4232 - val_actual_acc: 0.1326\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = 100\n",
    "history = model.fit_generator(train_generator,\n",
    "                            steps_per_epoch=steps_per_epoch,\n",
    "                            epochs=1000,\n",
    "                            validation_data=validation_generator,\n",
    "                            validation_steps=int(round(steps_per_epoch/data_ratio*(1-data_ratio))),\n",
    "                            shuffle=True\n",
    "                             )\n",
    "\n",
    "model.save('worm1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d62e6dcbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d62e608dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['actual_acc']\n",
    "val_acc = history.history['val_actual_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "plt.plot(epochs,\n",
    "smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs,\n",
    "smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
