{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Q:\\Program Files\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "143/143 [==============================] - 1s 6ms/step - loss: 0.4537 - acc: 0.0140\n",
      "Epoch 2/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.4219 - acc: 0.0140\n",
      "Epoch 3/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.3922 - acc: 0.0140\n",
      "Epoch 4/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.3650 - acc: 0.0140\n",
      "Epoch 5/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.3393 - acc: 0.0140\n",
      "Epoch 6/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.3150 - acc: 0.0140\n",
      "Epoch 7/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2927 - acc: 0.0140\n",
      "Epoch 8/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2705 - acc: 0.0140\n",
      "Epoch 9/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.2493 - acc: 0.0140\n",
      "Epoch 10/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2299 - acc: 0.0140\n",
      "Epoch 11/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.2105 - acc: 0.0140\n",
      "Epoch 12/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.1912 - acc: 0.0140\n",
      "Epoch 13/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.1744 - acc: 0.0140\n",
      "Epoch 14/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1574 - acc: 0.0140\n",
      "Epoch 15/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1407 - acc: 0.0140\n",
      "Epoch 16/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.1258 - acc: 0.0140\n",
      "Epoch 17/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.1122 - acc: 0.0140\n",
      "Epoch 18/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0995 - acc: 0.0350\n",
      "Epoch 19/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0869 - acc: 0.0350\n",
      "Epoch 20/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0755 - acc: 0.0420\n",
      "Epoch 21/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0653 - acc: 0.0420\n",
      "Epoch 22/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0558 - acc: 0.0420\n",
      "Epoch 23/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0475 - acc: 0.0420\n",
      "Epoch 24/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0418 - acc: 0.0420\n",
      "Epoch 25/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0372 - acc: 0.0420\n",
      "Epoch 26/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0337 - acc: 0.0420\n",
      "Epoch 27/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0311 - acc: 0.0420\n",
      "Epoch 28/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0295 - acc: 0.0420\n",
      "Epoch 29/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0282 - acc: 0.0420\n",
      "Epoch 30/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0274 - acc: 0.0420\n",
      "Epoch 31/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0265 - acc: 0.0420\n",
      "Epoch 32/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0257 - acc: 0.0420\n",
      "Epoch 33/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0250 - acc: 0.0420\n",
      "Epoch 34/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0244 - acc: 0.0420\n",
      "Epoch 35/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0237 - acc: 0.0420\n",
      "Epoch 36/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0231 - acc: 0.0420\n",
      "Epoch 37/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0226 - acc: 0.0420\n",
      "Epoch 38/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0220 - acc: 0.0420\n",
      "Epoch 39/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0215 - acc: 0.0420\n",
      "Epoch 40/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0210 - acc: 0.0420\n",
      "Epoch 41/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0205 - acc: 0.0420\n",
      "Epoch 42/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0200 - acc: 0.0420\n",
      "Epoch 43/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0195 - acc: 0.0420\n",
      "Epoch 44/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0191 - acc: 0.0420\n",
      "Epoch 45/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0187 - acc: 0.0420\n",
      "Epoch 46/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0182 - acc: 0.0420\n",
      "Epoch 47/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0178 - acc: 0.0420\n",
      "Epoch 48/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0174 - acc: 0.0420\n",
      "Epoch 49/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0170 - acc: 0.0420\n",
      "Epoch 50/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0166 - acc: 0.0420\n",
      "Epoch 51/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0162 - acc: 0.0420\n",
      "Epoch 52/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0158 - acc: 0.0420\n",
      "Epoch 53/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0154 - acc: 0.0420\n",
      "Epoch 54/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0150 - acc: 0.0420\n",
      "Epoch 55/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0146 - acc: 0.0420\n",
      "Epoch 56/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0143 - acc: 0.0420\n",
      "Epoch 57/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 0.0139 - acc: 0.0420\n",
      "Epoch 58/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0135 - acc: 0.0420\n",
      "Epoch 59/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0132 - acc: 0.0420\n",
      "Epoch 60/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0128 - acc: 0.0420\n",
      "Epoch 61/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0124 - acc: 0.0420\n",
      "Epoch 62/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0120 - acc: 0.0420\n",
      "Epoch 63/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0117 - acc: 0.0420\n",
      "Epoch 64/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0114 - acc: 0.0420\n",
      "Epoch 65/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0110 - acc: 0.0420\n",
      "Epoch 66/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0107 - acc: 0.0420\n",
      "Epoch 67/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0103 - acc: 0.0420\n",
      "Epoch 68/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0100 - acc: 0.0420\n",
      "Epoch 69/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0096 - acc: 0.0420\n",
      "Epoch 70/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0093 - acc: 0.0420\n",
      "Epoch 71/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0090 - acc: 0.0420\n",
      "Epoch 72/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0086 - acc: 0.0420\n",
      "Epoch 73/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0083 - acc: 0.0420\n",
      "Epoch 74/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0080 - acc: 0.0420\n",
      "Epoch 75/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0077 - acc: 0.0420\n",
      "Epoch 76/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0074 - acc: 0.0420\n",
      "Epoch 77/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0071 - acc: 0.0420\n",
      "Epoch 78/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0069 - acc: 0.0420\n",
      "Epoch 79/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0066 - acc: 0.0420\n",
      "Epoch 80/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0063 - acc: 0.0420\n",
      "Epoch 81/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0061 - acc: 0.0420\n",
      "Epoch 82/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0058 - acc: 0.0420\n",
      "Epoch 83/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0055 - acc: 0.0420\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 84us/step - loss: 0.0053 - acc: 0.0420\n",
      "Epoch 85/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0050 - acc: 0.0420\n",
      "Epoch 86/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0048 - acc: 0.0420\n",
      "Epoch 87/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0045 - acc: 0.0420\n",
      "Epoch 88/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0043 - acc: 0.0420\n",
      "Epoch 89/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0041 - acc: 0.0420\n",
      "Epoch 90/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0039 - acc: 0.0420\n",
      "Epoch 91/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0037 - acc: 0.0420\n",
      "Epoch 92/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0035 - acc: 0.0420\n",
      "Epoch 93/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0034 - acc: 0.0420\n",
      "Epoch 94/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0032 - acc: 0.0420\n",
      "Epoch 95/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0030 - acc: 0.0420\n",
      "Epoch 96/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0029 - acc: 0.0420\n",
      "Epoch 97/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0028 - acc: 0.0420\n",
      "Epoch 98/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0026 - acc: 0.0420\n",
      "Epoch 99/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0025 - acc: 0.0420\n",
      "Epoch 100/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0024 - acc: 0.0420\n",
      "Epoch 101/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0023 - acc: 0.0420\n",
      "Epoch 102/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 0.0022 - acc: 0.0420\n",
      "Epoch 103/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0021 - acc: 0.0420\n",
      "Epoch 104/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0020 - acc: 0.0420\n",
      "Epoch 105/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0020 - acc: 0.0420\n",
      "Epoch 106/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0019 - acc: 0.0420\n",
      "Epoch 107/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0018 - acc: 0.0420\n",
      "Epoch 108/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0017 - acc: 0.0420\n",
      "Epoch 109/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0017 - acc: 0.0420\n",
      "Epoch 110/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0016 - acc: 0.0420\n",
      "Epoch 111/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0016 - acc: 0.0420\n",
      "Epoch 112/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 0.0015 - acc: 0.0420\n",
      "Epoch 113/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0015 - acc: 0.0420\n",
      "Epoch 114/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0014 - acc: 0.0420\n",
      "Epoch 115/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0014 - acc: 0.0420\n",
      "Epoch 116/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0013 - acc: 0.0420\n",
      "Epoch 117/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0013 - acc: 0.0420\n",
      "Epoch 118/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0012 - acc: 0.0420\n",
      "Epoch 119/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0012 - acc: 0.0420\n",
      "Epoch 120/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 0.0012 - acc: 0.0420\n",
      "Epoch 121/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0011 - acc: 0.0420\n",
      "Epoch 122/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0011 - acc: 0.0420\n",
      "Epoch 123/500\n",
      "143/143 [==============================] - 0s 98us/step - loss: 0.0011 - acc: 0.0420\n",
      "Epoch 124/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 0.0010 - acc: 0.0420\n",
      "Epoch 125/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 9.9744e-04 - acc: 0.0420\n",
      "Epoch 126/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 9.6687e-04 - acc: 0.0420\n",
      "Epoch 127/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 9.3954e-04 - acc: 0.0420\n",
      "Epoch 128/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 9.1033e-04 - acc: 0.0420\n",
      "Epoch 129/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 8.8484e-04 - acc: 0.0420\n",
      "Epoch 130/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 8.6058e-04 - acc: 0.0420\n",
      "Epoch 131/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 8.3522e-04 - acc: 0.0420\n",
      "Epoch 132/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 8.1220e-04 - acc: 0.0420\n",
      "Epoch 133/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 7.9032e-04 - acc: 0.0420\n",
      "Epoch 134/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 7.6866e-04 - acc: 0.0420\n",
      "Epoch 135/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 7.4778e-04 - acc: 0.0420\n",
      "Epoch 136/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 7.2823e-04 - acc: 0.0420\n",
      "Epoch 137/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 7.0920e-04 - acc: 0.0420\n",
      "Epoch 138/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 6.9018e-04 - acc: 0.0420\n",
      "Epoch 139/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 6.7400e-04 - acc: 0.0420\n",
      "Epoch 140/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 6.5632e-04 - acc: 0.0420\n",
      "Epoch 141/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 6.3840e-04 - acc: 0.0420\n",
      "Epoch 142/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 6.2491e-04 - acc: 0.0420\n",
      "Epoch 143/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 6.0881e-04 - acc: 0.0420\n",
      "Epoch 144/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 5.9389e-04 - acc: 0.0420\n",
      "Epoch 145/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 5.8040e-04 - acc: 0.0420\n",
      "Epoch 146/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 5.6574e-04 - acc: 0.0420\n",
      "Epoch 147/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 5.5335e-04 - acc: 0.0420\n",
      "Epoch 148/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 5.4033e-04 - acc: 0.0420\n",
      "Epoch 149/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 5.2905e-04 - acc: 0.0420\n",
      "Epoch 150/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 5.1556e-04 - acc: 0.0420\n",
      "Epoch 151/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 5.0383e-04 - acc: 0.0420\n",
      "Epoch 152/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 4.9312e-04 - acc: 0.0420\n",
      "Epoch 153/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 4.8234e-04 - acc: 0.0420\n",
      "Epoch 154/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 4.7236e-04 - acc: 0.0420\n",
      "Epoch 155/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 4.6305e-04 - acc: 0.0420\n",
      "Epoch 156/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 4.5338e-04 - acc: 0.0420\n",
      "Epoch 157/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 4.4428e-04 - acc: 0.0420\n",
      "Epoch 158/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 4.3523e-04 - acc: 0.0420\n",
      "Epoch 159/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 4.2695e-04 - acc: 0.0420\n",
      "Epoch 160/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 4.1793e-04 - acc: 0.0420\n",
      "Epoch 161/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 4.1039e-04 - acc: 0.0420\n",
      "Epoch 162/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 4.0247e-04 - acc: 0.0420\n",
      "Epoch 163/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 3.9581e-04 - acc: 0.0420\n",
      "Epoch 164/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 3.8753e-04 - acc: 0.0420\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 84us/step - loss: 3.8137e-04 - acc: 0.0420\n",
      "Epoch 166/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 3.7510e-04 - acc: 0.0420\n",
      "Epoch 167/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 3.6848e-04 - acc: 0.0420\n",
      "Epoch 168/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 3.6245e-04 - acc: 0.0420\n",
      "Epoch 169/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 3.5658e-04 - acc: 0.0420\n",
      "Epoch 170/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 3.5045e-04 - acc: 0.0420\n",
      "Epoch 171/500\n",
      "143/143 [==============================] - 0s 98us/step - loss: 3.4589e-04 - acc: 0.0420\n",
      "Epoch 172/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 3.3970e-04 - acc: 0.0420\n",
      "Epoch 173/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 3.3452e-04 - acc: 0.0420\n",
      "Epoch 174/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 3.3031e-04 - acc: 0.0420\n",
      "Epoch 175/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 3.2619e-04 - acc: 0.0420\n",
      "Epoch 176/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 3.2084e-04 - acc: 0.0420\n",
      "Epoch 177/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 3.1681e-04 - acc: 0.0420\n",
      "Epoch 178/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 3.1279e-04 - acc: 0.0420\n",
      "Epoch 179/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 3.0825e-04 - acc: 0.0420\n",
      "Epoch 180/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 3.0410e-04 - acc: 0.0420\n",
      "Epoch 181/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.9975e-04 - acc: 0.0420\n",
      "Epoch 182/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.9508e-04 - acc: 0.0420\n",
      "Epoch 183/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.9094e-04 - acc: 0.0420\n",
      "Epoch 184/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.8713e-04 - acc: 0.0420\n",
      "Epoch 185/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.8184e-04 - acc: 0.0420\n",
      "Epoch 186/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.7791e-04 - acc: 0.0420\n",
      "Epoch 187/500\n",
      "143/143 [==============================] - 0s 105us/step - loss: 2.7373e-04 - acc: 0.0420\n",
      "Epoch 188/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.6950e-04 - acc: 0.0420\n",
      "Epoch 189/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.6450e-04 - acc: 0.0420\n",
      "Epoch 190/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.6123e-04 - acc: 0.0420\n",
      "Epoch 191/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.5780e-04 - acc: 0.0420\n",
      "Epoch 192/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.5335e-04 - acc: 0.0420\n",
      "Epoch 193/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.4986e-04 - acc: 0.0420\n",
      "Epoch 194/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 2.4599e-04 - acc: 0.0420\n",
      "Epoch 195/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.4265e-04 - acc: 0.0420\n",
      "Epoch 196/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.3906e-04 - acc: 0.0420\n",
      "Epoch 197/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.3541e-04 - acc: 0.0420\n",
      "Epoch 198/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.3241e-04 - acc: 0.0420\n",
      "Epoch 199/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.2929e-04 - acc: 0.0420\n",
      "Epoch 200/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.2601e-04 - acc: 0.0420\n",
      "Epoch 201/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.2269e-04 - acc: 0.0420\n",
      "Epoch 202/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.1981e-04 - acc: 0.0420\n",
      "Epoch 203/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.1714e-04 - acc: 0.0420\n",
      "Epoch 204/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.1405e-04 - acc: 0.0420\n",
      "Epoch 205/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.1132e-04 - acc: 0.0420\n",
      "Epoch 206/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 2.0803e-04 - acc: 0.0420\n",
      "Epoch 207/500\n",
      "143/143 [==============================] - 0s 91us/step - loss: 2.0541e-04 - acc: 0.0420\n",
      "Epoch 208/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 2.0260e-04 - acc: 0.0420\n",
      "Epoch 209/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.9989e-04 - acc: 0.0420\n",
      "Epoch 210/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.9771e-04 - acc: 0.0420\n",
      "Epoch 211/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.9549e-04 - acc: 0.0420\n",
      "Epoch 212/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.9207e-04 - acc: 0.0420\n",
      "Epoch 213/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.8949e-04 - acc: 0.0420\n",
      "Epoch 214/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.8760e-04 - acc: 0.0420\n",
      "Epoch 215/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.8533e-04 - acc: 0.0420\n",
      "Epoch 216/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.8261e-04 - acc: 0.0420\n",
      "Epoch 217/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.8045e-04 - acc: 0.0420\n",
      "Epoch 218/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.7852e-04 - acc: 0.0420\n",
      "Epoch 219/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.7663e-04 - acc: 0.0420\n",
      "Epoch 220/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.7492e-04 - acc: 0.0420\n",
      "Epoch 221/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.7267e-04 - acc: 0.0420\n",
      "Epoch 222/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.7063e-04 - acc: 0.0420\n",
      "Epoch 223/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.6869e-04 - acc: 0.0420\n",
      "Epoch 224/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.6678e-04 - acc: 0.0420\n",
      "Epoch 225/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.6493e-04 - acc: 0.0420\n",
      "Epoch 226/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.6292e-04 - acc: 0.0420\n",
      "Epoch 227/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.6126e-04 - acc: 0.0420\n",
      "Epoch 228/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5948e-04 - acc: 0.0420\n",
      "Epoch 229/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5750e-04 - acc: 0.0420\n",
      "Epoch 230/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5615e-04 - acc: 0.0420\n",
      "Epoch 231/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5429e-04 - acc: 0.0420\n",
      "Epoch 232/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5271e-04 - acc: 0.0420\n",
      "Epoch 233/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.5104e-04 - acc: 0.0420\n",
      "Epoch 234/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.4979e-04 - acc: 0.0420\n",
      "Epoch 235/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.4830e-04 - acc: 0.0420\n",
      "Epoch 236/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.4677e-04 - acc: 0.0420\n",
      "Epoch 237/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.4544e-04 - acc: 0.0420\n",
      "Epoch 238/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.4347e-04 - acc: 0.0420\n",
      "Epoch 239/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.4208e-04 - acc: 0.0420\n",
      "Epoch 240/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.4083e-04 - acc: 0.0420\n",
      "Epoch 241/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.3940e-04 - acc: 0.0420\n",
      "Epoch 242/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.3828e-04 - acc: 0.0420\n",
      "Epoch 243/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.3680e-04 - acc: 0.0420\n",
      "Epoch 244/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 77us/step - loss: 1.3583e-04 - acc: 0.0420\n",
      "Epoch 245/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.3418e-04 - acc: 0.0420\n",
      "Epoch 246/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.3309e-04 - acc: 0.0420\n",
      "Epoch 247/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.3178e-04 - acc: 0.0420\n",
      "Epoch 248/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.3072e-04 - acc: 0.0420\n",
      "Epoch 249/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.2931e-04 - acc: 0.0420\n",
      "Epoch 250/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.2826e-04 - acc: 0.0420\n",
      "Epoch 251/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.2702e-04 - acc: 0.0420\n",
      "Epoch 252/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.2605e-04 - acc: 0.0420\n",
      "Epoch 253/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.2452e-04 - acc: 0.0420\n",
      "Epoch 254/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.2351e-04 - acc: 0.0420\n",
      "Epoch 255/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.2244e-04 - acc: 0.0420\n",
      "Epoch 256/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.2121e-04 - acc: 0.0420\n",
      "Epoch 257/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.2015e-04 - acc: 0.0420\n",
      "Epoch 258/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.1928e-04 - acc: 0.0420\n",
      "Epoch 259/500\n",
      "143/143 [==============================] - 0s 84us/step - loss: 1.1794e-04 - acc: 0.0420\n",
      "Epoch 260/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.1692e-04 - acc: 0.0420\n",
      "Epoch 261/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.1581e-04 - acc: 0.0420\n",
      "Epoch 262/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.1515e-04 - acc: 0.0420\n",
      "Epoch 263/500\n",
      "143/143 [==============================] - 0s 70us/step - loss: 1.1376e-04 - acc: 0.0420\n",
      "Epoch 264/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.1282e-04 - acc: 0.0420\n",
      "Epoch 265/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.1210e-04 - acc: 0.0420\n",
      "Epoch 266/500\n",
      "143/143 [==============================] - 0s 77us/step - loss: 1.1090e-04 - acc: 0.0420\n",
      "Epoch 267/500\n",
      " 32/143 [=====>........................] - ETA: 0s - loss: 2.1401e-04 - acc: 0.0625"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-80da562a8f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_answer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNB_EPOCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mQ:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mQ:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mQ:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mQ:\\Program Files\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mQ:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import optimizers\n",
    "np.random.seed()\n",
    "\n",
    "NB_EPOCH = 500\n",
    "VERBOSE = 1\n",
    "\n",
    "X_in = [[ 0 , 44 ], [ 0 , 18 ], [ 38 , 0 ], [ 48 , 14 ], [ 0 , 36 ], [ 14 , 0 ], [ 34 , 0 ], [ 0 , 0 ], [ 0 , 38 ], [ 32 , 0 ], [ 28 , 0 ], [ 36 , 0 ], [ 20 , 48 ], [ 0 , 6 ], [ 0 , 20 ], [ 0 , 42 ], [ 0 , 8 ], [ 24 , 32 ], [ 4 , 0 ], [ 6 , 8 ], [ 24 , 10 ], [ 0 , 22 ], [ 16 , 12 ], [ 30 , 40 ], [ 0 , 32 ], [ 0 , 32 ], [ 16 , 0 ], [ 48 , 20 ], [ 0 , 8 ], [ 32 , 0 ], [ 0 , 46 ], [ 0 , 22 ], [ 0 , 8 ], [ 10 , 24 ], [ 0 , 36 ], [ 14 , 0 ], [ 0 , 22 ], [ 42 , 0 ], [ 16 , 12 ], [ 40 , 30 ], [ 44 , 0 ], [ 40 , 0 ], [ 34 , 0 ], [ 0 , 32 ], [ 40 , 30 ], [ 32 , 0 ], [ 0 , 30 ], [ 24 , 18 ], [ 0 , 26 ], [ 22 , 0 ], [ 0 , 4 ], [ 16 , 0 ], [ 10 , 0 ], [ 0 , 32 ], [ 0 , 42 ], [ 2 , 0 ], [ 0 , 38 ], [ 32 , 24 ], [ 48 , 0 ], [ 20 , 0 ], [ 0 , 18 ], [ 0 , 38 ], [ 14 , 48 ], [ 40 , 42 ], [ 16 , 12 ], [ 26 , 0 ], [ 0 , 20 ], [ 40 , 30 ], [ 16 , 30 ], [ 36 , 48 ], [ 36 , 0 ], [ 18 , 24 ], [ 34 , 0 ], [ 16 , 0 ], [ 0 , 24 ], [ 0 , 24 ], [ 0 , 18 ], [ 38 , 0 ], [ 28 , 0 ], [ 0 , 34 ], [ 0 , 36 ], [ 24 , 32 ], [ 16 , 30 ], [ 40 , 30 ], [ 24 , 0 ], [ 0 , 14 ], [ 8 , 6 ], [ 12 , 0 ], [ 16 , 0 ], [ 16 , 30 ], [ 48 , 14 ], [ 0 , 30 ], [ 38 , 0 ], [ 38 , 0 ], [ 0 , 8 ], [ 36 , 48 ], [ 0 , 32 ], [ 10 , 24 ], [ 46 , 0 ], [ 24 , 10 ], [ 30 , 0 ], [ 0 , 48 ], [ 40 , 0 ], [ 42 , 0 ], [ 32 , 24 ], [ 32 , 0 ], [ 12 , 16 ], [ 0 , 4 ], [ 0 , 28 ], [ 32 , 0 ], [ 40 , 42 ], [ 46 , 0 ], [ 0 , 24 ], [ 30 , 16 ], [ 36 , 48 ], [ 40 , 0 ], [ 24 , 0 ], [ 0 , 22 ], [ 40 , 42 ], [ 10 , 24 ], [ 0 , 16 ], [ 14 , 48 ], [ 22 , 0 ], [ 0 , 22 ], [ 30 , 0 ], [ 0 , 2 ], [ 48 , 20 ], [ 6 , 0 ], [ 6 , 0 ], [ 28 , 0 ], [ 20 , 0 ], [ 0 , 40 ], [ 42 , 0 ], [ 48 , 36 ], [ 14 , 0 ], [ 10 , 24 ], [ 0 , 30 ], [ 48 , 20 ], [ 40 , 30 ], [ 0 , 0 ], [ 42 , 40 ], [ 0 , 48 ], [ 32 , 24 ]]\n",
    "X_answer = [[44] ,[18] ,[38] ,[50] ,[36] ,[14] ,[34] ,[0] ,[38] ,[32] ,[28] ,[36] ,[52] ,[6] ,[20] ,[42] ,[8] ,[40] ,[4] ,[10] ,[26] ,[22] ,[20] ,[50] ,[32] ,[32] ,[16] ,[52] ,[8] ,[32] ,[46] ,[22] ,[8] ,[26] ,[36] ,[14] ,[22] ,[42] ,[20] ,[50] ,[44] ,[40] ,[34] ,[32] ,[50] ,[32] ,[30] ,[30] ,[26] ,[22] ,[4] ,[16] ,[10] ,[32] ,[42] ,[2] ,[38] ,[40] ,[48] ,[20] ,[18] ,[38] ,[50] ,[58] ,[20] ,[26] ,[20] ,[50] ,[34] ,[60] ,[36] ,[30] ,[34] ,[16] ,[24] ,[24] ,[18] ,[38] ,[28] ,[34] ,[36] ,[40] ,[34] ,[50] ,[24] ,[14] ,[10] ,[12] ,[16] ,[34] ,[50] ,[30] ,[38] ,[38] ,[8] ,[60] ,[32] ,[26] ,[46] ,[26] ,[30] ,[48] ,[40] ,[42] ,[40] ,[32] ,[20] ,[4] ,[28] ,[32] ,[58] ,[46] ,[24] ,[34] ,[60] ,[40] ,[24] ,[22] ,[58] ,[26] ,[16] ,[50] ,[22] ,[22] ,[30] ,[2] ,[52] ,[6] ,[6] ,[28] ,[20] ,[40] ,[42] ,[60] ,[14] ,[26] ,[30] ,[52] ,[50] ,[0] ,[58] ,[48] ,[40]]\n",
    "X_in = np.asarray(X_in, dtype=np.float32)\n",
    "X_answer = np.asarray(X_answer, dtype=np.float32)\n",
    "\n",
    "X_in /= np.amax(X_in)\n",
    "X_answer /= np.amax(X_answer)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim = 2, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_in, X_answer, epochs=NB_EPOCH, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
