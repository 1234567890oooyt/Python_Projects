{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = ['Абу Аль','Куманяев Сергей','Коваленко Иван','Абрамов Владислав','Балицкий Данила','Шкенёв Пётр','Виноградов Александр','Воронков Александр','Крылов Никита','Башмаков Кирилл','Кирилл Лаврентьев''Погребняк Александра','Панафидин Егор','Яворская Дарья','Алексеева Настя','Иванова Иулита','Розин Даниил','Розин Даня','Вылку Александр','Власов Илья','Сигова Елизавета','Молодкин Максим','Галыгина Таисия','Воробьёва Лина','Светлова Елена','Фрескин Василий','Дёмина Яна','Сладкевич Владислав','Игнатович Екатерина','Гончарова Анна','Лунин Дмитрий','Турчак Валерия','Назаров Михаил','Крадинов Борис','Данилов Александр','Паталова Алиса','Лебедь Иван','Ефимов Даниил','Шадрина Анастасия','Тараканова Ксения','Мозолина Надежда','Бурченко Анна','Широков Владислав','Соломенцева Полина','Большаков Иван','Араманович Александр','Мещеряков Артур','Белахов Гриша','Сапрунов Юрий','Ткачёв Даня','Михайленко Егор','Майер Юрий','Амельченко Глеб','Пилецка Владислава','Анисимова Дина','Туманова Елена','Олинов Дмитрий','Гузь Вася','Макаров Дмитрий','Запаренчук Алексей','Табачников Борис','Васильев Валерий','Олинов Дмитрий','Савинов Александр','Осичева Александра','Иващенко Лев','Плевокас Янис','Кондратенко Дарья','Пучкова Дарья','Яковлева Настя','Кокорев Константин','Куликов Михаил','Баранова Ксения','Васильев Пётр','Кузнецова Анжелика','Солдатова Елизавета','Аммосов Александр','Метс Доминика','Затекин Дмитрий','Елисов Михаил','Кирюхин Алексей','Лозовский Александр','Молодкин Максим','Мазур Денис','Кирюхин Алексей','Решетникова Арина','Халилулин Рафаэль','Гречаная Дарья','Злобина Марианна','Немкова Мария','Луппов Даниил','Бандзеладзе Александр','Алимов Дмитрий','Чеканов Арсений','Циглер Матвей','Барабанова Анна','Кирюхин Алексей','Кадолов Захар','Белахов Григорий','Ивашенко Валерия','Григорьев Антон','Пер Николай','Мурашов Леонид','Матюнин Никита', 'Сладкевич Владислав','Семёнова Тамара','Козлова Варвара','Яковлева Анастасия','Лысикова Александра','Лысикова Анна','Тихая Вита','Коротков Артём','Бузыкина Мария','Кургузова Юлия','Борисова Елизавета','Немкова Мария','Барабанова Анна']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching ВШЭ\n",
      "Found Абу Аль on ВШЭ, Факультет компьютерных наук, Прикладная математика и информатика (01.03.02) (Прикладная математика и информатика) \n",
      "Found Абу Аль on ВШЭ, Факультет компьютерных наук, Программная инженерия (09.03.04) \n",
      "Searching РТУ МИРЭА\n",
      "Found Абу Аль on РТУ МИРЭА, ИТ, Программная инженерия (09.03.04) \n",
      "Found Абу Аль on РТУ МИРЭА, ИТ, Прикладная информатика (09.03.03) \n",
      "Found Абу Аль on РТУ МИРЭА, Киб, Прикладная математика и информатика (01.03.02) \n",
      "Searching МГТУ им. Баумана\n",
      "Searching МПГУ\n",
      "Searching МГЛУ\n",
      "Searching МСХА\n",
      "Searching РХТУ\n",
      "Searching РУДН\n",
      "Searching МФТИ\n",
      "Searching РГУНГ\n",
      "Searching Московский Политех\n",
      "Searching РГГУ\n",
      "Searching МИЭТ\n",
      "Searching МЭИ\n",
      "Searching РАНХиГС\n",
      "Searching МИФИ\n",
      "Searching МГППУ\n",
      "Searching РЭА\n",
      "Searching МГАВМ\n",
      "Searching ГУУ\n",
      "Searching МГИМО\n",
      "Searching МИСиС\n",
      "Searching МИИГАиК\n",
      "Searching ВАВТ\n",
      "Searching РАНХиГС - ЭМИТ\n",
      "Searching МГУ\n",
      "Searching МАИ\n"
     ]
    }
   ],
   "source": [
    "vuzes = {}\n",
    "\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "admlist_adress ='http://admlist.ru'\n",
    "with urllib.request.urlopen(admlist_adress + '/index.html') as file:\n",
    "    text = file.read().decode('utf-8')\n",
    "\n",
    "soup = BeautifulSoup(text, 'lxml')\n",
    "VUZ_list = soup.findAll('tr')\n",
    "link = None\n",
    "for vuz in VUZ_list:\n",
    "    td_vuz = vuz.find('td')\n",
    "    if td_vuz is None:\n",
    "        continue\n",
    "    \n",
    "    a = td_vuz.find('a')\n",
    "    if a is not None:\n",
    "        link = a.get('href').split('/')[0]\n",
    "        \n",
    "        # Opening faculties page\n",
    "        vuz_name = a.text\n",
    "        vuzes[vuz_name] = 0\n",
    "        print('Searching', vuz_name)\n",
    "        with urllib.request.urlopen(admlist_adress + '/' + link + '/index.html') as file:\n",
    "            text = file.read().decode('utf-8')\n",
    "\n",
    "        soup = BeautifulSoup(text, 'lxml')        \n",
    "        \n",
    "        fac_list = soup.findAll('tr')\n",
    "        for fac in fac_list:\n",
    "            td_fac = fac.find('td')\n",
    "            if td_fac is None:\n",
    "                continue\n",
    "\n",
    "            a = td_fac.find('a')\n",
    "            if a is not None:\n",
    "                link_to_list = admlist_adress + '/' + link + '/'+ a.get('href')\n",
    "\n",
    "                # Opening page with list\n",
    "                with urllib.request.urlopen(link_to_list) as file:\n",
    "                    text = file.read().decode('utf-8')\n",
    "\n",
    "                soup = BeautifulSoup(text, 'lxml')             \n",
    "                \n",
    "                if link in ['msu', 'mai']:\n",
    "                    if len(soup.findAll('table')) < 3:\n",
    "                        continue\n",
    "                    pupils_list = soup.findAll('table')[2].findAll('tr')\n",
    "                else:\n",
    "                    pupils_list = soup.findAll('tr')                \n",
    "                \n",
    "                if len(pupils_list) <= 3:\n",
    "                    continue\n",
    "                title = pupils_list[2]\n",
    "                pupils_list = pupils_list[3:]\n",
    "\n",
    "                fac_table_refrashed = False\n",
    "                for pupil in pupils_list:\n",
    "                    splits = pupil.findAll('td')[3].text.split()\n",
    "                    if len(splits) < 2:\n",
    "                        continue\n",
    "                    surname, name, *_ = splits\n",
    "                    name = surname + ' ' + name\n",
    "                    if name in friends:\n",
    "                        print('Found',name, 'on', soup.find('h2').text)\n",
    "                        vuzes[vuz_name] += 1\n",
    "    if link == 'mai':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vuzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
