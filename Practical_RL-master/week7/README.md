# Materials

_Links on all articles mentioned during the lecture could be found in "References" at the very end of the presentation slides. All other interesing links which contribute to the topic of POMDP are presented below_

## Planning
* [Introduction to planning in POMDP, ch.: 6](https://www.amazon.com/Decision-Making-Under-Uncertainty-Application/dp/0262029251)
* [Bayes filters in robotics, ch.: 3, 4](https://docs.ufpr.br/~danielsantos/ProbabilisticRobotics.pdf)
* SOTA in scalable approximate __offline__ planning:  [SARSOP](http://www.roboticsproceedings.org/rss04/p9.pdf) and [PLEASE](http://www.aaai.org/ocs/index.php/SOCS/SOCS15/paper/viewFile/10686/10627) which is build on top of the former
* SOTA in scalable approximate __online__ planning: [DESPOT](https://arxiv.org/pdf/1609.03250v1.pdf)
* Not SOTA but very useful and enlightening __online__ planning approach: [POMCP](https://papers.nips.cc/paper/4031-monte-carlo-planning-in-large-pomdps.pdf)
* [Realizations of SARSOP, DESPOT and MCVI in C++] (http://bigbird.comp.nus.edu.sg/pmwiki/farm/appl/)
* Recent approaches combining  POMDP planning with learning on top of neural networks: [Predictron](https://openreview.net/pdf?id=BkJsCIcgl), [historgram filter](https://openreview.net/pdf?id=ByvJuTigl) and [QMDP-Net](https://arxiv.org/pdf/1703.06692.pdf)


## Learning

Non neural approach:
* [Data efficient learning in continous POMDP](https://arxiv.org/abs/1602.02523v1)
* [Managing wind farms with bayesian POMDP](http://ascelibrary.org/doi/abs/10.1061/(ASCE)CP.1943-5487.0000390)
* [Bayesian learning and decision-making in dynamic environments](http://www.jmlr.org/papers/volume12/ross11a/ross11a.pdf)


---

# Homework
Homework is platform and framewerk independent, so choose the ones which suit you best, but pay attention on how many you will need to implement youself in case of nonstandart ones.
Instructions and suggestions could be found in [homework notebook](https://github.com/yandexdataschool/Practical_RL/blob/master/week7/pomdp_homework.ipynb).

